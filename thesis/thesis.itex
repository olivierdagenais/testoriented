<?xml version="1.0" encoding="UTF-8"?>
<iTeX>
  <preamble><!-- !TEX TS-program = pdflatex -->
    <!-- !TEX encoding = UTF-8 Unicode -->

    <command name="documentclass" opt="12pt" param="dalthesis" />

    <region comment='disable turning "fi", "ff", etc. into one character'>
      <command name="usepackage" param="fontspec" />
      <command name="setmonofont" param="Courier New" />
      <command name="setmainfont" opt="Mapping=tex-text,Ligatures={NoCommon,NoRare}" param="Latin Modern Roman" />
    </region>

    <command name="usepackage" param="array" />

    <region comment='the "listings" package is used for source code snippets'>
      <command name="usepackage" param="listings" />
      <command name="usepackage" param="setspace" />
      <command name="lstset" param="tabsize=2" />
      <command name="lstdefinestyle" param="realCode}{basicstyle=\footnotesize\ttfamily, xleftmargin=2em, numbers=left, numberstyle=\footnotesize\ttfamily" />
      <command name="lstdefinestyle" param="pseudoCode}{basicstyle=\small, numbers=none" />
      <!-- Override the lstinputlisting command to surround it inside braces,
      otherwise the style parameter does not work:
        http://tex.stackexchange.com/q/21663/1892
        http://stackoverflow.com/questions/2908908/#2909530
      -->
      <raw>\let\originallstinputlisting\lstinputlisting</raw>
      <raw>\renewcommand{\lstinputlisting}[2][]{{\originallstinputlisting[{#1}]{#2}}}</raw>
    </region>

    <region comment="URLs and references are hyperlinked">
      <command name="usepackage" param="url" />
      <command name="usepackage" param="hyperref" opt="pdftitle={Improving testability with Stateless Method Extraction},pdfauthor={Olivier Dagenais},colorlinks=true,linkcolor=black,anchorcolor=black,citecolor=black,citecolor=black,urlcolor=black,pdftex=true" />
    </region>

    <region comment="Define column type for results tables">
      <!-- Used these articles
http://tex.stackexchange.com/questions/12703/
http://tex.stackexchange.com/questions/10270/
      -->
      <raw>\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}b{#1}}</raw>
    </region>
    <command name="usepackage" param="nameref" />
    <command name="usepackage" param="multirow" />
    <command name="usepackage" param="pdfpages" />
    <command name="usepackage" param="float" />
    <!-- http://www.tex.ac.uk/cgi-bin/texfaq2html?label=tmupfl -->
    <command name="usepackage" param="morefloats" />
    <command name="usepackage" param="lscape" />
    <!-- Comment out the line above and uncomment the line below to see the landscape code samples rotated in the PDF viewer, but with a chance of mis-print.
http://tex.stackexchange.com/questions/20303/xelatex-forces-readers-to-rotate-their-heads-90-degrees
    -->
    <!-- <command name="usepackage" param="pdflscape" /> -->
    <raw>\newfloat{code}{htbp}{loc}</raw>
  </preamble>
  <document>
    <region name="Title page">
      <command name="title" param="Improving testability with stateless method extraction" />
      <command name="author" param="Olivier Dagenais" />
      <command name="submitdate" param="February 29, 2012" />
      <command name="copyrightyear" param="2012" />
      <command name="degree" param="Master of Computer Science" />
      <command name="nolistoffigures" />
      <!-- Prevent automatic title page in frontmatter -->
      <command name="notitlepage" />
      <!-- ...because we invoke it here -->
      <command name="pagenumbering" param="roman" />
      <command name="daltitlepage" />
    </region>

    <region name="Before Table of Contents">
      <block param="abstract">
        <!-- An abstract is required in all theses. -->
        <!-- No more than 150 words -->
        The unit testing of object-oriented classes is complicated by the presence of hidden mutable state, since the state of an instance may depend on its entire history of input.  This difficulty is known as "the state problem" and causes unit tests to contain a lot of test set-up code, making them more fragile and complex.  This thesis presents the <em>stateless method extraction</em> "testability refactoring", which is designed to overcome the state problem by extracting simple methods that operate only on their parameters, communicate results only through their return values, have no side-effects and whose functionality can be directly verified by unit tests.  An empirical evaluation compares our approach to three other strategies, using three open-source projects and measuring three metrics for each combination.  Our approach produces the best results on average, improving the testability of the classes under test while keeping their public interface intact.
      </block>
      <block param="acknowledgements">
        I would like to thank Marie-Noëlle Houston, Eric Nadeau, James Hague and Keith Bell for their insightful review comments and suggestions.
        
        I would also like to thank Dr. Dwight Deugo for his guidance and help with distilling my research and findings into a suitable thesis format.
        
        Last, but not least, I would like to thank my lovely wife Natalie for all her support and help.
      </block>
    </region>

    <command name="frontmatter">
      <region name="[List of] Listings">
        <command name="addcontentsline" param="toc}{chapter}{Listings" />
        <command name="lstlistoflistings" />
        <command name="clearpage" />
      </region>
    </command>
    <command name="mainmatter">
      <command name="chapter" param="Introduction">
        <command name="label" param="chapter:Introduction" />
        <command name="section" param="Introduction">
          Our thesis is that testability can be improved with stateless method extraction.  In this chapter, we introduce the "state problem" and the motivation for solving it.  We also introduce how we will be evaluating our stateless method extraction approach and the metrics we will use to evaluate and measure testability improvements using it.  We conclude with an overview of the rest of the thesis.
        </command>
        <command name="section" param="Problem">
          Software has advanced considerably in the last several years, but has software quality kept up?  We do not always know how good a program or component is, or if it is free of defects, and if those defects will affect the program, directly or otherwise.  Software defects can range from the benign, such as incorrect colours and typographical errors in the interface or output, to the very serious, such as causing the destruction of a rocket carrying four satellites <see cite="lions96ariane, esa05clustermission" /> or the death of several patients <see cite="leveson95medicaldevices" />.

          Programming languages and compilers have evolved to add features that make it easier to write code, although those features do not always make it easier to test the same code.  Object-oriented programming (OOP), for example, has introduced constructs and paradigms designed to make abstraction, inheritance and polymorphism easier, but at the same time has introduced a feature that can make testing more difficult:  encapsulation (information hiding) in the form of instance state.  Encapsulation allows an object to hide its implementation details so as to present a simpler interface to callers.  Indeed, Alan Kay describes this simpler, higher-level interaction between objects as "goals", replacing low-level assignments: "Again, the whole point of OOP is not to have to worry about what is inside an object." <see cite="kay93earlyhistory" />

          Hidden and mutable instance state poses a problem for automated unit testing because that instance state may come into play when exercising a specific scenario <see cite="binder00testharness" />.  Since the instance state is mutable, the values may not be initialized at instance construction or can change as instance methods are called.  Because the instance state is hidden, there exists, by definition, no way to manipulate this instance state directly.  Separately, hidden (but immutable) instance state or mutable (but visible) instance state do not provide too many difficulties for test writing.  It is the combination of the hidden and mutable properties that makes it difficult to write tests.

          <command name="subsection" param="Hidden Mutable State, Described">
            Hidden mutable state (HMS) manifests itself in different forms:
            <block param="itemize">
              <command name="item"> Instance state that cannot be set from the constructor or a factory method.</command>
              <command name="item"> Instance state that cannot be directly set from a setter method or property.</command>
              <command name="item"> A constructor or direct factory method is not available.  For example, an instance can only be created as a by-product of a method call on another class.</command>
              <command name="item"> Instance state points to objects with their own hidden mutable state.</command>
            </block>
            In short, a class with hidden mutable state has variables or fields that must be set or modified indirectly as a result of calling a method that, although not necessarily directly related, modifies one or more variables or fields.
          </command>

          Hidden mutable state results in difficult-to-test code, which means it remains untested, despite the many automated test frameworks and systems available <see cite="aberdour07dotnetunit" />.  This is likely due to a trade-off between ease of maintenance and testability, where testability was ultimately not favoured.

          We still want to test the code, but we must first surmount the difficult-to-test obstacle that hidden mutable state introduces:
          <block param="quote">
            "It is often difficult to control the pretest state of the [Implementation Under Test (IUT)].  The instance variables of the IUT are encapsulated and often composed of still more uncontrollable objects.  The interface of the IUT is typically insufficient for testing purposes. (...) Although existing IUT methods can be used to control state, they often do not provide all access needed and can produce spurious test results if they are buggy.  They maybe not even exist, if their development has been deferred to a later increment or they are part of an abstract class. (...) Observing the post-test state of the IUT is often difficult, for the same reasons that controlling the pretest state is difficult." <see cite="binder00testharness" />
          </block>

          In the process of testing a method that uses hidden instance state (as input, output or both), it usually becomes necessary to write the unit test such that it will indirectly orchestrate said instance state so that specific scenarios can be implemented.  This makes the test method difficult to maintain because the test will be more unwieldy and less obvious - especially in the "arrange" phase <see cite="reehal10arrangeact" />, also called the "setup" phase <see cite="meszaros07xunitpatterns" /> - which may discourage the creation of such tests.

          <region name="two stateful code listings">
            <listing label="lst:StatefulSmokeDetector" style="realCode" file="Stateful/SmokeDetector.cs" placement="p">
              C# showing the <tt>SmokeDetector</tt> class with HMS
            </listing>
            <listing label="lst:StatefulSmokeDetectorTest" style="realCode" file="Stateful/SmokeDetectorTest.cs" placement="t!">
              C# showing the test class for the <tt>SmokeDetector</tt>, with the repeated calls to the <tt>Cycle()</tt> method
            </listing>
          </region>

          An example of the state problem can be seen in listings <see ref="lst:StatefulSmokeDetector" /> and <see ref="lst:StatefulSmokeDetectorTest" />.  They demonstrate how having all the instance fields marked as <tt>private</tt> forces any test wishing to bring the object to a certain state - such as "alarm sounds while detection decays" - to repeatedly call the <tt>Cycle()</tt> method with various values provided to the <tt>level</tt> parameter.  By the same token, the only observable state for verification is the return value of the method, although, in this particular instance, this should be sufficient for most test scenarios.
        </command>
        <command name="newpage" />
        <command name="section" param="Motivation">
          <command name="label" param="sec:Motivation" />
          <!-- TODO:
          = should I motivate [unit] testing more, like I did in my paper?
          = how about talking about the applicability to code that is currently without tests or with insufficient tests
          -->
          Lest we could somehow perform the practically impossible "complete testing" (in other words, exhaustively trying all possible inputs), testing can only show the presence of defects and not their absence <see cite="dijkstra69structuredprogramming" />.  A good set of automated tests, on the other hand, can catch software regressions that may be introduced through the addition of a feature or the removal of a defect.  Finding - and fixing - regressions as early as possible ensures the fixing cost is minimized <see cite="spolsky00joeltest, patton05softwaretesting" />.  A good set of automated tests is henceforth defined as one that can catch most software regressions.  Meszaros calls this goal "Bug Repellent" <see cite="meszaros07xunitpatterns" />.

          A metric commonly used to represent confidence in a set of automated tests is code coverage percentage, usually in the form of statement coverage <see cite="sink06advocatingcoverage" />.  Code that is covered might be - but is not necessarily - tested, but uncovered code is definitely untested code <see cite="binder00classes" />.  Shipping software with untested code is like serving a dish that has not yet been tasted. <!-- can quote [Rapps+85, 367], which is reprinted in Binder, page 67 -->

          HMS does not just present trouble to tests written by programmers - henceforth referred to as human-generated tests (HGT) - but also to computer-generated tests (CGT), such as those generated through Evolutionary Testing (ET), a form of Search Based Software Testing.  <!-- TODO: does Concolic Testing also suffer from the state problem? -->  Indeed, McMinn reported on the difficulty HMS brought to ET:
          <block param="quote">
            "States can cause a variety of problems for ET, since test goals involving states can be dependent on the entire history of input to the test object, as well as just the current input." <see cite="mcminn03thestate" />
          </block>

          Although it is possible to work around some HMS with a noteworthy "arrange" (or "setup") phase, this is not always desirable as it can increase the maintenance overhead and costs to write the unit tests, both for human- and computer-generated tests.  There are other obvious options available, such as increasing the visibility of the mutable state or converting the state from mutable to read-only.  While it is possible to perform the former without changing the public interface of the IUT, the latter would very likely change the public interface, not to mention the associated risk in performing non-trivial modifications without the safety net of sufficient tests.  Fortunately, there exists an option with better results.

          One perhaps less obvious option is the extraction of a subset of the state<em>ful</em> functionality in the form of a state<em>less</em> method which has all its inputs and outputs available to the test driver, while sourcing those inputs from and outputs to the very instance fields they represent within the implementation itself.  An example of this can be seen in listings <see ref="lst:StatelessSmokeDetector" /> and <see ref="lst:StatelessSmokeDetectorTest" />.  The original implementation of the <tt>Cycle()</tt> method has been trivially extracted into a static overload that accepts all its input and emits all its output through parameters and the method return value<footnote>The <tt>ref</tt> keyword in C# causes the method argument to be passed by reference, such that "any change to the parameter in the method is reflected in the underlying argument variable in the calling method."<see cite="msdn10ref"/></footnote>.  The <tt>AccumulateDetection()</tt> test method can then be written to supply values for all parameters, while keeping the fields that the parameters would be initialized from, safe from modification.  Indeed, the previous test is still there, unchanged, since the <tt>SmokeDetector</tt>'s public interface did not change as a result of performing this transformation.

          <region name="two stateless code listings">
            <listing label="lst:StatelessSmokeDetector" style="realCode" file="Stateless/SmokeDetector.cs">
              C# showing the <tt>SmokeDetector</tt> class with the static <tt>Cycle()</tt> method overload extracted
            </listing>
            <listing label="lst:StatelessSmokeDetectorTest" style="realCode" file="Stateless/SmokeDetectorTest.cs">
              C# showing the test class for <tt>SmokeDetector</tt> exploiting the new <tt>Cycle()</tt> method overload
            </listing>
          </region>
          
          If we could overcome the unit testing obstacles brought on by HMS, we would be able to write more and better tests, thus enhancing our ability for catching regressions as our software projects evolve and saving time and effort.
        </command>
        <command name="newpage" />
        <command name="section" param="Goal">
          <command name="label" param="sec:Goal" />
          <!-- Can address only part of the problem
          Something abstract/general, such as "world hunger", or a subset of it "hunger in Ottawa"
          Can be written retroactively, after the results have been written -->
          If we are to overcome the difficulties of HMS, can we do so with minimal changes to the public interface and with minimal risk of introducing regressions?  Can the unit tests be kept parsimonious, yet cover all the important edge cases?  Is there something we can do to make code containing hidden mutable state more easily testable?

          The goal of this thesis is to improve the testability of classes that suffer from the "state problem" - because they contain HMS - while increasing the maintainability of the accompanying tests, as well as minimally affecting the functionality and the public interface of the code under test.  The goal is to be validated according to the following metrics:

          <block param="enumerate">
            <command name="item"> Complexity of the unit tests.
            <!--
- Applying the Single Responsibility Principle (from SOLID) leads to extracting small methods
- stateless methods are referentially transparent
- "Why Functional Programming Matters" argues "We conclude that since modularity is the key to successful programming, functional programming offers important advantages for software development."
- what if I show there are no changes to any of the common metrics when SME is used?  That would count as "no worse than before"
- if the MUT is "testable", the test will be small (low number of statements)
- LOC seems to be bad when evaluating benchmarks and baselines and comparing against other languages (i.e. Jones' business), but otherwise OK
- I could present the results with the appropriate caveats (i.e. less logical SLOC per unit test method means simpler tests, but it also means entirely different tests; tests that simply were not possible before.  For example, before, the test would have been monolithic, whereas now there could be three small, focused tests that perform the same work)
- unless I have a source that says smaller methods are better/make better tests, etc., I don't have much to go by for size of unit tests
- many of my examples have been too conveniently transformable; there's lots of code I encounter that would be more difficult to test and SME wouldn't help - there's something more complicated needed, such as extracting a new class (single responsibility principle)
- Binder, chapter 13, talks about "Bottom-up Integration" which reads "Components with the least number of dependencies are tested first.  When these components pass, their drivers are replaced with their clients; another round of testing then begins."
- Binder, chapter 19 has "Test Case/Test Suite Method" which describes a lot of xUnit.
- Binder page 69 talks about defect density relative to number of code changes
            -->
            </command>
            <command name="item"> Number of changes to the public interface of the class under test.</command>
            <command name="item"> Percentage of branches covered using concolic testing <see cite="lakhotia10empiricalinvestigation" />.
            <!-- TODO: can maintainability be measured? -->
            <!-- TODO:
            = can I measure the risk of introducing defects or regressions?
            = in other words, what is the safety of the testability transformation/refactoring?
            -->
            </command>
          </block>
          <!--
          = even though I mention ET in the motivation section, I have no goal to evaluate anything for ET???
          = is there a mention of instance state (i.e. HMS) being a problem for Pex or concolic testing in general?
          == my experiments with Pex were designed to have it be the objective evaluator, such that if Pex is unable to create an instance of a class, it is unlikely a human will have an easy time.  This is mostly for the case where a class has no constructor and no easy factory method.
          == Pex is documented as handling ALL state with the help of a shadow interpreter
          == "But then Pex may not know how to create an object through the publicly available constructors such that the object's private fields are in the desired state." (Pex)
          == "If the class is visible and has a visible default constructor, Pex can create an instance of the class. If all the fields are visible, it can generate values for them as well. However, if the fields are encapsulated with properties or not exposed to the outside world, Pex requires help to create the object so as to achieve a better code coverage." http://msdn.microsoft.com/en-us/magazine/ee819140.aspx
          ==
          """
          Warning: field xxx is not public; Pex needs help to construct object (or similar)

Pex generates test inputs, and part of the inputs may be objects with fields. Here, Pex wants to generate an instance of an object which has a private field, and Pex believes that an interesting program behavior will occur when this private field has a particular value. However, while possible with Reflection, Pex does not dare to manufacture objects with arbitrary field values. Instead, in those cases it relies on the user to provide hints how to use the public methods of a class to create an object and bring it into a state where its private field has the desired value.
          """
http://research.microsoft.com/en-us/um/redmond/projects/pex/wiki/pex%20needs%20help%20to%20construct%20object.html
          === I should be able to find instances where Pex can not
          -->
        </command>
        <command name="section" param="Objectives">
          <command name="label" param="sec:Objectives" />
          <!-- (what you will produce to meet your goal)
          action items to address goal -->
          To fulfill the general goal of improving testability of HMS-afflicted code, we have the following objectives:
          
          <block param="enumerate">
            <command name="item"> Design and describe a testability refactoring <see cite="harman11refactoringtestability" /> called "stateless method extraction" (SME).

            The SME technique would transform the source code of the implementation under test (IUT) to introduce a functional, or "externally state-free", software layer to specifically work around many of the testability problems of HMS and to generally increase the testability of the code under test.  This technique will be applied manually by the author, although it should be possible to automate it.
            </command>
            <command name="item"> Design and implement an automated evaluation.

            The evaluation will measure the three metrics of the goal on 4 competing strategies (including SME), using 3 open-source projects.
            </command>
            <command name="item"> Implement the Public Interface Comparer tool.
            
            As a suitable tool to enumerate the changes in public interface between two versions of a .NET project output could not be found, one will be written.
            </command>
            <command name="item"> Independently apply testability refactorings on the open-source projects.

            SME and 2 other testability refactorings will be applied to evaluate their relative effectivenesses.
            </command>
            <command name="item"> Run the evaluation and collect the results for comparison and discussion.</command>
          </block>
        </command>
        <command name="section" param="Outline">
          The remainder of the thesis is organized as follows:  chapter <see ref="chapter:Background" /> introduces the problem domain, describes related concepts, related work and concludes with how the work fits in context.  Chapter <see ref="chapter:Approach" /> covers the design, suitability and applicability of the proposed testability refactoring, including examples.  Chapter <see ref="chapter:ResultsValidation" /> introduces a mechanism by which to evaluate the proposed testability refactoring, followed by the results of the evaluation and their correlation to the goal.  The document ends with chapter <see ref="chapter:Conclusion" /> where the work is summarized, the results discussed and further work is proposed.
        </command>
        <command name="section" param="Summary">
          <!-- key points of what was presented and linkage to next chapter -->
          In this chapter, we introduced the state problem, the specific difficulties related to hidden mutable state and our approach as a possible solution.  We also described the three metrics we will be using to evaluate our approach along with specific objectives for the design of the approach and its evaluation.  We concluded with an overview of the rest of this thesis.
        </command>
      </command>
      <command name="chapter" param="Background">
        <command name="label" param="chapter:Background" />
        <command name="section" param="Introduction">
          This chapter presents an overview of the related concepts from object-oriented (OO) programming to automated testing to computer-generated tests, introduces related work, establishes context within that work and defines the scope of the thesis.
        </command>
        <command name="section" param="Object Oriented Programming">
          This thesis focuses on testing programs written with OO languages - as opposed to procedural or functional languages - because the intent is to solve a problem specific to OO languages:  hidden mutable state.  Although procedural languages (such as C) allow programs to have mutable state, the state is not usually hidden.  Functional languages (such as Lisp) on the other hand, only allow programs to be written using immutable state through the use of set-once variables.  Pure procedural and functional languages are therefore excluded from consideration.

          <command name="subsection" param="Terminology">
            OO languages will generally have a basic set of features, the most important of which are described here for clarity:
            <block param="description">
              <command name="item" opt="class"> The definition for an object.</command>
              <command name="item" opt="instance"> A run-time manifestation of a class, each of which has its own scope.</command>
              <command name="item" opt="static"> A scope for the definition of a class.</command>
              <command name="item" opt="field"> A variable associated with a class (static field) or with an instance (instance field).</command>
              <command name="item" opt="method"> A set of operations attached to a class (static method) or to an instance (instance method).</command>
              <command name="item" opt="constructor"> A special method that is called when an instance of a class is created.</command>
              <command name="item" opt="factory method"> A method whose purpose is to create instances of a class, but not necessarily an instance of the class on which it is found.</command>
              <command name="item" opt="overload"> Two (or more) methods that have the same name, but different parameter numbers or types are said to be <em>overloads</em> of the same method.</command>
              <command name="item" opt="interface"> A contract (usually in the form of a list of methods) for classes to implement which enables their instances to be interchangeable with other implementations of the interface.</command>
              <command name="item" opt="property"> A method whose purpose is to allow the reading or reading and writing of a field's value.  Some languages support this directly while others offer a convention of "getter" and "setter" methods, instead.</command>
              <!-- TODO: encapsulation? -->
            </block>
          </command>
        </command>
        <command name="section" param="Automated Testing">
          A proper introduction to automated testing, especially as it pertains to OO programs, would fill a book and indeed it has.  The reader is encouraged to consult <em>Testing Object-Oriented Systems</em> by Robert V. Binder <see cite="binder00testharness" /> for details beyond this chapter's overview.

          Generally, a test is said to be automated if there exists a program that can: start the IUT or a subset thereof, initialize some suitable inputs for the scenario to be verified, provide these inputs to the IUT and then verify the resulting output, without any intervening assistance.
          <command name="subsection" param="Testing frameworks">
            Automated testing frameworks provide developers with the ability to write and organize test scenarios, execute them sequentially and independently from one another and finally report on their successes.

            This thesis focuses on testing frameworks <see cite="beck99simplesmalltalk" /> that allow the test development environment to be identical to the implementation development environment, collectively called XUnit <see cite="fowler06xunit" />.  A single test scenario can be implemented as a <em>test method</em> in a <em>test class</em>, exercising functionality in the method under test (MUT) in another class, the class under test (CUT).  A collection of test classes is known as a <em>test suite</em>.

            Test methods will generally have at least three phases: arrange, act and assert (Meszaros calls them <em>setup</em>, <em>exercise</em> and <em>verify</em>, plus adds <em>teardown</em> <see cite="meszaros07xunitpatterns" />).  The functionality in a test method is not always separated as such and might instead be intermixed or even be located elsewhere in the test class.  The <em>arrange</em> phase concerns itself with preparing the CUT and/or the environment, effectively setting the indirect inputs for the MUT and optionally initializing complex direct inputs.  The <em>act</em> phase contains code that calls the MUT with its direct inputs and collects the direct outputs, if any.  The <em>assert</em> phase derives any indirect outputs, if any, and verifies the <em>actual</em> outputs against the <em>expected</em> outputs.  The optional fourth phase consists of cleaning up the environment, as necessary.

            The terms <em>test inputs</em> and <em>test outputs</em> will henceforth be used to refer to both their direct and indirect sets.  It is worth noting that because exhaustive testing is not feasible, test suites will usually contain scenarios that sample only a fraction of the possible input space.  In those cases, the test inputs will have been selected to represent typical use, boundary conditions and other potential areas for defects.  Such classes of values for the test inputs earns them the "interesting and relevant" designation.
          </command>
          <command name="subsection" param="Test scope">
            As alluded to in the previous sub-section, this thesis concerns itself with automated testing, at the lowest level, by focusing the test scenarios on methods, which is also known as <em>unit testing</em>.  This is in contrast to <em>integration testing</em> which concerns itself with the interaction between a class and another class and/or some external environment such as a file system or a network, and <em>subsystem testing</em> which involves observing the interaction between a class and several other classes and/or external components such as a database or a web service.
          </command>
          <command name="subsection" param="Code coverage">
            An IUT can be automatically <em>instrumented</em> to record which statements and expressions (collectively known as <em>sequence points</em>) are executed - or <em>visited</em> - during an automated test run.  The resulting report is known as <em>statement coverage</em> and will usually correlate its results with the original source code by highlighting the statements and expressions that were executed  <see cite="binder00classes" />.  This report will also include enough data to determine the coverage percentage, which is computed as <em>visited sequence points</em> (VSP) divided by <em>total sequence points</em> (TSP).  The report usually aggregates this information at the method, class, namespace and program levels <see cite="sink06advocatingcoverage" />.

            Code coverage can be used to determine the completeness of the test suite or, more precisely, to identify areas of the IUT that are untouched by the tests.  The presence of uncovered code can also reveal surprises in the implementation, although its best use remains the identification of missing test scenarios.
          </command>
        </command>
        <command name="section" param="Motivation for Computer-Generated Tests">
          It may not always be possible or feasible to have a programmer write automated tests for a component or an implementation.  Reasons provided by Bühler and Wegener <see cite="buehler08evolutionaryfunctional" /> include the simultaneous satisfaction of functional, real-time and safety requirements as well as the very large test space resulting from the interaction of 50-70 independently-developed embedded systems.  The nature of the assembled system - in this case a premium vehicle - also makes manual testing, such as driving the vehicle in an environment suitable for each scenario, prohibitively expensive.  Bühler and Wegener go on to suggest generating tests automatically to work around these obstacles and thus reduce costs.  Evolutionary testing (ET), "the application of evolutionary computation to test automation" <see cite="buehler08evolutionaryfunctional" />, is therefore suggested to automatically and efficiently sample the test input space.  ET will usually be implemented using genetic algorithms (GA), which are well-suited to a mix of exploration and exploitation in the search space <see cite="mcminn04searchbased" />.

          Binder writes:
          <block param="quote">
            "Automatic test generation can be used without having to pregenerate expected results.  Although generating input values automatically is easy, generating the corresponding expected results automatically is usually difficult." <see cite="binder00assertions" />
          </block>
          Even if tests are automatically generated without the use of an oracle (human or otherwise), the generated test suite can still serve as a baseline and could be used to detect changes in the outputs as a result of adding features or fixing defects.  These changes in the outputs could indicate a regression, just as changes in the outputs of human-generated tests would.

          In the present case, there's an additional reason computer-generated tests are interesting:  we can use an automatic structural test generator to objectively compare the testability of source code under various transformations.

          More details about the various flavours and uses of computer-generated tests are provided in the following sections.
        </command>
        <command name="section" param="Approaches to Computer-Generated Tests">
          There are three major approaches in generating tests:  Random Testing, Search Based Software Testing and Concolic Testing <see cite="lakhotia10empiricalinvestigation" /> are described in the following sections.
          <command name="subsection" param="Random Testing">
            Random testing (RT), as the name implies, consists of generating inputs based on random numbers and is thus undirected.  RT does not perform as well as ET <see cite="wegener01evolutionarytest" />, although it has been used as a baseline for comparing other test generators <see cite="lakhotia10empiricalinvestigation" />.
          </command>
          <command name="subsection" param="Search Based Software Testing">
            Search-based software testing (SBST) is the application of a metaheuristic search technique (MST) to the problem of generating test inputs <see cite="mcminn04searchbased" />.  The technique is based around optimization of an <em>objective function</em>, trying to improve an initial solution based on feedback by said objective function - either by maximizing or minimizing its value, depending on the desired outcome - effectively making it a guided quest for global optima in the search space.

            For test input generation, the search space is the domain of the test inputs and the objective function is carefully constructed to reward interesting and relevant test inputs.  The nature of "interesting and relevant" depends on the <em>intent</em> of the testing exercise.  In general, the biggest difficulty of SBST lies in the definition of the objective function <see cite="baresel02fitnessfunction" />.  Consult the following section for the major intents of SBST.

            The general flow of MST implementations is to start with one or more "initial solutions", created either with domain knowledge or at random, and apply the objective function on the solution(s) to establish a solution score.  If no solution score exceeds a pre-defined threshold, tweak the solution(s) according to some heuristic and repeat the process with the new solution(s) until either no improvement in score is detected or some pre-defined time or iteration threshold is reached.

            The simplest heuristic is called "hill climbing", a strategy that focuses on the best objective function value in the neighbourhood of the current solution's search space.  This greedy, exploit-only strategy will often cause a hill climber to get stuck in local optima.

            An improvement to hill climbing was proposed in the "simulated annealing" heuristic whereby solutions with worse objective function values will be considered with a probability decreasing with the number of iterations, allowing more of the search space to be explored in the beginning and ending with a hill climber-like exploitation.

            One of the better MST heuristics is "genetic algorithms (GA)", a class of "evolutionary algorithms".  It is designed to simulate the process of natural selection (sometimes known as "survival of the fittest") by modelling a <em>population</em> of solutions as chromosomes and providing ways for pairs of solutions to "breed" through recombination (splicing part of one parent with part of the other and also combining the remaining two parts), providing the next generation of solutions.  The simulation is made more authentic through the use of mutations (random, low-probability alterations to the chromosome) and various reproduction selection mechanisms, such as fitness-proportional selection and tournament selection.  Through this simulation, solutions will appear to evolve across the generations and, given appropriately-tuned parameters, the population of solutions will be diverse and "fit", thus providing a good balance of exploration and exploitation of the search space.
          </command>
          <command name="subsection" param="Concolic Testing">
            Concolic testing (CT) is the combination of concrete and symbolic execution applied to the problem of test data generation.  It is also known as dynamic symbolic execution <see cite="mcminn04searchbased" />.

            Symbolic execution (SE) is a simulated execution of a given path through the program using symbols in place of input values, and keeping track of expressions instead of concrete values as assignments and operations take place <see cite="king76symbolicexecution" />.  For a program operating exclusively with integers, one could say SE is the algebraic equivalent of the arithmetic operations that would be evaluated with concrete execution.  The resulting output of SE is generally a system of constraints on the inputs for executing the given path.

            Concrete execution - running an instrumented version of the program - can be combined with SE such that the two executions are correlated to verify the generated constraints against concrete values.  Often times, this correlation allows the simplification of these constraints, for example by removing non-linear sub-expressions <see cite="mcminn04searchbased" />.  A constraint solver can then be used to find test input values that cause the execution of specific paths through the IUT <see cite="tillman08pex" />.
          </command>
        </command>
        <command name="section" param="Intents of Computer-Generated Tests">
          There are four major uses for Computer-Generated Tests (CGT) described in the following sub-sections.  They differ mostly in the choice of executable statements to target and are not usually specific to any CGT approach in particular.  The exception is non-functional testing, which does not target any executable statement in particular and is more suited to an optimization approach (such as SBST).
          <command name="subsection" param="Structural Testing Intent">
            Coupling an automated test generator with a code coverage tool makes it possible to discover which inputs can be used to reach otherwise hard-to-cover areas as well as areas of the code where no inputs can be found to reach them (within a pre-defined search time).  This could indicate that the code is unreachable because it contains, for example, conflicting pre-conditions.  Structural testing will generally attempt to execute all statements of an IUT at least once.
          </command>
          <command name="subsection" param="Functional Testing Intent">
            Functional testing is a form of verification that uses a machine-readable form of the specification <see cite="mcminn04searchbased" />.  One way of doing so is with a formal specification expressed as disjunctions that represent <em>routes</em> (or paths) through the program.  These routes can then be tested individually using structural testing.

            An easier approach is to automatically turn the specification into pre-conditions and post-conditions.  The objective is then to find test inputs that conform to all pre-conditions but that cause post-conditions to fail, in effect targeting the fault branch of the post-conditions.

            A third approach is to encode the specification's requirements as a component of a simulator.  For example, Bühler and Wegener evaluated the functionality of a brake assist system using a simulator <see cite="buehler08evolutionaryfunctional" />.  The simulator would report if the safety requirements were violated by the brake assist system, such as instances where the system either did not enhance the driver's brake torque in a critical situation or provided too much braking in a non-critical situation.
          </command>
          <command name="subsection" param="Grey-Box Testing Intent">
            The objectives of grey-box testing are to attempt to get assertions, already embedded in a program, to be violated and to trigger exception conditions.  Some of this work even temporarily turned specially-formatted comments into executable assertions for the purposes of targeting their fault branches for execution <see cite="mcminn04searchbased" />.
          </command>
          <command name="subsection" param="Non-Functional Testing Intent">
            Non-functional testing concerns itself with verifying non-functional requirements, such as constraints on execution time, working memory, long-term storage and processor load, usually for embedded and real-time systems.  Test inputs are sought which cause the program to exceed pre-defined thresholds, such as taking more time than usual or consuming more memory than expected.  This can be measured by instrumentation external to the IUT, such as the operating system's timers and counters, or by using a simulator <see cite="sthamer02usingevolutionary" />.
          </command>
        </command>
        <command name="section" param="Related Work">
          The following sub-sections are introduced by quotes relevant to their topic.
          <command name="subsection" param="The State Problem">
            <block param="quote">
              "Side-effects, by which I mean changes to the values stored in fields of objects or elements of arrays, are clearly intended to be used frequently in Java. However, the presence of side-effects can make it harder to reason about a program, because there is invisble [sic] state to the side of computations which changes. That means a reader needs to keep track of both the visible aspects of a program and the hidden values off to the side that may change." <see cite="haahr99programmingstyle" />

              "Although encapsulation does not directly contribute to the occurrence of bugs, it can present an obstacle to testing.  Testing requires accurate reporting of the concrete and abstract states of an object and the ability to set state easily.  Object-oriented languages make it difficult - if not impossible - to directly set or get the concrete state." <see cite="binder00withnecessary" />
            </block>
            McMinn identified the "State Problem" in the context of evolutionary testing and described a few possible solutions that enhanced the ET system to compensate for problems brought on by state <see cite="mcminn03thestate" />.  Difficulties with internal state are also mentioned by Bühler and Wegener <see cite="buehler08evolutionaryfunctional" />, Harman et al. <see cite="harman09aop" />, Tillman and de Halleux <see cite="tillman08pex" /> and Baresel et al. <see cite="baresel02fitnessfunction" />.

            Difficulties associated with internal state can be reduced or worked around with better analysis, such as data dependency analysis <see cite="korel05datadependence" />.  Since said analysis can often be time-consuming, techniques such as program slicing <see cite="tip95surveyslicing" /> were developed to help reduce the search space.  McMinn went on to develop a technique that enhances the search to look for method call sequences and combines the chaining approach with evolutionary search <see cite="mcminn05evolutionarysearch" />.

            Another approach to generate tests for programs with state - specifically those written in OO programming languages - was proposed by Wappler and Wegener <see cite="wappler06evolutionaryunit" />.  Their two-phase technique, called "strongly-typed genetic programming", consists of first using genetic programming to generate a sequence of methods to call (creating instances of classes as necessary), then using a genetic algorithm to find suitable values for the parameters of the generated method calls.
            
            Binder suggests four approaches to work around a programming language's visibility constraints: "Private Access Driver", "Test Control Interface", "Drone" and "Built-in Test Driver"  <see cite="binder00testharness" />.
            <!-- TODO: discuss Microsoft's PrivateObject -->
          </command>
          <command name="subsection" param="The Case for Functional Programming">
            <block param="quote">
             "However, the functional style is also perfectly adapted to incremental testing:  programs written in this style can also be <em>tested</em> one function at a time.  When a function neither examines nor alters external state, any bugs will appear immediately. Such a function can affect the outside world only through its return values. Insofar as these are what you expected, you can trust the code which produced them." <see cite="graham93onlisp" />
            </block>
            "Imperative functional programming" is promoted by Reddy <see cite="reddy96imperativefunctional" /> and appears to push the idea of a <em>public</em> functional programming interface built on top of imperative features.  This is in contrast to the present thesis, which would see an <em>internal</em> functional programming interface (built on top of imperative features) as a building block for a possibly pre-existing object-oriented interface.

            Van-Roy and Haridi support the spirit of our approach, declaring "We find that a good rule of thumb for complex systems is to keep as many components as possible declarative.  State should not be 'smeared out' over many components.  It should be concentrated in just a few carefully selected components." <see cite="vanroy04conceptstechniques" />  Support is also provided by Wampler: "Side-effect-free functions make excellent building blocks for reuse, since they don't depend on the context in which they run. Compared to functions with side effects, they are also easier to design, comprehend, optimize, and test." <see cite="wampler11functionalprogramming" />

            Hevery, on the other hand, appears to disagree with our approach <see cite="hevery08staticmethods" /> and argues for a pure object-oriented approach <see cite="hevery09thinkoo" />.  Haahr nevertheless argues for "referential transparency" <see cite="haahr99programmingstyle" /> to not only make computations easier to understand but also easier to parallelise.
          </command>
          <command name="subsection" param="The Case for Testability Transformations">
            <block param="quote">
              "It could be said that the algorithm for side-effect removal creates an `almost functional' language, in which all state changes are expressed using the assignment statement. This would return the programming paradigm to that considered by the initial work on the Axiomatic Method, where axiomatic semantics is comparatively elegant and easy to define and use. This, perhaps, provides further additional anecdotal evidence that side-effects are hard to reason about and that their removal is worthwhile for comprehension." <see cite="harman01sideeffect" />
            </block>
            Because programs are not always easily testable as written, it has been suggested by Harman et al. to automatically create an alternate (and temporary) version of the program that is easier to analyze or test by applying some transformations <see cite="harman04testabilitytransformation" />.  These transformations can be as simple as "flag removal"; the inline expansion of a boolean variable with its underlying expression <see cite="harman02improvingevolutionary" />.  Another example would be the removal of expressions with side-effects <see cite="harman01sideeffect" />.

            The general idea of testability transformation was further developed by Korel et al. <see cite="korel05datadependence" /> as well as McMinn et al. <see cite="mcminn08empiricalevaluation" />, among others.  Program slicing could also be considered a testability transformation <see cite="harman09aop" />.  Harman eventually goes one step further and suggests "testability refactoring": a permanent program transformation that has the simultaneous goals of making the program easier to test and better (or at least no worse) for the programmer <see cite="harman11refactoringtestability" />.
          </command>
          <command name="subsection" param="The Case for Simplicity">
            <block param="quote">
              "A low cyclomatic complexity generally indicates a method that is easy to understand, test, and maintain." <see cite="msdn10avoidcomplexity" />
            </block>
            McCabe introduced the concept of "cyclomatic complexity" with the intention of evaluating the difficulty involved when testing programs based on their structure <see cite="mccabe76complexitymeasure" />.  Indeed, McCabe even discussed the possibility of reducing a program's structure to reduce the testing effort, with the intent of writing software that is both testable and maintainable.  Basili et al. <see cite="basili96oodmetrics" /> showed that the <em>Response For a Class (RFC)</em> metric<footnote>RFC is defined as "The number of methods that can potentially be executed in response to a message received."</footnote> is correlated to the probability of finding faults for a class, suggesting smaller methods will be less likely to have defects.

            Hevery created the Testability Explorer tool to compute the "Non-Mockable Total Recursive Cyclomatic Complexity" metric, compute the "Demeter" metric as well as count the number of global mutable fields in Java programs <see cite="hevery08testabilityexplorer" />.  The first metric is an evolution of McCabe's metric for OO programs while the other two metrics also help to reduce the testing effort through smaller call chains (Demeter) and less "spooky action at a distance" (surprise side-effects) by reducing the use of mutable global fields <see cite="hevery08flawbrittle" />.  Hevery's technique of choice for increasing testability is the addition of "test seams" <see cite="hevery08staticmethods" />.
          </command>
        </command>
        <command name="section" param="Scope">
          <!-- 
          We are not comparing test-generation systems (such as Random, SBST and Concolic Testing), we are comparing techniques humans would use to work around HMS when testing classes that have it.  Pex is only used to see if what we are doing is helping.
          We are not interested in any particular intent described in that section, since that applies only to CGT.
          Should we "score" the approaches by the cases in the related work section?  How does each approach help towards functional programming, towards transforming the IUT for testability purposes (which I guess we already have) and if the approach helps to improve simplicity of IUT or corresponding unit tests.
          -->
          The thesis focuses on addressing the glass-box unit testing difficulties introduced by hidden mutable state, in the context of object-oriented software, through the use of stateless method extraction.  In other words, the implementation under test is available for inspection as tests are written on a per-method basis for classes that contain private instance fields whose values are altered by calls to instance methods.

          Considerations outside the scope of this thesis therefore include:
          <block param="itemize">
            <command name="item"> Opaque-box testing</command>
            <command name="item"> Integration (or other high-level) testing</command>
            <command name="item"> Non-object-oriented software</command>
          </block>

          Additional considerations outside the scope of this thesis include:
          <block param="itemize">
            <command name="item"> Testing of hidden state mutations.  These must still be tested, but those tests are not covered by this thesis.</command>
            <command name="item"> Run-time performance of IUT or unit tests</command>
            <command name="item"> Performance of SBST (such as ET) on IUT</command>
            <!-- Is the last one really reasonable since the basis of this thesis was the ET-related "state problem"?  Shouldn't I be able to show some progress on that front? -->
          </block>

          Stateless method extraction is to be compared against 3 other strategies for unit testing OO software containing hidden mutable state;  table <see ref="tbl:ScopeTable" /> describes precisely the strategies covered.

          <table placement="htbp">
            <tabular spec="l | >{\centering}m{2cm} >{\centering}m{2cm} | >{\centering}m{2cm}">
              <tr><td /><td multicolumn="{2}{c|}">Known effects</td><td /></tr>
              <tr><td multicolumn="{1}{c|}">Strategies</td><td>Affects IUT or tests</td><td>Affects public interface</td><td>Covered</td></tr>
              <command name="hline" />
              <tr><td>Do nothing</td><td>neither</td><td>N</td><td>Y</td></tr>
              <tr><td>Stateless method extraction</td><td>IUT</td><td>N</td><td>Y</td></tr>
              <tr><td>Making mutable state visible</td><td>IUT</td><td>N</td><td>Y</td></tr>
              <tr><td>Making state and methods visible</td><td>IUT</td><td>N</td><td>Y</td></tr>
              <tr><td>Making hidden state immutable</td><td>IUT</td><td>Y</td><td>N</td></tr>
              <tr><td>Extracting test helper methods</td><td>tests</td><td>N</td><td>N</td></tr>
              <tr><td> "Private Access Driver"</td><td>IUT</td><td>N</td><td>N</td></tr>
              <tr><td> "Test Control Interface"</td><td>both</td><td>N</td><td>N</td></tr>
              <tr><td> "Drone"</td><td>tests</td><td>N</td><td>N</td></tr>
              <tr><td> "Built-in Test Driver"</td><td>both</td><td>N</td><td>N</td></tr>
              <tr><td>Adding "test seams"</td><td>IUT</td><td>Y</td><td>N</td></tr>
            </tabular>
            <command name="caption" param="A matrix of known strategies designed to improve testability, their known effects and whether they are covered by this thesis." />
            <command name="label" param="tbl:ScopeTable" />
          </table>
          <!--
TODO: what about simply refactoring so that processing is taking place closer to the objects involved?  For example, instead of computing the great-circle distance in a method of the FlyingSalespersonProblem class, have it be an instance method on LatLon: GreatCircleDistance(LatLon destination), which might also allow LatLon to keep a cache of the Sin() and Cos() of the radian version of Lat (as well as the radian version of Lon) for further performance.  There probably is more risk involved when moving the functionality like that, although the risk would most likely be proportional to the test coverage (as it would be in general).

          = contrast with test helper methods
          == For example, DeepZoomImageTest.TestComputeLevelSize() that creates two instances per call:
          Assert.AreEqual (new Size (1200, 1500), TestComputeLevelSize (PortraitImageSize, 12));
          vs. the original stateless method that could be called directly:
          Assert.AreEqual (new Size (1200, 1500), DeepZoomImage.ComputeLevelSize (PortraitImageSize, 12));
          === For that particular one, because my settings class performs work in the constructor, there are some properties which MUST be provided.
          == how about test helper properties?
          == they shift complexity instead of removing it altogether.  I need to find some way to prove that this leads to more brittle tests.  Perhaps the fact that the stateless method is reusable vs. the test helper method is not?
          = constrast with factory methods:
          """
          As an alternative to employing only existing constructors to configure objects,
the user may also provide factory methods, which could invoke a sequence of
method calls to construct and configure a new object, possibly creating cyclic
references as well.
          """ Pex, last paragraph of section 3.4
          -->
        </command>
        <command name="section" param="Summary">
          <!-- key points of what was presented and linkage to next chapter -->
          This chapter introduced the reader to representative terminology and domain concepts before describing more advanced concepts, related work and finally how the thesis fits into the existing research.
        </command>
      </command>
      <command name="chapter" param="Approach">
        <command name="label" param="chapter:Approach" />
        <command name="section" param="Introduction">
          <!-- what the chapter is about -->
          This chapter describes our approach to improving the testability of classes that suffer from the state problem.  Our approach takes the form of our SME testability refactoring and we describe several examples of its use, followed by discussions on when SME can be used as well as how.  We conclude with a discussion of important decisions made.
        </command>
        <command name="section" param="Design">
          <command name="label" param="sec:Design" />
          Stateless method extraction's intent is to separate the interaction between the hidden mutable state in a class and the inputs and outputs of said class' instance methods.  This decoupling allows programmers to first focus their unit tests on the pure computation aspects, then on the object-oriented layer above the stateless methods.

          It is important to note that SME relies on the fact that all its steps will only modify the source code in ways that will not alter any of the behaviours and functionality present before SME was performed.  That is to say, all the operations performed should be pure refactorings <see cite="fowler00refactoring" /> and no functionality changes are to be performed during the process.  These rules help ensure the use of SME is invisible to end-users and has the least chance of introducing defects or regressions in the affected methods.

          <command name="subsection" param="Overview">
            Stateless method extraction is performed in six high-level steps:
            <block param="enumerate">
              <command name="item"> Identification of a candidate block.
                <br />
                A "candidate block" is a functionality subset of an instance method that looks promising to turn into a stateless method.
              </command>
              <command name="item"> Re-ordering of incidental operations.
                <br />
                On some occasions, it may be necessary to move some statements out of the candidate block that are not relevant to the functionality subset and/or whose ordering is not critical (such as logging).
              </command>
              <command name="item"> Assignment of inputs and outputs to local variables.
                <br />
                Identify the new method's input and output parameters, then create local variables for them.
              </command>
              <command name="item"> Simplification of inputs.
                <br />
                Optimize the input parameters to be native or built-in types.
              </command>
              <command name="item"> Extraction of the candidate block into a method.
                <br />
                The candidate block should now be easily converted into a stateless method.
              </command>
              <command name="item"> Re-inline any variables created to facilitate a refactor.
                <br />
                This reverses the actions of step #3 so the refactor has as little impact on the original code as possible and only contains the necessary changes.
              </command>
            </block>
            Listing <see ref="lst:Procedure" /> shows a pseudo-code version of the stateless method extraction procedure.  The following sub-sections will cover the individual steps in greater detail.
            <!-- TODO: should this be an "algorithmic" block, instead? -->
            <listing label="lst:Procedure" style="pseudoCode" file="Procedure.pc" placement="t">
              Pseudo-code showing the general procedure for extracting stateless methods
            </listing>
          </command>
          <command name="newpage" />
          <command name="subsection" param="Step 1: Identification of a Candidate Block">
            <command name="label" param="subsec:Step1" />
            The first step of SME consists of identifying, in an instance method, one or more functionality subsets that would be good candidates for extraction and subsequent unit testing.  That is to say, it is not necessary to extract the entire body of an instance method if there are parts of the method that would be more suitable to extract and unit test separately.  It is also possible a method will contain no candidate blocks to extract; the technique need not be forcibly applied if no unit testing advantages can be realized.

            The criteria for establishing candidacy of a block consist of:
            <block param="enumerate">
              <command name="item"> A continuous set of stateless statements.
                <br />
                Stateless statements are defined as depending directly on their inputs and without side-effects.  Statements that interpret input parameters to interact with the environment (such as reading/writing files and sending/receiving network traffic) are not considered stateless.  Statements may produce effects (such as assignment and return values) but may not cause other values to change as a result of execution (such as modifying HMS), as this would defeat the purpose.  Section <see ref="subsec:Step2" /> describes how to deal with non-stateless statements.
              </command>
              <command name="item"> Inputs (local variables, fields and/or method parameters): at least 1, but no more than 6.</command>
              <command name="item"> Outputs (local variables, fields and/or return values): at least 1, but no more than 3.  At least one non-trivial result must be produced by processing the input(s).
              </command>
            </block>
            Categories of interesting candidate blocks include:
            <block param="itemize">
              <command name="item"> Implementations of mathematical formulas.
                <br />
                For example, converting from degrees to radians or computing the great circle distance (the shortest path between two points on a sphere), both of which are shown being performed inline in listing <see ref="lst:StatefulFlyingSalesPerson" />, while they have been respectively extracted into the <tt>ToRadians()</tt> and <tt>CalculateGreatCircleDistance()</tt> methods in listing <see ref="lst:StatelessComputeTourLength" />.
              </command>
              <command name="item"> Processing of a single element where such processing currently takes place while looping through a sequence of elements.
                <br />
                For a before-after example, refer to listings <see ref="lst:StatefulGenerateXml" /> and <see ref="lst:StatelessGenerateXml" />.
              </command>
              <command name="item"> String parsing, especially when using a regular expression.
                This allows the parsing to be separated from the use of its results, so that the parsing and the subsequent computations can be tested separately.
              </command>
              <command name="item"> Filling in of templates.
                <br />
                This can be considered the reverse of parsing and usually involves combining a few inputs to yield a meaningful construction, such as a string representation of an object.  An example of this category can be found in the <tt>GenerateItemNode()</tt> method extracted in listing <see ref="lst:StatelessGenerateXml" />.  Here an <tt>XElement</tt> instance is created (on line 36) and its attributes initialized from two of the supplied parameters (lines 37 and 38) as well as from a value derived from the last two parameters (line 45).
              </command>
            </block>

            <listing label="lst:StatefulFlyingSalesPerson" style="realCode" linerange="13-58" file="Stateful/FlyingSalespersonProblem.cs">
              C# showing the <tt>ComputeTourLength()</tt> method in the <tt>FlyingSalespersonProblem</tt> class with some inlined mathematical formulas
            </listing>
            <listing label="lst:StatelessComputeTourLength" style="realCode" linerange="36-71" file="Stateless/FlyingSalespersonProblem.cs">
              C# showing the <tt>ComputeTourLength()</tt> method with the <tt>ToRadians()</tt> and <tt>CalculateGreatCircleDistance()</tt> methods that were extracted from it
            </listing>
            
            <region name="two code listings for partial loop block extraction">
              <listing label="lst:StatefulGenerateXml" style="realCode" linerange="40-78" file="Stateful/ImageCollection.cs">
                C# showing the <tt>GenerateXml()</tt> method with a candidate block between lines 19-30
              </listing>
              <listing label="lst:StatelessGenerateXml" style="realCode" linerange="40-87" file="Stateless/ImageCollection.cs">
                C# showing the <tt>GenerateXml()</tt> method with the candidate block extracted as the <tt>GenerateItemNode()</tt> method
              </listing>
            </region>
            It follows that there are uninteresting categories of blocks, such as:
            <block param="itemize">
              <command name="item"> Trivial state changes.
                <br />
                A good example is a <tt>Reset()</tt> method that sets a number of instance fields to a specific set of values, such as constants.  The whole point of such a method is to mutate hidden state and thus there would likely be very little functionality that could be tested in isolation.
              </command>
              <command name="item"> Too many inputs and/or outputs.
                <br />
                This category could be considered a more general case of the previous category, but there are instances where it may not make sense to break up some processing for readability, maintenance or performance reasons.
              </command>
              <command name="item"> Not enough outputs.
                <br />
                An example of a block in this category would be an instance method calling instance methods on its fields in such a way that there are no observable changes to the fields' own hidden mutable state.  Extracting that block would likely provide no unit testing advantage and is thus uninteresting.
              </command>
              <command name="item"> Too many interactions with the environment.
                <br />
                If an instance method consists mostly of interactions with external entities such as a file system or a database, there may be very little functionality left that is stateless that would benefit from extraction and isolated unit testing.
              </command>
            </block>
          </command>
          <command name="subsection" param="Step 2: Re-ordering of Incidental Operations">
            <command name="label" param="subsec:Step2" />
            The second SME step is about finding and, if necessary, moving statements that are either unrelated to a computation or statements that are not stateless (such as those that cause side-effects) out of the candidate block.  This should only take place if the original instance method's functionality will not be adversely affected by the move.  If the functionality would indeed be adversely affected by the re-ordering of unrelated or non-stateless statements, the candidate block should be split such that its new endpoint is just before said unrelated or non-stateless statement.  A subsequent candidate block could be attempted just after the unrelated or non-stateless statement.

            <region name="two code listings for operation re-ordering">
              <listing label="lst:StatefulGenerateXmlIntermixed" style="realCode" linerange="80-118" file="Stateful/ImageCollection.cs">
                C# showing the <tt>GenerateXmlIntermixed()</tt> method with a candidate block between lines 18-33
              </listing>
              <listing label="lst:StatefulGenerateXmlUnmixed" style="realCode" linerange="40-78" file="Stateful/ImageCollection.cs">
                C# showing the <tt>GenerateXml()</tt> method with a shorter candidate block between lines 19-30
              </listing>
            </region>

            An example of unrelated statements can be seen in listing <see ref="lst:StatefulGenerateXmlIntermixed" />, specifically in the candidate block identified between lines 18 and 33.  The majority of the operations in the block concern themselves with the creation and configuration of the <tt>itemNode</tt> instance, while at least 3 of them perform tasks incidental to the <tt>itemNode</tt> configuration:  lines 21, 23 and 25.  Line 20 does augment <tt>itemNode</tt>, but does so with a trivial operation (the <tt>Add()</tt> method call) and so its inclusion in the candidate block could be argued either way.  For the purposes of this example, line 20 will be considered incidental.  The candidate block could be shrunk by re-ordering all the operations identified as incidental without affecting the functionality.  In particular, the <tt>mortonNumber++;</tt> operation on line 23 is only sensitive to ordering insofar as <tt>itemNode.SetAttributeValue("N", mortonNumber);</tt> on line 22 is concerned and thus could be moved down and out of the candidate block.  Lines 20 and 21 depend on one another as well as line 19 (the creation of the <tt>itemNode</tt> instance), but the behaviour would be the same if they appeared at the end of the block (the XML API used in the example guarantees this) and therefore, because they have no advantage being located immediately after the creation of <tt>itemNode</tt>, they can be safely moved out of the candidate block.  The last incidental operation is <tt>maxPostId = Math.Max(maxPostId, postId);</tt> on line 25.  Its only dependency is the <tt>postId</tt> loop variable and thus could be moved up to be the very first operation in the loop.  Listing <see ref="lst:StatefulGenerateXmlUnmixed" /> illustrates the result of re-ordering the lines containing incidental operations and the smaller, simpler candidate block obtained between lines 19 and 30.
            <!-- TODO: can also argue the decision to keep the path manipulation code (fileName and relativeDziSubPath) in the candidate block vs. moving it out.  There's no change in the number of parameters to GenerateItemNode(), but it might make for even smaller/simpler tests that are more focused? -->

            A statement is said to be non-stateless if values or data not explicitly specified by parameters or the return value are modified as a result of execution.  This can be as simple as an instance method modifying hidden mutable state, a method modifying global state or a method interpreting its parameters for interaction with the environment, such as using a string parameter as the name of a file to create or delete, or the name of a database table to read from or write to.  Non-stateless operations will generally be more difficult to re-order because, by definition, they cause or depend on side-effects and standard data dependency analysis will be made difficult because it would have to be aware of private instance field changes.

            An example of a non-stateless method in the middle of a candidate block can be seen at line 15 of listing <see ref="lst:StatefulSubversionClient" />.  The <tt>ExecuteSvn()</tt> method, defined at line 10 of listing <see ref="lst:CommonSubversionClient" />, starts a sub-process and returns the contents of <tt>StandardOutput</tt> and thus is said to interact with the environment, making it definitely non-stateless.  In this particular case, because the call to the <tt>ExecuteSvn()</tt> method depends on the computations immediately above it and provides input needed by the computations immediately below it, it can not be moved before or after the candidate block (lines 7-32).  This causes the original candidate block to be split into parts excluding the immovable, non-stateless method with the first half being lines 7-13 and the second half lines 17-32.  Listing  <see ref="lst:StatelessSubversionClient" /> shows the two stateless methods that were extracted, respectively, from the first and second candidate blocks: <tt>CreateInfoArguments()</tt> and <tt>ParseInfoFromXml()</tt>.

            <listing label="lst:CommonSubversionClient" style="realCode" linerange="6-30" file="Stateful/SubversionClient.cs" placement="p">
              C# showing common code used by listings <see ref="lst:StatefulSubversionClient" /> and <see ref="lst:StatelessSubversionClient" />
            </listing>

            <command name="newpage" />

            <region name="two code listings for candidate block splitting">
              <listing label="lst:StatefulSubversionClient" style="realCode" linerange="32-66" file="Stateful/SubversionClient.cs" placement="t!">
                C# showing the <tt>LoadInfo()</tt> method with a candidate block between lines 7-32
              </listing>

            <command name="newpage" />

              <listing label="lst:StatelessSubversionClient" style="realCode" linerange="32-76" file="Stateless/SubversionClient.cs" placement="t!">
                C# showing the <tt>CreateInfoArguments()</tt> and <tt>ParseInfoFromXml()</tt> stateless methods that were extracted from the <tt>LoadInfo()</tt> method
              </listing>
            </region>

            <command name="newpage" />

            <listing label="lst:StatefulCartesianCoordinate" style="realCode" linerange="3-24" file="Stateful/CartesianCoordinate.cs" placement="t">
              C# showing the <tt>ToPolar()</tt> method with interleaved computations for <tt>r</tt> and <tt>theta</tt>
            </listing>

            It could also be the case that the original instance method is computing several outputs simultaneously and such statements are intermixed.  If the outputs are independently-computed (or their computations share some intermediate results, then diverge), it may be worth investigating the separation of their computations by re-ordering statements such that they can then be extracted, and subsequently unit tested, independently.  An example of intermixed computations can be seen in listing <see ref="lst:StatefulCartesianCoordinate" /> between lines 15 and 19, while another version of the method with the computations separated through re-ordering can be seen in listing <see ref="lst:StatelessCartesianCoordinate" />.

            <listing label="lst:StatelessCartesianCoordinate" style="realCode" linerange="3-24" file="Stateless/CartesianCoordinate.cs" placement="t">
              C# showing the <tt>ToPolar()</tt> method with the computations for <tt>r</tt> and <tt>theta</tt> separated into their own consecutive sequences
            </listing>

            Incidental operation re-ordering can be considered a form of program slicing <see cite="tip95surveyslicing" /> in that data dependency analysis <see cite="korel05datadependence" /> can be used to identify a subset of computations of a method responsible for one of the outputs and isolate them.  Assuming all the discarded operations were stateless, it would be safe to say that the remaining operations can execute one immediately after the other and still produce the same result, the same way lines 15, 17 and 19 in listing <see ref="lst:StatefulCartesianCoordinate" /> are necessary for the computation of <tt>r</tt> and can be re-arranged to be consecutive, as seen in lines 15, 16 and 17 in listing <see ref="lst:StatelessCartesianCoordinate" />.
          </command>
          <command name="subsection" param="Step 3: Assignment of Inputs and Outputs to Local Variables">
            <command name="label" param="subsec:Step3" />
            The third step concerns the temporary introduction of local variables for each of the input and output parameters, as per the "introduce explaining variable" refactoring <see cite="fowler00introducevariable" />.  This makes the upcoming stateless method parameters and return values explicit so that it is easier to provide them with suitable names, easier to evaluate their simplicity (consult section <see ref="subsec:Step4" /> for details) and to more clearly delineate the candidate block so that it will be easier to extract it using existing "extract method" refactoring tools.

            The local variables introduced during this step should be remembered to allow their re-inlining to be performed again at the end of the current iteration, as described in section <see ref="subsec:Step6" />.
          </command>
          <command name="subsection" param="Step 4: Simplification of Inputs">
            <command name="label" param="subsec:Step4" />
            Stateless method extraction's fourth step entails finding the simplest types that can be used for the parameters and return values without causing an undue increase in their numbers.  Any type with an easy construction (a single call to a constructor or a factory method) and without side-effects while reading its component values (typical of an immutable instance) is considered "simple" for the purpose of SME.

            <listing label="lst:StatefulVector" style="realCode" linerange="15-36" file="Stateful/Plane.cs" placement="t">
              C# showing the original <tt>Plane</tt> class computing a cross-product and a dot-product inline
            </listing>
            <listing label="lst:StatelessVector" style="realCode" linerange="15-44" file="Stateless/Plane.cs" placement="t">
              C# showing the <tt>Plane</tt> class with the <tt>CrossProduct()</tt> and <tt>DotProduct()</tt> stateless methods extracted from it
            </listing>

            As a first example of possible input simplification, refer to listing <see ref="lst:StatefulVector" /> where line 19 computes the dot product of two 3D vectors.  This candidate block has, as parameters, two instances of a <tt>Vector</tt> type.  The stateless method that was extracted as lines 26-29 of listing <see ref="lst:StatelessVector" /> could also have been written to accept 6 parameters representing both triplets of the vectors' values.  Assuming a <tt>Vector</tt> instance can be created in one statement (a call to its constructor, in this case) and reading its component values can cause no side-effects, it may be worth keeping the input parameters as two <tt>Vector</tt> instances for readability reasons.  It is worth noting that an argument could also be made to make the new <tt>DotProduct()</tt> method accept the 6 component values so that the method could be subsequently re-used to calculate dot products of vectors not expressed using instances of <tt>Vector</tt>.

            <region name="two code listings for Match-based formatting">
              <listing label="lst:StatefulCodeFormatMatchEvaluator" style="realCode" linerange="35-64" file="Stateful/CodeBlockModifier.cs" placement="t">
                C# showing the original <tt>CodeBlockModifier</tt> class
              </listing>

            <command name="newpage" />

              <listing label="lst:StatelessCodeFormatMatchEvaluator" style="realCode" linerange="35-78" file="Stateless/CodeBlockModifier.cs" placement="t!">
                C# showing the <tt>CodeBlockModifier</tt> class after SME
              </listing>
            </region>

            On the other hand, suppose the candidate block's purpose is to reformat text based on the results of a regular expression match, as shown between lines 22-27 in listing <see ref="lst:StatefulCodeFormatMatchEvaluator" />.  In this case, because the input parameter is of a type that is difficult to create <footnote>The <tt>Match</tt> class has no visible constructors.  The only way to create an instance is through the return value of the <tt>Match()</tt> method overloads on the <tt>Regex</tt> class.</footnote>, it is easy to argue that the method's parameters should be four strings (consult lines 34-43 of listing <see ref="lst:StatelessCodeFormatMatchEvaluator" /> to see the extracted method) instead of one <tt>Match</tt> instance, given how trivial strings are to create versus the complexity involved in creating said <tt>Match</tt> instance.  Indeed, as listing <see ref="lst:StatefulCodeFormatMatchEvaluatorTest" /> shows, the original method must either be tested indirectly (through calling the <tt>ModifyLine()</tt> method) or by creating a <tt>Match</tt> instance (in a rather pathological way, lest the original regular expression pattern is refactored for re-use as in lines 12-13 of listing <see ref="lst:StatelessCodeFormatMatchEvaluator" />), while listing <see ref="lst:StatelessCodeFormatMatchEvaluatorTest" /> shows the extracted stateless <tt>BuildCodeElementString()</tt> method can be tested directly.

            <region name="two code listings for Match-based formatting tests">
              <listing label="lst:StatefulCodeFormatMatchEvaluatorTest" style="realCode" linerange="7-30" file="Stateful/CodeBlockModifierTest.cs" placement="t">
                C# showing two ways to test the <tt>CodeFormatMatchEvaluator()</tt> method
              </listing>
              <listing label="lst:StatelessCodeFormatMatchEvaluatorTest" style="realCode" linerange="17-41" file="Stateless/CodeBlockModifierTest.cs" placement="t">
                C# showing the parsing and formatting functionality tested directly and separately
              </listing>
            </region>
          </command>
          <command name="subsection" param="Step 5: Extraction of the Candidate Block Into a Method">
            <command name="label" param="subsec:Step5" />
            The fifth step consists of replacing the candidate block with a call to a new method into which the contents of the candidate block was moved.  The names and types of the parameters will come from the local variables introduced in step 3, as will the names and types of the new method's local variables representing the return values.  The name of the extracted method should describe how the parameters are processed to produce the return values, although the new method could become an overload of the original method.

            The newly-extracted method, by virtue of the candidate block processing in the previous steps, should only read from its input parameters and write to its return values, otherwise it would not qualify as [externally] "stateless".  To help prevent the accidental interaction with any instance fields, the method should be marked as being scoped to the class (as opposed to being scoped to instances), which is done in many programming languages by decorating the method with the <tt>static</tt> keyword.

            The "extract method" refactoring <see cite="fowler00extractmethod" /> is implemented as a built-in interactive tool in development environments <see cite="msdn05extractmethod, eclipse08extractmethod" />, which makes this step almost trivial.
          </command>
          <command name="subsection" param="Step 6: Re-inline any Variables Created to Facilitate a Refactor">
            <command name="label" param="subsec:Step6" />
            The SME technique's sixth and final step cleans up the temporary refactoring performed as part of step 3.  This is done by performing the "inline temp" refactoring <see cite="fowler00inlinetemp" />, an inline expansion of the local variables introduced to represent the new method's input parameters and return values.
          </command>
          <command name="subsection" param="End-to-end Detailed Walk-through">
            The following example demonstrates the application of SME on a simplified version of the <tt>FootNoteFormatterState</tt> class from the <em>Textile.NET</em> open-source project <see cite="chabant09textilenet" />.  First, the original implementation is presented in listing <see ref="lst:StatefulFootNoteFormatterState" />, along with the source code to its parent class in listing <see ref="lst:StatefulSimpleBlockFormatterState" />.  Second, a unit test will be attempted against the original implementation.  SME will then be applied and finally new unit tests will be written against the transformed implementation.

            <command name="subsubsection" param="Analysis and corresponding unit test">
              <listing label="lst:StatefulFootNoteFormatterState" style="realCode" linerange="60-95" file="Stateful/FootNoteFormatterState.cs">
                C# showing the original <tt>FootNoteFormatterState</tt> class
              </listing>
              <listing label="lst:StatefulSimpleBlockFormatterState" style="realCode" linerange="25-58" file="Stateful/FootNoteFormatterState.cs">
                C# showing the <tt>SimpleBlockFormatterState</tt> base class
              </listing>

              As we can see in listing <see ref="lst:StatefulFootNoteFormatterState" />, the <tt>FootNoteFormatterState</tt> class is part of a framework and must fulfill a contract by implementing some methods from its base class, <tt>SimpleBlockFormatterState</tt> (see listing <see ref="lst:StatefulSimpleBlockFormatterState" />).  One of these methods is <tt>OnContextAcquired()</tt> (see lines 31-35 of listing <see ref="lst:StatefulFootNoteFormatterState" />), which reads from the <tt>Tag</tt> property, parses it with a regular expression and writes the result to the <tt>m_noteID</tt> field, a classic example of interaction with HMS.  We will focus on this method for the purposes of testing it, starting with an analysis of its inputs and outputs, so that we can feed it test data and verify its results.
              
              Looking at listing <see ref="lst:StatefulSimpleBlockFormatterState" />, we see that the <tt>Tag</tt> property's underlying value comes from the <tt>m_tag</tt> field (line 32), which is only written to at line 16, as part of the <tt>Consume()</tt> method.  We see that the <tt>Consume()</tt> method also calls the <tt>OnContextAcquired()</tt> method, so our test can call the <tt>Consume()</tt> method to invoke the <tt>OnContextAcquired()</tt> method indirectly.  Even if the test class subclassed <tt>FootNoteFormatterState</tt> to be able to call <tt>OnContextAcquired()</tt> directly (due to its visibility of <tt>protected</tt>), it would not be sufficient because <tt>m_tag</tt> is only written to by a call to <tt>Consume()</tt>.  The <tt>Consume()</tt> method's parameter is an instance of the <tt>Match</tt> class, which has no visible constructors and can only be obtained from a call to one of the <tt>Match()</tt> method overloads on the <tt>Regex</tt> class.  As for the outputs, we see that the <tt>m_noteID</tt> field is unavailable for direct inspection (due to its visibility of <tt>private</tt>), however the <tt>Enter()</tt> method reads the <tt>m_noteID</tt> field to insert its value into a template, the result of which is written to the <tt>TextWriter</tt> instance provided at construction.  As luck would have it, the <tt>Consume()</tt> method also calls the <tt>Enter()</tt> method. <!-- TODO: can add a footnote saying the non-simplified version called it rather indirectly -->

              <listing label="lst:StatefulFootNoteFormatterStateTest" style="realCode" linerange="8-29" file="Stateful/FootNoteFormatterStateTest.cs" placement="h">
                C# showing the unit test for the original <tt>OnContextAcquired()</tt> method
              </listing>

              Armed with the information gathered by this analysis, we can now write a unit test, which can be seen in listing <see ref="lst:StatefulFootNoteFormatterStateTest" />.  As we can see, the <tt>arrange</tt> phase is rather complex, given it must initialize five variables to satisfy the requirements for all the methods involved.  Notice also how the <tt>assert</tt> phase can verify that the substring <tt>"1"</tt> we provided inside the <tt>input</tt> string on line 10 was indeed parsed out by the <tt>OnContextAcquired()</tt> method and then formatted again as the substring <tt>"&lt;sup&gt;1&lt;/sup&gt;"</tt> into the string that was written - through the <tt>Enter()</tt> method - to the <tt>TextWriter</tt>-compatible instance we provided on line 6.  This level of indirection is at best frustrating and at worse a sufficient obstacle to prevent such unit tests to be written in the first place, encouraging more involved and/or fragile integration tests, if any.
            </command>
            <command name="subsubsection" param="Step 1: Identification of a candidate block">
              Keeping with our focus on the <tt>OnContextAcquired()</tt> method, the first step of SME would identify almost all the processing that takes place, since matching a regular expression, extracting one of the captured groups and converting a string into an integer are all "stateless statements" and together they produce a non-trivial result.  We can also identify one input - the value of the <tt>Tag</tt> property - and one output - assignment to the <tt>m_noteID</tt> field.
            </command>
            <command name="subsubsection" param="Step 2: Re-ordering of incidental operations">
              All three statements are necessary and related to the computation; in this particular case there are no incidental operations and thus the second SME step results in no actions taken.
            </command>
            <command name="subsubsection" param="Step 3: Assignment of inputs and outputs to local variables">
              Listing <see ref="lst:StatefulIntermediateFootNoteFormatterState" /> shows the <tt>OnContextAcquired()</tt> method after the small transformation called for by the third SME step: the introduction of local variables for inputs and outputs, namely the <tt>tag</tt> variable on line 3 and the <tt>result</tt> variable on line 5.

              <listing label="lst:StatefulIntermediateFootNoteFormatterState" style="realCode" linerange="129-135" file="Stateful/FootNoteFormatterState.cs">
                C# showing the <tt>OnContextAcquired()</tt> method with additional local variables
              </listing>
            </command>
            <command name="subsubsection" param="Step 4: Simplification of inputs">
              The only input parameter is a string and a string is considered one of the "simple" types, thus the fourth SME step results in no action being taken.
            </command>
            <command name="subsubsection" param="Step 5: Extraction of the candidate block into a method">
              The application of SME's fifth step can be seen in listing <see ref="lst:StatelessIntermediateFootNoteFormatterState" />, where the <tt>ParseFootNoteId()</tt> stateless method was introduced based on the candidate block inside the <tt>OnContextAcquired()</tt> method.  Notice how the <tt>ParseFootNoteId()</tt> method has been decorated with the visibility of <tt>internal</tt> so that it is not visible to outside callers, while still visible to the tests.  Notice also how the method was decorated with the scope of <tt>static</tt> because it no longer needs to read from or write to any instance fields or properties, nor call any instance methods <footnote>Microsoft recommends that methods which do not access instance members be marked as static for performance reasons.  This is documented as Code Analysis rule <em>CA1822: Mark members as static</em> at <url>http://msdn.microsoft.com/en-us/library/ms245046.aspx</url></footnote>.

              <listing label="lst:StatelessIntermediateFootNoteFormatterState" style="realCode" linerange="147-158" file="Stateless/FootNoteFormatterState.cs">
                C# showing the <tt>OnContextAcquired()</tt> method with the <tt>ParseFootNoteId()</tt> method extracted
              </listing>
            </command>
            <command name="subsubsection" param="Step 6: Re-inline any variables created to facilitate a refactor">
              The sixth step of SME reverses the actions of the third step and inlines the <tt>tag</tt> and <tt>result</tt> temporary variables, as can be seen in listing <see ref="lst:StatelessFootNoteFormatterState" />.
              <listing label="lst:StatelessFootNoteFormatterState" style="realCode" linerange="97-106" file="Stateless/FootNoteFormatterState.cs" placement="H">
                C# showing the <tt>OnContextAcquired()</tt> and <tt>ParseFootNoteId()</tt> methods after SME
              </listing>
            </command>
            <command name="subsubsection" param="Writing a unit test after SME">
              Now that SME has been applied on the <tt>OnContextAcquired()</tt> method, our mission to unit test its functionality has been greatly simplified, as the computations have been <em>outsourced</em> to the <tt>ParseFootNoteId()</tt> method and <tt>OnContextAcquired()</tt> simply serves as a proxy for said computations, while coordinating access to the HMS.  The <tt>ParseFootNoteId()</tt> method's inputs consist of a single string and its return values consist of a single integer, making unit tests almost trivial, as listing <see ref="lst:StatelessParseFootNoteIdTest" /> shows.  We can still keep the test shown in listing <see ref="lst:StatefulFootNoteFormatterStateTest" /> as it tests at a higher level the functionality of <tt>ParseFootNoteId()</tt> and its integration with the HMS, but if a defect is later found in the footnote parsing code, we can write a very short test to expose it instead of a more involved test.
              <listing label="lst:StatelessParseFootNoteIdTest" style="realCode" linerange="22-33" file="Stateless/FootNoteFormatterStateTest.cs">
                C# showing the unit test for the <tt>ParseFootNoteId()</tt> method
              </listing>
            </command>
          </command>
          <command name="subsection" param="Accelerated Walk-through">
            The following example demonstrates the application of SME for the purposes of testing the functionality of the <tt>Enter()</tt> method of the <tt>FootNoteFormatterState</tt> class in listing <see ref="lst:StatefulFootNoteFormatterState" />.  We are able to re-use the analysis we used for the <tt>OnContextAcquired()</tt> method and find that a test written against the original version of the class would look a lot like the one we came up with in listing <see ref="lst:StatefulFootNoteFormatterStateTest" />.  The rest of this sub-section will feature listings <see ref="lst:StatefulEnterFootNoteFormatterState" />, <see ref="lst:StatefulIntermediateEnterFootNoteFormatterState" />, <see ref="lst:StatelessIntermediateEnterFootNoteFormatterState" />, <see ref="lst:StatelessEnterFootNoteFormatterState" /> and <see ref="lst:StatelessFormatFootNoteTest" /> that illustrate - without narrative - the SME steps applied to increase the testability of the <tt>Enter()</tt> method and the unit test that can be written against the newly-extracted <tt>FormatFootNote()</tt> method.

            <listing label="lst:StatefulEnterFootNoteFormatterState" style="realCode" linerange="70-78" file="Stateful/FootNoteFormatterState.cs">
              C# showing the original <tt>Enter()</tt> method
            </listing>
            <listing label="lst:StatefulIntermediateEnterFootNoteFormatterState" style="realCode" linerange="107-117" file="Stateful/FootNoteFormatterState.cs">
              C# showing the <tt>Enter()</tt> method with temporary variables introduced
            </listing>
            <listing label="lst:StatelessIntermediateEnterFootNoteFormatterState" style="realCode" linerange="119-135" file="Stateless/FootNoteFormatterState.cs">
              C# showing the <tt>FormatFootNote()</tt> method that was extracted from the <tt>Enter()</tt> method
            </listing>
            <listing label="lst:StatelessEnterFootNoteFormatterState" style="realCode" linerange="70-85" file="Stateless/FootNoteFormatterState.cs">
              C# showing the temporary variables re-inlined in the <tt>Enter()</tt> method
            </listing>
            <listing label="lst:StatelessFormatFootNoteTest" style="realCode" linerange="8-20" file="Stateless/FootNoteFormatterStateTest.cs">
              C# showing the unit test for the <tt>FormatFootNote()</tt> method
            </listing>
          </command>
            <!-- examples
sum-of-squares is an excellent example of statlessness that can be exploited for parallel processing after seperating the computation from the looping

[re: formulas]
Notice how the SME refactoring not only makes testing trivial but also makes the processing in the original method a lot more obvious and transparent:  once ToRadians() and CalculateGreatCircleDistance() are tested the implementation of ComputeTourLength() is easier to read and it becomes easier to re-use these two methods elsewhere.

The candidate block selection in this one could be debatable:  do we include the ToRadians() calls?  If we don't, we still need to provide the method 4 doubles as input (no change there) and the radian versions of the angles are therefore only used to call CalculateGreatCircleDistance (which suggests they should follow the rest of the math).  Also, from a testing perspective, it will be more intuitive to provide the CalculateGreatCircleDistance() method angles in degrees rather than in radians.

At the same time, we don't want to have the parameters be _cities, _visitingOrder, i and j (no change in number) since the first two aren't the simplest types because they require non-trivial construction.  Indeed, those are the parameters that are set-up and provided in the stateful version, so we would not be gaining very much (we trade the division by two and the creation of FSP by the creation of those two arrays).

We *could* get the parameters to CalculateGreatCircleDistance to be two LatLon instances (from and to, only 2) because we know we can create those in one step (and there are no side-effects from reading their Lat and Lon properties), but that might not always be the case.  The tests would now look like:

    var actual = FlyingSalespersonProblem.
      CalculateGreatCircleDistance(
        new LatLon(36.12, -86.67),
        new LatLon(33.94, -118.40)
      );
    Assert.AreEqual(2887.26, actual, 0.01);

The algorithm/procedure favours the simplest types because it doesn't need knowledge of construction complexity and it would make the job of SBST/constraint solvers easiest.  There's no accounting for taste, so if a programmer decides it's better for them to use LatLon instances, then so be it.


[re: loop processing]
Notice how it is now possible to test a single instance of the <I /> element, as opposed to needing to provide a sequence of inputs (which may have restrictions of their own) and asserting/testing surrounding output (or, worse yet, if there is lots of surrounding output, it may lead to some lazy "find an instance of this in all of that" testing)

[re: string parsing]
= FootNoteFormatterState is perfect because it is impossible to test [the parsing or the formatting] in isolation because:
  = m_tag is only assignable in SimpleBlockFormatterState
  = by a method (Consume) that accepts an instance of Match (Match can't be directly created)
    = it might be easiest to stop here and create the Match from a Regex on input
  = which is called from a private method
  = which is called from TextileFormatter.Format(string)
  = which must be constructed with an instance of IOutputter
  => see revision 202 for what a "test" looks like vs. what it looks like with a small stateless method extraction

[re: trivial visibility change]
        private string FixEntities(string text)
        {
            // de-entify any remaining angle brackets or ampersands
            text = text.Replace("&", "&amp;");
            text = text.Replace(">", "&gt;");
            text = text.Replace("<", "&lt;");
            //Regex.Replace(text, @"\b&([#a-z0-9]+;)", "x%x%");
            return text;
        }

[re: non-SME extraction, but still testability-related]
Extracted the regular expression pattern string in revision 220 (and a Regex instance itself in revision 221), which allowed the parsing to be tested independently of the formatting.
            -->
        </command>
        <command name="newpage" />
        <command name="section" param="Suitability">
          <command name="label" param="sec:Suitability" />
          Although designed to work around the difficulties introduced by HMS, SME is suitable for methods that are difficult to test - even in the absence of HMS - due to unwieldy arrange phases, computation coupling, the presence of side-effects and/or restrictions of visibility.  These additional suitabilities are addressed in the following sub-sections.

          <command name="subsection" param="Unwieldy Arrange Phase">
            <command name="label" param="subsec:UnwieldyArrangePhase" />
            If a unit test method has an <em>arrange</em> phase that is longer than 50% of the test method, it is probably an indication that there are too many parameters, the parameters are too difficult to create and/or the functionality under test is buried too deep.  SME would help isolate the functionality that is intended to be tested and thus reduce the number of parameters, since candidate blocks are selected to use between 1 and 6 parameters.  SME would also help reduce the complexity of the parameters - the input simplification step takes care of this - and expose the computation as a single, direct method call.  The arrange phase would then be shrunk considerably, if not entirely removed, leading to simpler unit tests.  An example of an unwieldy arrange phase was seen in listing <see ref="lst:StatefulFootNoteFormatterStateTest" /> and can also be seen in listing <see ref="lst:StatefulCalculateGreatCircleDistanceTest" /> whereby a test for the <em>great circle distance</em> formula <see cite="weisstein99greatcircle" /> in the <tt>FlyingSalespersonProblem</tt> class (refer back to listing <see ref="lst:StatefulFlyingSalesPerson" />) must initialize a list of cities, an instance of the <tt>FlyingSalespersonProblem</tt> class and a visiting order.  Contrast this with the test for the <tt>CalculateGreatCircleDistance()</tt> stateless method in listing <see ref="lst:StatelessCalculateGreatCircleDistanceTest" /> which only needs to supply the coordinates of the two points. <!-- TODO: the CalculateGreatCircleDistance() method is a great building block to write and test on its own, leading to the construction of the ComputeTourLength() method, which can still be tested -->

            <listing label="lst:StatefulCalculateGreatCircleDistanceTest" linerange="12-31" file="Stateful/FlyingSalespersonProblemTest.cs" style="realCode">
              C# showing an indirect test of the <em>great circle distance</em> formula used by the <tt>ComputeTourLength()</tt> method
            </listing>
            <listing label="lst:StatelessCalculateGreatCircleDistanceTest" linerange="54-61" file="Stateless/FlyingSalespersonProblemTest.cs" style="realCode">
              C# showing a direct test of the <em>great circle distance</em> formula by calling the <tt>CalculateGreatCircleDistance()</tt> stateless method
            </listing>
          </command>

          <command name="subsection" param="Computation Coupling">
            A method may be performing several computations in such a way to make it difficult to unit test any such computation on an individual basis, usually due to operations that make it difficult to observe intermediate results.  We call this <em>computation coupling</em>.  For example, the <tt>ModifyLine()</tt> method in listing <see ref="lst:StatefulCodeFormatMatchEvaluator" /> combines parsing and formatting in a single operation <footnote>The <tt>Replace()</tt> method will call the <tt>CodeFormatMatchEvaluator()</tt> method to re-format every match.</footnote> while listing <see ref="lst:StatelessCodeFormatMatchEvaluator" /> shows how exposing the <tt>CodeBlockRegex</tt> object and the <tt>BuildCodeElementString()</tt> method makes the functionality more directly reachable.  Indeed, consult listing <see ref="lst:StatelessCodeFormatMatchEvaluatorTest" /> to see how this decoupling enables the unit testing of the parsing and the formatting, seen in the <tt>ParseZone()</tt> and <tt>BuildCodeElementString()</tt> test methods, respectively, without needing to always perform both at once.  Contrast this to the <tt>ModifyLine()</tt> test method in listing <see ref="lst:StatefulCodeFormatMatchEvaluatorTest" />, which must exercise the parsing and the formatting simultaneously.

            In this particular case, the SME technique was extended to include two other extractions:  the compile-time <tt>Pattern</tt> string constant representing the regular expression pattern and the <tt>CodeBlockRegex</tt> run-time constant representing the compiled regular expression.  This provided the unit tests with access to the same functionality used for performing the work, thereby enhancing the unit tests' realism and relevance.  Finally, SME's candidate block identification enabled the separation of parsing and formatting, which allowed both to be tested separately as units, as well as together since the public-facing functionality did not change as a result of the refactorings.

            <region name="two code listings for computation coupling">
              <listing label="lst:StatefulMortonLayout" style="realCode" linerange="4-25" file="Stateful/MortonLayout.cs" placement="t">
                C# showing the original <tt>Decode()</tt> method computing the values of <tt>x</tt> and <tt>y</tt> simultaneously
              </listing>
              <listing label="lst:StatelessMortonLayout" style="realCode" linerange="4-27" file="Stateless/MortonLayout.cs" placement="t">
                C# showing the <tt>Decode()</tt> method with the <tt>DecodeAxis()</tt> method extracted out of it
              </listing>
            </region>

            Computation de-coupling might not always be addressable through SME as there could be computations that are tightly-coupled for readability or performance reasons and separating them would lead to a readability or performance loss.
            
            An example of two computations that would be worse if separated can be seen in listing <see ref="lst:StatefulMortonLayout" />, where we can see that <tt>x</tt> and <tt>y</tt> are computed simultaneously.  Compare this to listing <see ref="lst:StatelessMortonLayout" />, where <tt>x</tt> and <tt>y</tt> are computed separately, meaning two runs through the loop on <tt>bits</tt> instead of one.  It is also less obvious, in the second case, that the values of <tt>x</tt> and <tt>y</tt> were obtained by interpreting interleaved bits of the Morton Layout's <tt>index</tt> <see cite="msdn08deepzoom" />.
          </command>

          <command name="subsection" param="The Presence of Side-effects">
            A method may not suffer from the state problem (it neither reads from nor writes to instance fields), but nevertheless has side-effects that increase the difficulty when writing unit tests, such as the modification of input parameters or interactions with the environment.  Stateless method extraction could potentially still take place, provided some candidate blocks can be identified around the code causing said side-effects.  This would allow some simple unit tests to be written against the simple stateless methods extracted, while still allowing more involved integration tests against the original method.

            <listing label="lst:StatefulMutableVector" style="realCode" linerange="3-32" file="Stateful/MutableVector.cs" placement="t">
              C# showing the <tt>CalculateAngle()</tt> method causing side-effects on its parameters
            </listing>

            An example of a method producing a result and causing side-effects can be seen in listing <see ref="lst:StatefulMutableVector" />.  The <tt>CalculateAngle()</tt> method calls the <tt>Normalize()</tt> method on <tt>MutableVector</tt>, which irreversibly scales the parameters to be unit vectors.  SME's candidate block identification would exclude both calls to <tt>Normalize()</tt> and would allow a version of the <tt>CalculateAngle()</tt> method to be created that had no side-effects but assumed both parameters were of unit length.
          </command>

          <command name="subsection" param="Visibility or Access Restrictions">
            An instance method may already be stateless, but, because of its nature, may be difficult to reach with unit tests.  This situation can manifest itself when the class under test subclasses another class to override some of its methods, but said methods are only visible to the superclass and subclasses thereof.  This is usually achieved with a visibility or accessibility of <tt>protected</tt>.  This can also happen when the class under test explicitly implements an interface (when using C#): the explicitly-implemented interface members will not be visible from the class' default interface <see cite="msdn10explicitinterface" />.

            In both cases, SME can help extract one or more stateless methods that will not require an instance of the class to be created and can be directly unit tested, while keeping the original methods with the visibility and accessibility they require.
          </command>

          <!-- TODO:
          Talk about file stream processing if we're starting to run out of content
          <command name="subsection" param="Unsuitability">
            TODO: There exist cases that even SME has difficulty helping; is it worth expanding upon the "uninteresting categories" given in Step 1?  What about for stuff not mentioned there, such as calls to base class methods as in KeePassLib's BinaryReaderEx.ReadBytes(int) that calls BinaryReader.ReadBytes(int) through base?
          "Applying SME with parameterizable side-effects"
          TODO: talk about using call-backs/function pointers
          </command>
          -->
        </command>

        <command name="section" param="Applicability">
          <command name="label" param="sec:Applicability" />
          In general, SME is most applicable to existing or legacy projects that were built with few or no unit tests.  As a result, their source code was not written with testability in mind, nor is it possible (for various reasons) to make large, sweeping testability-related changes.  The prospect of fixing defects or adding features to such a project, without sufficient tests to catch regressions, would seem risky.  SME could be used to introduce small, easily-testable methods - along with some unit tests - to the affected source code before making each fix or adding each new feature, thereby establishing a functionality baseline, if only a partial one.

          As noted in section <see ref="sec:Suitability" />, SME is suitable for more than HMS and, by the same token, can also be applied to more than legacy projects.  Sometimes there are technological reasons that impede the testability of a class or method.  For example, some frameworks force the introduction of a parameterless constructor to be able to create an instance of a class for the purposes of serialization.  Such frameworks may introduce mutable state where none would be present otherwise and SME can then be used to help keep the unit tests simple.

          It would seem that any software project with insufficient testing coverage is fair game, although as the following sub-sections discuss, there are conditions under which SME could deliver greater value than other techniques.

          <command name="subsection" param="Identifying Stateless Methods">
            <command name="label" param="subsec:IdentifyStateless" />
            SME will work best if the programming language or toolkit used has a concept of a <em>stateless</em> method.  This would ensure that each method marked as a stateless method only reads from its input parameters, only writes to its return values, does not read from or write to any instance or static fields (reading from constants is acceptable, as long as they represent immutable instances), does not interact with the environment (such as reading a file, sending data across a network or updating a database) and only calls methods similarly identified as stateless.

            <region name="two code listings for the proposed attributes">
              <listing label="lst:StatelessStatelessAttribute" style="realCode" linerange="3-24" file="Stateless/StatelessAttribute.cs" placement="t">
                C# showing a proposed <tt>Stateless</tt> attribute with a sample of its use
              </listing>
              <listing label="lst:StatelessImmutableAttribute" style="realCode" linerange="3-23" file="Stateless/ImmutableAttribute.cs">
                C# showing a proposed <tt>Immutable</tt> attribute with a sample of its use
              </listing>
            </region>

            Such a concept need not be implemented at the language level and could instead be implemented by a static code analysis (SCA) tool with the help of a designated decoration.  For example, this decoration could be implemented as an attribute in .NET or an annotation in Java.  Listing <see ref="lst:StatelessStatelessAttribute" /> shows a C# implementation of the proposed <tt>Stateless</tt> attribute (lines 1-5) and a sample of its use (line 12).  By placing the line <tt>[Stateless]</tt> above the <tt>FormatIso8601Utc()</tt> method definition, the C# compiler will include the reference to <tt>StatelessAttribute</tt> in the byte code such that its presence on the method can be queried by SCA tools.
          </command>
          <command name="subsection" param="Identifying Immutable Instances">
            A class which contains no mutable state is said to be <em>immutable</em>.  Any state an immutable class has can only be set during construction - through the parameters of constructors or factory methods - and all its instance methods either return that state directly or perform computations with it (possibly including the method's parameters), in a manner very much like stateless methods.  Immutable classes can make it easier to implement SME because there exists, by definition, no sequence of method calls on their instances that can modify their state.  Instances of immutable classes therefore make excellent inputs to stateless methods.  As discussed in section <see ref="subsec:Step4" />, immutable classes are considered "simple" and can therefore provide stateless methods with convenient groupings of related input parameters, instead of specifying them separately.  The use of immutable classes can thus provide additional readability in unit tests at the expense of a constructor call.

            Similar to the <tt>Stateless</tt> decoration suggested in sub-section <see ref="subsec:IdentifyStateless" />, a decoration could be defined to identify classes that are immutable and thus safe to use as constants or input parameters.  Listing <see ref="lst:StatelessImmutableAttribute" /> shows a C# implementation of the proposed <tt>Immutable</tt> attribute (lines 1-5) and a sample of its use (line 7).  By placing the line <tt>[Immutable]</tt> above the <tt>EarthLocation</tt> class definition, the C# compiler will include the reference to the <tt>ImmutableAttribute</tt> in the byte code such that its presence on the class can be queried by SCA tools.  This idea was further developed by Bazuzi and Pilch-Bisson <see cite="pilch07enforcingimmutability" />.

            These proposed <tt>Stateless</tt> and <tt>Immutable</tt> decorations have the additional benefit that they could also be exploited by an optimizing compiler to inline the stateless methods (and apply other such performance improvements) in release mode, due to the new guarantees of immutability and invariance they provide by being enforced by the compiler and/or SCA.
          </command>
          <command name="subsection" param="Controlling Visibility">
            The SME technique will work best if the programming language has features to control the visibility of methods to ensure that the newly-introduced stateless methods do not pollute the public interface of the affected classes.  C# has the <tt>internal</tt> access modifier <see cite="msdn10internal" />, which, when combined with the <tt>InternalsVisibleTo</tt> attribute <see cite="msdn10internalsvisible" />, can expose the stateless methods to a unit test project, but not to consumers of the API, which, in effect, hides the results of SME from end-users.  Java has a similar concept with its packages <see cite="java96packages" />.  Indeed, unless the <tt>public</tt> or <tt>private</tt> access modifiers are used, a method will be visible from within the package it was defined <see cite="java96names" />, which means unit tests in the same package will have access to the newly-extracted stateless methods, but consumers of the API will not.

            An alternative to visibility controls or access modifiers - especially for programming languages without such features - is to place the extracted methods in a separate class (possibly named after the original class, but suffixed with <tt>Stateless</tt>) or even not attached to any class, provided the language makes this possible.  It may even be the case that, upon further consideration, a newly-extracted method should really belong in the class of one of its parameters.  For example, the <tt>CrossProduct()</tt> and <tt>DotProduct()</tt> methods extracted from the <tt>Plane</tt> class in listing <see ref="lst:StatelessVector" /> would probably be best located in the <tt>Vector</tt> class.
          </command>
        <!-- Loop item processing is difficult when there are operations other than per-item processing, such as stats and loop invariants
        File processing could be abstracted to stream or sequence processing, which is more testable through MemoryStream and IEnumerable.
        -->
        </command>

        <command name="section" param="Public Interface Comparer Tool">
          <command name="label" param="sec:PublicInterfaceComparer" />
          The Public Interface Comparer <footnote>The source code for the Public Interface Comparer Tool can be found in the public Subversion repository at <url>http://testoriented.googlecode.com/svn/pic/trunk/</url></footnote> is a tool written specifically to measure the <em>Public Interface Changes</em> metric.  This section explains how it works and gives a few examples of its use.
          
          <command name="subsection" param="How it Works">
            The tool is a command-line program that accepts three arguments: the path to the <tt>baselineFile</tt>, the path to the <tt>challengerFile</tt> and the path to the <tt>reportFile</tt>.  For each of the assemblies (byte code binary files) pointed to by <tt>baselineFile</tt> and <tt>challengerFile</tt>, the <tt>PublicInterfaceScanner</tt> class uses the reflection features of .NET to find all the publicly-visible types (classes and structs) and, for each of those, finds all their publicly-visible members (fields, properties, events and methods).  Each such member is converted into a canonical string representation of its definition and added to a list.  When all members of an assembly have been added to the list, the list is sorted alphabetically and returned to the main program.
            
            Public visibility is defined as the application programming interface (API) intentionally exposed by the authors of the library for consumption by third-party programs.  In .NET and Java, the mechanism for doing so is to decorate a member with the visibility keywords of <tt>public</tt> or <tt>protected</tt>.
            
            When the program has received both lists of publicly-visible members, the creation of the difference report - which will be written to the file pointed to by <tt>reportFile</tt> - is a matter of finding differences between the two lists.  This is done in a single pass in a manner similar to merging.
          </command>
          <command name="subsection" param="Examples">
            An example use of the Public Interface Comparer tool is presented here, where listing <see ref="lst:StatefulBlockModifier" /> shows one version of the <tt>BlockModifier</tt> class while listing <see ref="lst:StatelessBlockModifier" /> shows another with a few differences in visibilities.

            <listing label="lst:StatefulBlockModifier" linerange="1-19" file="Stateful/BlockModifier.cs" style="realCode" placement="t">
              C# showing the <tt>BlockModifier</tt> class from the <tt>Textile</tt> project after the <tt>visibility</tt> strategy was applied
            </listing>
            <listing label="lst:StatelessBlockModifier" linerange="1-19" file="Stateless/BlockModifier.cs" style="realCode" placement="h">
              C# showing the <tt>BlockModifier</tt> class from the <tt>Textile</tt> project after some illustrative visibility changes were applied
            </listing>
            <listing label="lst:BlockModifierPIC" file="PIC-BlockModifier.txt" style="realCode" placement="h">
              Sample report of the public interface differences between the code in listing <see ref="lst:StatefulBlockModifier" /> and that of listing <see ref="lst:StatelessBlockModifier" />
            </listing>

            <command name="newpage" />

            As we can see in listing <see ref="lst:BlockModifierPIC" />, the constructor (line 1) and the <tt>Conclude()</tt> method (line 2) were identified as public interface changes between the two versions of the <tt>BlockModifier</tt> class.
          </command>
        </command>
        <command name="section" param="Decisions Made">
          <command name="label" param="sec:Decisions" />
          <region name="Candidate block identification">
          The candidate block identification step in section <see ref="subsec:Step1" /> requires that blocks contain only stateless statements, because statelessness is a transitive property and the presence of any operation that causes side-effects in a method will disqualify all methods that call such a method from claiming statelessness.  A stateless method must therefore only call stateless methods, otherwise the effort is defeated.

          The candidate block identification also requires selecting computations that use 1 to 6 inputs, because a method that accepts no parameters would have to return a constant (otherwise it could not be considered stateless) while 6 was selected as a suggested maximum number of inputs, as a matter of experience, since too many inputs might make it difficult to write tests, defeating the goal of this thesis.  Binder concurs with the number 6: <!-- TODO: a stateless method with a single parameter could be implemented as an extension method or hanging off that class, as mentioned with Vector's [Dot|Cross]Product -->
          <block param="quote">
            "Suppose a small function has 6 or fewer variables, (...)" <see cite="binder00combinationalmodels" />
          </block>

          The last criterion in block candidacy is selecting computations that produce 1 to 3 outputs, because a method that does not return any results likely causes side-effects - thus can not be considered stateless - and side-effects are not trivial to observe during unit testing.  The suggested maximum number of outputs was also selected from experience and is again intended to keep unit tests simple, mostly because very few programming languages support returning more than one value at once.  Returning multiple values at once is often emulated by using a container for the values, either through a specialized type (such as <tt>Vector</tt> used in listings <see ref="lst:StatefulVector" /> and <see ref="lst:StatelessVector" /> or <tt>EarthLocation</tt> in listing <see ref="lst:StatelessImmutableAttribute" />) or an anonymous one, such as a tuple <see cite="msdn10tupleclass, python08datastructures" />.  <!-- TODO: talk about experimental tuple unpacking in Mono: http://tirania.org/blog/archive/2009/Dec-23.html --> <!-- TODO: "returning" more than one value can be done with a call-back/functor -->
          </region>

          The intent of incidental operation re-ordering is to maximize the number of operations in a candidate block while minimizing the number of inputs and outputs.  This is done to avoid extracting stateless methods that perform too few operations, which would cause unit testing to become a high-work and low-return activity. <!-- TODO: if an example is warranted, the best one is probably cartesian to polar coordinates: it makes no sense to extract (_x * _x) or (_y * _y) or (xSquared + ySquared) individually, but collectively, yes.  Similar for the computation of theta, especially if Math.Atan(y, x) wasn't available. -->  Although this incidental operation re-ordering step is automatable through data dependency analysis and program slicing, a programmer will likely be the best judge of which operations are considered related and if these operations collectively have a recognized or standard meaning.
          
          For example, the expression <tt>new Vector(a.Y * b.Z - a.Z * b.Y, a.Z * b.X - a.X * b.Z, a.X * b.Y - a.Y * b.X)</tt> is better identified as a <tt>CrossProduct()</tt> method that accepts two <tt>Vector</tt> instances <tt>a</tt> and <tt>b</tt>.

          Input simplification's intent is to minimize the amount of knowledge the stateless method will need to perform its processing or computation.  It does this by optimizing the inputs and outputs such that the upcoming unit tests (exercising the to-be-extracted stateless method) contain a minimal number of statements, while balancing the readability and maintainability of both the stateless method and said upcoming unit tests.  Another reason for favouring "simple" types - usually the language's built-in base types, such as strings, integers and floating-point numbers - is that they are immutable and/or passed by value, meaning their use from within a stateless method will not result in side-effects.  Although any type with instance fields that are set at construction time, and are read-only thereafter, is acceptable as an input parameter, readability and maintainability should be considered if less than the majority of its instance fields are used by the method under test.  For example, the use of a <tt>DateTime</tt> struct as a parameter when only its <tt>Year</tt> and <tt>Month</tt> properties are needed might suggest that two integer parameters for <tt>year</tt> and <tt>month</tt> would make for a better choice.

          In the absence of programming language features to definitely identify and enforce a method as stateless, the <tt>static</tt> keyword is used to at least make it more difficult to access or manipulate HMS.  It should be noted that it is not always possible to restrict the use of HMS from a static method.  Making a stateless method static also makes it callable without first having to create an instance of a class.  Unfortunately, the <tt>static</tt> keyword does not prevent manipulation of static fields, nor does it enforce that all method calls therein are also stateless.

          The stateless methods' visibility of <tt>package</tt> or <tt>internal</tt> was selected to make the use of SME invisible to end-users.  Indeed, having the test fixture in the same package as the class under test is the convention for JUnit <see cite="vogel07junittutorial" />.  Using MSTest to test methods marked as <tt>internal</tt> in another project is not only documented but also assisted by Visual Studio <see cite="msdn10settinginternals" />.

          Sub-section <see ref="subsec:UnwieldyArrangePhase" /> argues for a threshold of 50% on the size of a unit test's <em>arrange</em> phase, which should trigger an investigation into the content of said arrange phase when exceeded, to see if simplification through SME or other means is possible.  The intent here is to minimize the size of unit tests to encourage their use.  Tests with long arrange phases are still valid but beyond a certain size might be considered <em>integration</em> tests more than <em>unit</em> tests.

          The set of transformations performed during SME were designed to be low-impact in order to encourage their use and reduce the risk of introducing regressions in the very code to which unit tests added.  Indeed, "altering internal structure without changing external behaviour" is the very definition of refactoring <see cite="fowler00refactoring" /> and, as such, care should be taken to <em>only</em> perform the SME steps during the process and to resist the temptation to fix defects or add features at the same time.  Once SME has been performed, unit tests are written against the new method to establish a functionality baseline and both sets of changes are committed to source control.  Only then will it be safe to add unit tests to expose any potential defects or missing features encountered during SME and then fix the defects or add the features in the presence of the safety net added in the previous step.  Binder calls this approach <em>Incremental Testing</em> <see cite="binder00classes, binder00testharness" />.
        </command>
        <command name="section" param="Summary">
          <!-- key points of what was presented and linkage to next chapter -->
          This chapter introduced our approach, describing the steps of the SME technique, along with samples of the associated source code transformations.  The suitability of SME for more than HMS was discussed, as well as the conditions under which SME would work best, concluding with a description of the PIC tool and the motivations behind the decisions made in the SME.
        </command>
      </command>
      <command name="chapter" param="Results and Validation">
        <command name="label" param="chapter:ResultsValidation" />
        <command name="section" param="Introduction">
          <!-- what the chapter is about -->
          This chapter describes experiments with which SME's efficiency at improving testability can be measured and compared against other strategies.  The results of the experiments are summarized and also presented in great detail, concluding with the relation of the results with the metrics of the goal.
        </command>
        <command name="section" param="Evaluation Design">
          <command name="label" param="sec:EvaluationDesign" />
          <!-- TODO: should we move a few words from the overview section up here? -->
        <!--
        = TODO: regarding the motivation for CGT in our case
        == The better the statement coverage of the generated tests, the more testable the original source code under the transformation is considered.
        = {Project}.ManualTests created to avoid interference with Pex if had used {Project}.Tests
        = discuss experiments with Pex (if only to introduce for another section)
        == trade-offs of automatic test generation based on code coverage
        == differences between a constraint solver and evolutionary testing
          -->
          <command name="subsection" param="Overview">
            The goal of stateless method extraction is to improve the testability of source code, especially that of classes with hidden mutable state.
            <command name="subsubsection" param="Strategies">
              SME will be compared to three other strategies, for a total of four:
              <block param="enumerate">
                <command name="item"> Do nothing</command>
                <command name="item"> Extract stateless methods</command>
                <command name="item"> Increase state visibility</command>
                <command name="item"> Increase state and method visibility</command>
              </block>
            </command>

            <command name="subsubsection" param="Projects">
              The evaluation makes use of the source code from the following C# open-source projects, selected by the author based on his familiarity with them:
              <block param="enumerate">
                <command name="item"> Textile.NET, changeset 26030 <see cite="chabant09textilenet" />, henceforth referred to as <tt>Textile</tt></command>
                <command name="item"> KeePass, version 2.10 <see cite="reichl10keepass" />, henceforth referred to as <tt>KeePassLib</tt></command>
                <command name="item"> Atomic CMS, version 2.0 <see cite="shapovalov09atomic" />, henceforth referred to as <tt>AtomicCms</tt></command>
                <!-- TODO: is PivotStack good enough? <command name="item"> PivotStack</command> -->
              </block>
            </command>

            <command name="subsubsection" param="Metrics">
              The goal's validation metrics (see section <see ref="sec:Goal" />) are repeated here and are evaluated for each of the competing strategies on each of the open-source projects:
              <block param="enumerate">
                <command name="item"> Complexity of the unit tests.</command>
                <command name="item"> Number of changes to the class under test's public interface.</command>
                <command name="item"> Percentage of branches covered using concolic testing.</command>
              </block>
            </command>

            The metrics are now explained in further detail, followed by the strategies, the selected methods from the open-source projects and finally how the evaluation was conducted.
          </command>
          <command name="subsection" param="Metrics">
            <command name="label" param="subsec:Metrics" />
            <command name="subsubsection" param="Complexity of the Unit Tests">
              <command name="label" param="subsubsec:complexity" />
              <block param="quote">
                "If the effort to produce and run tests is high, however, less testing will be done." <see cite="binder00testharness" /> <!-- page 1043 -->
                
                "The fewer tests you write, the less productive you are and the less stable your code becomes." <see cite="gamma98testinfected" />
              </block>
              There appears to be consensus regarding the minimization of unit tests' sizes <see cite="feathers05unittesting, osherove06writemaintainable, stewart10testsizes" />.  Keeping unit tests small is generally with the intention of reducing the friction related to writing said unit tests (as noted above by Binder) as well as increasing the readability and maintainability of the source code <see cite="graham93onlisp" />.

              The tool used for evaluating the complexity of the manually-written unit tests is the <em>Visual Studio Code Metrics PowerTool 10.0</em> <see cite="ms11codemetrics" /> (CMPT).  It can compute, among others, a <em>Maintainability Index</em> (MI) that is derived and adapted from the Carnegie Mellon University's Software Engineering Institute metric of the same name <see cite="vandoren97maintainabilityindex" />.  In short, the tool combines a few low-level metrics, obtained by scanning the byte code, and scales the result between 0 and 100.  Higher values are better.  The modifications Microsoft made are as follows:
              
              <block param="quote">
                "The metric originally was calculated as follows: <m>Maintainability Index = 171 - 5.2 \times ln(Halstead Volume) - 0.23 \times (Cyclomatic Complexity) - 16.2 \times ln(Lines Of Code)</m>

                This meant that it ranged from 171 to an unbounded negative number.  We noticed that as code tended toward 0 it was clearly hard to maintain code and the difference between code at 0 and some negative value was not useful. (...) As a result of the decreasing usefulness of the negative numbers and a desire to keep the metric as clear as possible we decided to treat all 0 or less indexes as 0 and then re-base the 171 or less range to be from 0 to 100. Thus, the formula we use is:

                <m>Maintainability Index = MAX(0,(171 - 5.2 \times ln(Halstead Volume) - 0.23 \times (Cyclomatic Complexity) - 16.2 \times ln(Lines Of Code)) \times 100 / 171)</m>" <see cite="morrison07maintainabilityindex" />
              </block>


              <!-- TODO: talk about which variant of the metric is used, what counts toward the score and what does not, which tool was used and how the results were extracted -->
              
              The CMPT is also used to evaluate the IUT of each strategy, to see if the transformations performed as part the respective strategies adversely affected the maintainability of the code being tested.  Because this metric is not part of the goal, its results will not be included in the unit test complexity metric and are recorded more as a "canary in a coal mine" to detect undesirable transformations. <!-- TODO: should the MI IUT become an official metric? -->
            </command>
            <command name="subsubsection" param="Number of Changes to the Class Under Test's Public Interface">
              <command name="label" param="subsubsec:changesPublicInterface" />
              It could be undesirable to make changes to the CUT's public interface simply to increase its testability.  Reasons for not wanting any such changes include:
              <block param="enumerate">
                <command name="item"> The class is part of an API with pre-existing releases. Changes to the API could break third-party applications consuming it.</command>
                <command name="item"> The class must implement a specific interface; a technological variation of the previous reason.</command>
                <command name="item"> Exposing instance state as directly mutable might allow callers to violate some constraints or invariants.</command>
              </block>
              This second metric counts how often each strategy causes a change to the public interface of the class under test, compared to the original version.  This metric will be referred to as the <em>Public Interface Changes</em> (PIC) metric.  Lower values are better, with zero being ideal.  The tool used is the <em>Public Interface Comparer</em> that was described in section <see ref="sec:PublicInterfaceComparer" />.
            </command>
            <command name="subsubsection" param="Percentage of Branches Covered Using Concolic Testing">
              <command name="label" param="subsubsec:codeCoverageConcolic" />
              The Pex tool <see cite="tillman08pex" /> is a concolic, constraint solver-based test generator that can be used to analyze a specified project and generate unit tests to exercise as much of that project's source code as it can.  Pex's ability to exercise the CUT's methods in an automated and unattended fashion provides a very good objective measure of testability.  This ability is measured by the code coverage reported when executing the generated unit tests with a code coverage tool.  Higher values are better.  Version 0.91.50418.0 of Pex is used, along with NUnit <see cite="poole00nunit" /> version 2.4.8 to run the unit tests and NCover <see cite="waldschmidt04ncover" /> version 1.5.8 to measure the code coverage.
            </command>
          </command>
          <command name="subsection" param="Strategies">
            <command name="label" param="subsec:Strategies" />
            <command name="subsubsection" param="Do nothing">
              No transformations are to be performed to the IUT, the source code will be used as-is to establish a baseline.  Henceforth referred to as <tt>base</tt>.
            </command>
            <command name="subsubsection" param="Increase State Visibility">
              All the fields (both instance and static fields) in all the classes had their visibility increased through a manual transformation that converted fields with a visibility (explicit or otherwise) of <tt>private</tt> to <tt>internal</tt> and <tt>protected</tt> to <tt>protected internal</tt>.  Henceforth referred to as <tt>visibility-state</tt>.
            </command>
            <command name="subsubsection" param="Increase State and Method Visibility">
              Similar to the previous strategy, all the fields and all the methods (both instance and static) in all the classes had their visibility increased through a manual transformation that converted fields and methods with a visibility (explicit or otherwise) of <tt>private</tt> to <tt>internal</tt> and <tt>protected</tt> to <tt>protected internal</tt>.  This strategy helps to understand the effectiveness of the Pex-related code coverage metric.  Henceforth referred to as <tt>visibility</tt>.
            </command>
            <command name="subsubsection" param="Extract Stateless Methods">
              This is the very approach proposed by this thesis; stateless methods are extracted - through a manual process - where good candidate blocks are identified.  Henceforth referred to as <tt>manual</tt>.
            </command>
          </command>
          <command name="subsection" param="Selected Methods for Maintainability Metric">
            <table placement="t">
              <tabular spec="p{0.01\textwidth} p{0.01\textwidth} p{0.01\textwidth} l">
                <tr>
                  <td>Project</td>
                </tr>
                <tr>
                  <td />
                  <td>Namespace</td>
                </tr>
                <tr>
                  <td />
                  <td />
                  <td>Class</td>
                </tr>
                <tr>
                  <td />
                  <td />
                  <td />
                  <td>Method</td>
                </tr>
                <command name="hline" />
                <tr><td multicolumn="{4}{l}"><tt>Textile</tt></td></tr>
                <region name="Textile.Blocks">
                  <tr>
                    <td></td>
                    <td multicolumn="{3}{l}"><tt>Textile.Blocks</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td multicolumn="{2}{l}"><tt>CodeBlockModifier</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td><tt>string ModifyLine(string)</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td><tt>string Conclude(string)</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td><tt>string CodeFormatMatchEvaluator(Match)</tt></td>
                  </tr>
                </region>

                <region name="Textile.States">
                  <tr>
                    <td></td>
                    <td multicolumn="{3}{l}"><tt>Textile.States</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td multicolumn="{2}{l}"><tt>FootNoteFormatterState</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td><tt>void Enter()</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td><tt>void OnContextAcquired()</tt></td>
                  </tr>
                </region>

                <tr><td multicolumn="{4}{l}"><tt>KeePassLib</tt></td></tr>
                <region name="KeePassLib.Cryptography.PasswordGenerator">
                  <tr>
                    <td></td>
                    <td multicolumn="{3}{l}"><tt>KeePassLib.Cryptography.PasswordGenerator</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td multicolumn="{2}{l}"><tt>PatternBasedGenerator</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td><tt>string ExpandPattern(string)</tt></td>
                  </tr>
                </region>
                <region name="KeePassLib.Security">
                  <tr>
                    <td></td>
                    <td multicolumn="{3}{l}"><tt>KeePassLib.Security</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td multicolumn="{2}{l}"><tt>XorredBuffer</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td><tt>byte[] ChangeKey(byte[])</tt></td>
                  </tr>
                </region>
                <tr><td multicolumn="{4}{l}"><tt>AtomicCms</tt></td></tr>
                <region name="AtomicCms.Web.Controllers">
                  <tr>
                    <td />
                    <td multicolumn="{3}{l}"><tt>AtomicCms.Web.Controllers</tt></td>
                  </tr>
                  <tr>
                    <td />
                    <td />
                    <td multicolumn="{2}{l}"><tt>AdminMenuItemController</tt></td>
                  </tr>
                  <tr>
                    <td />
                    <td />
                    <td />
                    <td><tt>void FormatResultMessage(IMenuItem, int?)</tt></td>
                  </tr>
                </region>
              </tabular>
              <command name="caption" param="Methods targeted for manually-written unit tests" />
              <command name="label" param="tbl:InterestingMethods" />
            </table>
            Table <see ref="tbl:InterestingMethods" /> lists the methods that have been selected because they were identified as particularly suitable for SME as per the criteria in section <see ref="sec:Suitability" />, such as interacting with HMS or computing several results simultaneously.  This selection forms a representative sample of the testing difficulties associated with HMS and care was taken to exclude methods that were deemed to already be trivially testable or too similar to those already selected.  Unit tests were written to target these methods for each strategy, exploiting the respective transformations to the IUT to simplify the tests where possible.  It is for the manually-written tests of these methods that the "complexity of the unit tests" metric will be computed.
          </command>
          <command name="subsection" param="Preparing the Projects for the Evaluation">
            <region comment="Intro">
            The source code to the projects was imported into a public source control repository <footnote>The files used for the suitability evaluation of this thesis are available inside the Subversion repository at <url>https://testoriented.googlecode.com/svn/suitability/trunk</url></footnote>.  Each project gets its own folder and the imported version (which serves as a baseline) is placed in a sub-folder called <tt>base</tt>.  Some slight modifications were made to the source code to simplify the evaluation, detailed as follows:
            </region>
            <command name="subsubsection" param="Consolidate Projects">
              If a project consisted of many sub-projects, the source files for those sub-projects were combined into a single project, to simplify the configuration of Pex.
            </command>
            <command name="subsubsection" param="Remove Provided Tests">
              Any existing automated tests were removed, otherwise Pex would be able to trivially reach areas of the CUTs through their tests, defeating the purpose of that part of the evaluation.
            </command>
            <command name="subsubsection" param="Add Two Empty Test Projects">
              To help Pex generate unit tests, a corresponding empty test project was created for each project (suffixed with <tt>.Tests</tt>), as was another empty test project created for the complexity metric (suffixed with <tt>.ManualTests</tt>).  Each empty test project was configured to reference its associated project.  The test projects are ready to have test classes added to them.
            </command>
            <command name="subsubsection" param="Expose Internal Members to Pex">
              Each project was configured to make any methods marked as <tt>internal</tt> visible to both the empty test projects and to Pex itself, using the <tt>InternalsVisibleTo</tt> attribute.
            </command>
            <command name="subsubsection" param="Disable Functionality That Interferes With the Evaluation">
              The <tt>KeePassLib</tt> project contains code to show a modal message box dialog that must be dismissed by an end-user.  This is undesirable for an unattended evaluation and therefore the body of the <tt>SafeShowMessageBox()</tt> method in the <tt>MessageService</tt> class was removed, as was that of the <tt>SafeShowMessageBoxInternal()</tt> method in the <tt>MessageService</tt> class.  Also, to prevent assertions in the projects from interrupting the automated evaluation in the same way, the compilation options were modified to use the <em>Release</em> configuration with optimizations disabled and full debug symbols enabled <footnote>Assertions will only display a dialog if the <tt>DEBUG</tt> constant is defined and it is not defined when using the Release configuration.  Disabling optimizations and enabling debug symbols is done to help keep the static code analysis as representative to the original source code as possible.</footnote>.
            </command>
            <command name="subsubsection" param="Create a Copy for Each Strategy">
              Now that we have a baseline for each project, we can create a copy of the <tt>base</tt> folder for each strategy we wish to compare against.  As such, the following folders were created:  <tt>manual</tt> (manual application of SME), <tt>visibility-state</tt> (increasing the visibility of state members, such as fields) and <tt>visibility</tt> (increasing the visibility of both fields and methods).  The corresponding transformations were then performed in their respective folders, isolated from one another and from the baseline.
            </command>
          </command>
          <command name="subsection" param="How it Works">
            <command name="label" param="subsec:HowItWorks" />
            The evaluation is conducted automatically using a small program written with NAnt <see cite="shaw06nant" />.  The major steps are as follows:
            <command name="subsubsection" param="Create a Working Copy">
              Pex modifies the test project file as part of its test generation process.  To make the evaluation repeatable, a copy is made, at the start of the run, of each strategy folder of each project, erasing the previous run's folders as necessary.  Pex can then operate in each working copy without chance of interference from the artifacts of any previous runs.
            </command>
            <command name="subsubsection" param="Compile">
              All the analysis tools (CMPT, Public Interface Comparer and Pex) work by analyzing the byte code of the projects (as opposed to their source code) and thus the next step is to compile the projects.
            </command>
            <command name="subsubsection" param="Run Manual Tests">
              As a sanity check, the tests written to be evaluated for their complexity are run to make sure they all pass.
            </command>
            <command name="subsubsection" param="Determine Public Interface Differences">
              The PIC metric is computed on each project's IUT and the report is stored in the project's working folder as the file <tt>PublicInterfaceDifferences.txt</tt>.  Each line of the report represents a public interface difference between the base code and the code of a strategy and therefore the number of public interface differences is the number of lines in the report.  By definition, the report for the <tt>base</tt> strategy will always contain 0 lines.
            </command>
            <command name="subsubsection" param="Evaluate Maintainability of IUT and Manual Tests">
              The CMPT is launched to compute the MI metric for both the IUT and the manually-written unit tests (henceforth known as MT).  This allows an objective measure of the maintainability of the IUT in the face of testability transformations as well as a measure of maintainability of the corresponding MT.  The CMPT emits the reports respectively as <tt>CodeMetrics.Iut.xml</tt> and <tt>CodeMetrics.Mt.xml</tt> in each working folder.  A quick post-processing step converts the absolute paths in the reports into relative paths to simplify comparisons, producing the files <tt>CodeMetrics.Iut.xml.filtered</tt> and <tt>CodeMetrics.Mt.xml.fitered</tt>.
            </command>
            <command name="subsubsection" param="Invoke Pex Wizard">
              Pex first needs to run in "Wizard" mode, which inspects the IUT and generates test helper methods called "parameterized unit tests".  Unfortunately, there are some defects in Pex that garble the test project files and must then be repaired.  This is done using the Extensible Stylesheet Language (XSL) transformation file <tt>FixPexWizard.xsl</tt> located in the <tt>Tools</tt> folder.  Lastly, the projects are recompiled so that Pex may perform the next step by inspecting the new byte code.
            </command>
            <command name="subsubsection" param="Invoke Pex Generator">
              Pex is now run in "Generate" mode, which produces the actual unit tests by using the helpers it generated in the previous step.  Again, some Pex defects call for the repair of the affected test project files, this time using the <tt>FixPexGenerator.xsl</tt> XSL transformation file.  The projects are recompiled one last time in preparation for running the generated tests.
            </command>
            <command name="subsubsection" param="Run Generated Tests With Coverage">
              The console NUnit runner executes all the unit tests that Pex generated while NCover monitors the execution to collect code coverage data for the IUT.  It is not important whether the tests pass, fail or end in error - Pex by its very nature will generate tests that throw or expect to throw <tt>ArgumentException</tt> instances - it is only important to record code coverage.  The NCover tool emits a coverage report in each project's working folder as the file <tt>coverage.xml</tt>.
            </command>
            <command name="subsubsection" param="Record Results">
              Results are collected from the various reports and submitted to an online spreadsheet <footnote>The spreadsheet can be seen at <url>https://docs.google.com/spreadsheet/ccc?key=0Ag6eugnyWA09dG9zQnFtTlQ0Z1dGUjI5TUlFMnpFWWc</url></footnote>, an explanation and a copy of which can be found in Appendix <see ref="appendix:Spreadsheet" />.
            </command>
          </command>
        </command>
        <command name="section" param="Representative SME Application">
          The following listings show the first of the 8 methods targeted for manually-written unit tests - listed in table <see ref="tbl:InterestingMethods" /> - before the application of SME (listing <see ref="lst:BaseCodeBlockModifierModifyLine" />) and after the application of SME (listing <see ref="lst:ManualCodeBlockModifierModifyLine" />), as well as the manually-written unit test targeting the original method (listing <see ref="lst:BaseCodeBlockModifierModifyLineTest" />) and the manually-written unit test targeting the extracted stateless method (listing <see ref="lst:ManualCodeBlockModifierModifyLineTest" />).
          
          Similar quartets of listings for the remaining 7 methods targeted for manually-written unit tests can be found in Appendix <see ref="appendix:RepresentativeSmeApplications" /> while a list of all the methods transformed in all 3 open-source projects can be found in Appendix <see ref="appendix:AllSmeApplications" />.
          <command name="newpage" />
          <block param="landscape">
            <listing label="lst:BaseCodeBlockModifierModifyLine" file="Textile/base/Textile/Blocks/CodeBlockModifier.cs" linerange="25-43" style="realCode" placement="p">
              C# showing the <tt>base</tt> version of the <tt>ModifyLine()</tt> method of the <tt>CodeBlockModifier</tt> class of the <tt>Textile</tt> project.
            </listing>
            <listing label="lst:ManualCodeBlockModifierModifyLine" file="Textile/manual/Textile/Blocks/CodeBlockModifier.cs" linerange="25-51" style="realCode" placement="p">
              C# showing the <tt>manual</tt> version of the <tt>ModifyLine()</tt> method, after SME plus a few more "introduce variable" refactorings.
            </listing>
            <listing label="lst:BaseCodeBlockModifierModifyLineTest" file="Textile/base/Textile.ManualTests/Blocks/CodeBlockModifierTest.cs" linerange="13-19" style="realCode" placement="h">
              C# showing the test for the <tt>base</tt> version of the <tt>ModifyLine()</tt> method.
            </listing>
            <listing label="lst:ManualCodeBlockModifierModifyLineTest" file="Textile/manual/Textile.ManualTests/Blocks/CodeBlockModifierTest.cs" linerange="23-28" style="realCode" placement="h">
              C# showing the test for the <tt>manual</tt> version of the <tt>ModifyLine()</tt> method.
            </listing>
          </block>
        </command>
        <command name="newpage" />
        <command name="section" param="Results">
          <command name="label" param="sec:Results" />
          Table <see ref="tbl:SummaryResults" /> summarizes the results of the metrics, which have been averaged across the participating open-source projects.  The table is assembled from the results of running the suitability evaluation against the source code as of revision 424 in the public Subversion repository.  Detailed results are presented in the following section, although it is clear that, in general, SME performed no worse and often better than the other strategies.
          <table placement="htbp">
            <tbody spec="p{0.42\textwidth} | R{0.11\textwidth} R{0.11\textwidth} R{0.08\textwidth} R{0.12\textwidth}">
              <tr>
                <td />
                <td multicolumn="{4}{c}">Metrics</td>
              </tr>
              <tr>
                <td>Strategies</td>
                <td>MI IUT<footnote>Maintainability Index of the Implementation Under Test.</footnote></td>
                <td>MI MT<footnote>Maintainability Index of the Manually-written unit Tests.  See <see nameref="subsubsec:complexity" /> in section <see ref="subsubsec:complexity" />.</footnote></td>
                <td>PIC<footnote>Public Interface Changes.  See <see nameref="subsubsec:changesPublicInterface" /> in section <see ref="subsubsec:changesPublicInterface" />.</footnote></td>
                <td>VSP/TSP<footnote>Visited Sequence Points divided by Total Sequence Points.  See <see nameref="subsubsec:codeCoverageConcolic" /> in section <see ref="subsubsec:codeCoverageConcolic" />.</footnote></td>
              </tr>
              <hline />
              <tr>
                <td><tt>base</tt></td>
                <td>83.67</td>
                <td>77.33</td>
                <td>0<footnote>This is the reference point other strategies use to measure public interface changes.</footnote></td>
                <td>52.92%</td>
              </tr>
              <tr>
                <td><tt>visibility-state</tt></td>
                <td>83.67</td>
                <td>76.67</td>
                <td>0</td>
                <td>53.04%</td>
              </tr>
              <tr>
                <td><tt>visibility</tt></td>
                <td>83.67</td>
                <td>77.00</td>
                <td>0</td>
                <td>56.35%</td>
              </tr>
              <tr>
                <td><tt>manual</tt></td>
                <td>84.00</td>
                <td>85.33</td>
                <td>0</td>
                <td>57.92%</td>
              </tr>
              <hline />
              <tr>
                <td>Difference between <tt>manual</tt> and <tt>base</tt></td>
                <td>+0.33</td>
                <td>+8.00</td>
                <td>0</td>
                <td>+5.00%</td>
              </tr>
            </tbody>
            <command name="caption" param="Summary results of the metrics" />
            <command name="label" param="tbl:SummaryResults" />
          </table>
        </command>
        <command name="section" param="Detailed Results">
          <command name="label" param="sec:DetailedResults" />
          The following sub-sections illustrate the results of the individual metrics described in sub-section <see ref="subsec:Metrics" /> and discuss some observations made while running the suitability evaluation.
          <command name="subsection" param="Complexity of the Unit Tests">
            Table <see ref="tbl:complexityResults" /> lists the per-project overall results of running the CMPT tool on the manually-written unit tests to obtain their maintainability index.

            <table placement="htbp">
              <tbody spec="p{0.16\textwidth} | R{0.10\textwidth} R{0.17\textwidth} R{0.17\textwidth} R{0.10\textwidth} | R{0.13\textwidth}">
                <tr>
                  <td />
                  <td multicolumn="{4}{c|}">Strategies</td>
                </tr>
                <tr>
                  <td>Projects</td>
                  <td><tt>base</tt></td>
                  <td><tt>visibility<raw>\newline</raw>-state</tt></td>
                  <td><tt>visibility</tt></td>
                  <td><tt>manual</tt></td>
                  <td>Difference <footnote>Difference between <tt>manual</tt> and <tt>base</tt></footnote></td>
                </tr>
                <hline />
                <tr>
                  <td><tt>Textile</tt></td>
                  <td>78.00</td>
                  <td>76.00</td>
                  <td>76.00</td>
                  <td>85.00</td>
                  <td>+7.00</td>
                </tr>
                <tr>
                  <td><tt>KeePassLib</tt></td>
                  <td>70.00</td>
                  <td>70.00</td>
                  <td>80.00</td>
                  <td>81.00</td>
                  <td>+11.00</td>
                </tr>
                <tr>
                  <td><tt>AtomicCms</tt></td>
                  <td>84.00</td>
                  <td>84.00</td>
                  <td>75.00</td>
                  <td>90.00</td>
                  <td>+6.00</td>
                </tr>
              </tbody>
              <command name="caption" param="Overall Maintainability Index of the unit tests in the \texttt{ManualTests} project per evaluation project, per strategy" />
              <command name="label" param="tbl:complexityResults" />
            </table>

            In the case of the <tt>Textile</tt> project, the slightly lower MI scores for the <tt>visibility</tt> and <tt>visibility-state</tt> strategies are owed to the tests written for <tt>FootNoteFormatterState</tt> and the fact that the increase in visibility allowed for <em>two</em> slightly more precise tests to be written, instead of the <em>one</em> general and indirect test possible in <tt>base</tt>.  Two tests mean more lines of code and therefore a lower overall MI score, but this limitation of the CMPT can be avoided by comparing the MI scores on a per-method basis, as shown in table <see ref="tbl:complexityDetailedResults" />.  There we see that every test method written with a strategy was at least equal to and most of the time better than <tt>base</tt>.  We also see that the <tt>manual</tt> strategy fared much better because it was able to test the most precise parts of the processing involved in the <tt>Enter()</tt> and <tt>OnContextAcquired()</tt> methods in just two lines per test and with less class coupling.

            <table placement="htbp">
              <command name="small" />
              <tbody spec="p{0.004\textwidth} p{0.004\textwidth} p{0.39\textwidth} | @{} R{0.08\textwidth} @{} R{0.10\textwidth} @{} R{0.10\textwidth} @{} R{0.10\textwidth} | @{} R{0.13\textwidth}">
                <tr>
                  <td multicolumn="{3}{l|}">Projects</td>
                  <td multicolumn="{4}{c|}">Strategies</td>
                  <td />
                </tr>
                <tr>
                  <td />
                  <td multicolumn="{2}{l|}">Test classes</td>
                  <td multicolumn="{2}{r@{}}"><tt>visibility</tt></td>
                  <td><tt>visib-</tt></td>
                  <td />
                  <td />
                </tr>
                <tr>
                  <td />
                  <td />
                  <td>Test methods</td>
                  <td><tt>base</tt></td>
                  <td><tt>-state</tt></td>
                  <td><tt>ility</tt></td>
                  <td><tt>manual</tt></td>
                  <td>Difference <footnote>Difference between <tt>manual</tt> and <tt>base</tt></footnote></td>
                </tr>
                <hline />
                <region name="Textile">
                  <tr>
                    <td multicolumn="{3}{l|}"><tt>Textile</tt></td>
                    <td />
                    <td />
                    <td />
                    <td />
                    <td />
                  </tr>
                  <tr>
                    <td />
                    <td multicolumn="{2}{l|}"><tt>CodeBlocksModifierTest</tt></td>
                    <td />
                    <td />
                    <td />
                    <td />
                    <td />
                  </tr>
                  <tr>
                    <td />
                    <td />
                    <td><tt>ModifyLine</tt></td>
                    <td>78.00</td>
                    <td>78.00</td>
                    <td>78.00</td>
                    <td>84.00</td>
                    <td>+6.00</td>
                  </tr>
                  <tr>
                    <td />
                    <td />
                    <td><tt>Conclude</tt></td>
                    <td>78.00</td>
                    <td>78.00</td>
                    <td>78.00</td>
                    <td>84.00</td>
                    <td>+6.00</td>
                  </tr>
                  <tr>
                    <td />
                    <td />
                    <td><tt>CodeFormatMatchEvaluator</tt></td>
                    <td>78.00</td>
                    <td>78.00</td>
                    <td>78.00</td>
                    <td>82.00</td>
                    <td>+4.00</td>
                  </tr>
                  <tr>
                    <td />
                    <td multicolumn="{2}{l|}"><tt>FootNoteFormatterStateTest</tt></td>
                    <td />
                    <td />
                    <td />
                    <td />
                    <td />
                  </tr>
                  <tr>
                    <td />
                    <td />
                    <td><tt>Enter</tt></td>
                    <td multirow="{2}{*}">65.00 <footnote>It is impossible to directly test the <tt>Enter()</tt> and <tt>OnContextAcquired()</tt> methods so a single, indirect test was written.</footnote></td>
                    <td>65.00</td>
                    <td>65.00</td>
                    <td>83.00</td>
                    <td>+18.00</td>
                  </tr>
                  <tr>
                    <td />
                    <td />
                    <td><tt>OnContextAcquired</tt></td>
                    <td />
                    <td>65.00</td>
                    <td>69.00</td>
                    <td>84.00</td>
                    <td>+19.00</td>
                  </tr>
                </region>
                <region name="KeePassLib">
                  <tr>
                    <td multicolumn="{3}{l|}"><tt>KeePassLib</tt></td>
                    <td />
                    <td />
                    <td />
                    <td />
                    <td />
                  </tr>
                  <tr>
                    <td />
                    <td multicolumn="{2}{l|}"><tt>PatternBasedGeneratorTest</tt></td>
                    <td />
                    <td />
                    <td />
                    <td />
                    <td />
                  </tr>
                  <tr>
                    <td />
                    <td />
                    <td><tt>ExpandPattern</tt></td>
                    <td>63.00</td>
                    <td>63.00</td>
                    <td>84.00</td>
                    <td>84.00</td>
                    <td>+21.00</td>
                  </tr>
                  <tr>
                    <td />
                    <td multicolumn="{2}{l|}"><tt>XorredBufferTest</tt></td>
                    <td />
                    <td />
                    <td />
                    <td />
                    <td />
                  </tr>
                  <tr>
                    <td />
                    <td />
                    <td><tt>ChangeKey</tt></td>
                    <td>59.00</td>
                    <td>59.00</td>
                    <td>59.00</td>
                    <td>61.00</td>
                    <td>+2.00</td>
                  </tr>
                </region>
                <region name="AtomicCms">
                  <tr>
                    <td multicolumn="{3}{l|}"><tt>AtomicCms</tt></td>
                    <td />
                    <td />
                    <td />
                    <td />
                    <td />
                  </tr>
                  <tr>
                    <td />
                    <td multicolumn="{2}{l|}"><tt>AdminMenuItemControllerTest</tt></td>
                    <td />
                    <td />
                    <td />
                    <td />
                    <td />
                  </tr>
                  <tr>
                    <td />
                    <td />
                    <td><tt>FormatResultMessage_Created</tt></td>
                    <td>64.00</td>
                    <td>64.00</td>
                    <td>70.00</td>
                    <td>84.00</td>
                    <td>+20.00</td>
                  </tr>
                  <tr>
                    <td />
                    <td />
                    <td><tt>FormatResultMessage_Updated</tt></td>
                    <td>64.00</td>
                    <td>64.00</td>
                    <td>70.00</td>
                    <td>82.00</td>
                    <td>+18.00</td>
                  </tr>
                </region>
              </tbody>
              <command name="caption" param="Detailed breakdown of Maintainability Index scores per method, per strategy" />
              <command name="label" param="tbl:complexityDetailedResults" />
            </table>

            In the case of the <tt>KeePassLib</tt> project, the transformations afforded to the <tt>visibility-state</tt> strategy did not help simplify the unit tests by any significant amount, meaning the unit testing difficulties in these MUTs were not surmountable by simply increasing the visibility of the instance state.  Indeed, the <tt>ExpandPattern()</tt> method is simply not visible to the unit tests, whereas the <tt>ChangeKey()</tt> method operates on state that is initialized from the constructor and from the method parameter, so the results are already easy enough to verify.  As a result, the transformations made in the <tt>visibility</tt> strategy were very similar to those made in the <tt>manual</tt> strategy and thus helped simplify the unit tests similarly.  SME, in this case, was still useful for the input parameter simplification and for making the test inputs explicit, which explains the slight advantage for the <tt>ChangeKey()</tt> method.
            
            In the case of the <tt>AtomicCms</tt> project, the unit testing of the <tt>FormatResultMessage()</tt> method provided a great example of an unwieldy arrange phase.  This is because the constructor of the <tt>AdminMenuItemController</tt> class - in the <tt>base</tt> version - requires two interfaces to be implemented (or mocked), on top of having to indirectly invoke the functionality to be tested (because <tt>FormatResultMessage()</tt> is a private instance method).  The difference these factors make can be seen by comparing listing <see ref="lst:StatefulAdminMenuItemControllerTest" /> and listing <see ref="lst:StatelessAdminMenuItemControllerTest" />: notice that the <tt>arrange</tt> phase has been completely eliminated in the <tt>manual</tt> version.  The need for the <tt>arrange</tt> phase disappeared in the <tt>manual</tt> version because creating an instance of the method's class is no longer required.  The method under test is directly callable, all its inputs are provided as simple parameters and the output is the method's return value.  Contrast this to listing <see ref="lst:StatefulAdminMenuItemControllerTest" />, where an instance is created (lines 5-8 and 26-29), the method under test is indirectly invoked (lines 13 and 34), its parameters need to be constructed (lines 9-10 and 30-31) and the output is derived from instance state (lines 16 and 37).

            <listing label="lst:StatefulAdminMenuItemControllerTest" style="realCode" linerange="109-147" file="Stateful/AdminMenuItemControllerTest.cs">
              C# showing two <tt>AtomicCms</tt> unit tests in the <tt>base</tt> version
            </listing>
            <listing label="lst:StatelessAdminMenuItemControllerTest" style="realCode" linerange="12-36" file="Stateless/AdminMenuItemControllerTest.cs" placement="h">
              C# showing the same two <tt>AtomicCms</tt> unit tests in the <tt>manual</tt> version
            </listing>
            
            <!-- TODO: could talk about (or at least cite) the Mole pattern -->
            
            The <tt>visibility-state</tt> strategy was again ineffective in the <tt>AtomicCms</tt> project because HMS was not the biggest unit testing obstacle.  The <tt>visibility</tt> strategy fared better because it could directly call the method under test, but still needed an arrange phase because an instance of the class needed to be created and the MUT had not benefited from input simplification like it did with the <tt>manual</tt> strategy.
          </command>
          <command name="subsection" param="Number of Changes to the Public Interface of the Class Under Test">
            Table <see ref="tbl:publicInterfaceResults" /> lists the per-project results of running the Public Interface Comparer tool on the IUTs to obtain their number of public interface changes - or differences - relative to the base source code.

            <table placement="htbp">
              <tbody spec="p{0.29\textwidth} | R{0.12\textwidth} R{0.18\textwidth} R{0.18\textwidth} R{0.12\textwidth}">
                <tr>
                  <td />
                  <td multicolumn="{4}{c}">Strategies</td>
                </tr>
                <tr>
                  <td>Projects</td>
                  <td><tt>base</tt></td>
                  <td><tt>visibility<raw>\newline</raw>-state</tt></td>
                  <td><tt>visibility</tt></td>
                  <td><tt>manual</tt></td>
                </tr>
                <hline />
                <tr>
                  <td><tt>Textile</tt></td>
                  <td>n/a</td>
                  <td>0</td>
                  <td>0</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td><tt>KeePassLib</tt></td>
                  <td>n/a</td>
                  <td>0</td>
                  <td>0</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td><tt>AtomicCms</tt></td>
                  <td>n/a</td>
                  <td>0</td>
                  <td>0</td>
                  <td>0</td>
                </tr>
              </tbody>
              <command name="caption" param="Number of changes to the public interface (relative to \texttt{base}) per project, per strategy" />
              <command name="label" param="tbl:publicInterfaceResults" />
            </table>

            This evaluation was mostly to ensure that none of the strategies would transform the IUT in such a way that could change the public interface exposed by the IUT to third-party programs.  It did come in handy during development to correct errors introduced during transformations and the presence of zeros across the results is a testament that all three strategies can be implemented without any changes that would be noticed by consumers of the end-result binaries.
          </command>
          <command name="subsection" param="Percentage of Branches Covered Using Concolic Testing">
            Table <see ref="tbl:percentageConcolicCoverage" /> lists the results of measuring the code coverage percentage achieved by the tests generated by Pex.

            <table placement="htbp">
              <tbody spec="p{0.17\textwidth} | R{0.09\textwidth} R{0.14\textwidth} R{0.175\textwidth} R{0.10\textwidth} | R{0.13\textwidth}">
                <tr>
                  <td />
                  <td multicolumn="{4}{c|}">Strategies</td>
                  <td />
                </tr>
                <tr>
                  <td />
                  <td multicolumn="{2}{r}"><tt>visibility</tt></td>
                  <td />
                  <td />
                  <td />
                </tr>
                <tr>
                  <td>Projects</td>
                  <td><tt>base</tt></td>
                  <td><tt>-state</tt></td>
                  <td><tt>visibility</tt></td>
                  <td><tt>manual</tt></td>
                  <td>Difference <footnote>Difference between <tt>manual</tt> and <tt>base</tt></footnote></td>
                </tr>
                <hline />
                <tr>
                  <td><tt>Textile</tt></td>
                  <td>59.79%</td>
                  <td>60.61%</td>
                  <td>64.13%</td>
                  <td>67.02%</td>
                  <td>+7.23%</td>
                </tr>
                <tr>
                  <td><tt>KeePassLib</tt></td>
                  <td>45.90%</td>
                  <td>46.00%</td>
                  <td>48.33%</td>
                  <td>49.18%</td>
                  <td>+3.28%</td>
                </tr>
                <tr>
                  <td><tt>AtomicCms</tt></td>
                  <td>50.24%</td>
                  <td>50.24%</td>
                  <td>57.85%</td>
                  <td>55.23%</td>
                  <td>+4.99%</td>
                </tr>
              </tbody>
              <command name="caption" param="Percentage of branch code coverage achieved by concolic testing per project, per strategy." />
              <command name="label" param="tbl:percentageConcolicCoverage" />
            </table>

            We can confidently say that the <tt>visibility-state</tt> strategy produced equivalent results to doing nothing, while the <tt>visibility</tt> strategy produced better results and the <tt>manual</tt> strategy produced the best results, save for the <tt>AtomicCms</tt> project.  This is most likely due to the fact that the <tt>AtomicCms</tt> project consists almost entirely of data access code, loading entities from a database into an object model in order to display them in a web page, as well as code to go the other way around.  The project is therefore very state-centric and contains very little of the kind of "pure computations" (such as deterministic data transformations) that lend themselves to be extracted into stateless methods.
            
            The fact that the <tt>visibility</tt> strategy fared better than the <tt>visibility-state</tt> strategy suggests that the biggest obstacle to Pex's quest for coverage is not hidden mutable state but rather methods it cannot reach.  Even so, that may be a necessary condition, but not a sufficient one as the <tt>manual</tt> strategy still outperformed the <tt>visibility</tt> strategy in 2 out of the 3 projects, which suggests that there is merit in what differentiates the <tt>manual</tt> strategy from the <tt>visibility</tt> strategy:  statelessness and input simplification.  <!-- TODO: consider talking about the MI metric on the Pex-generated tests? -->
          </command>
          <!--
          = applying the stateless method extraction technique to the open-source projects
          = applying the technique to examples provided in original paper
          = applying the technique backwards to PivotStack
          = evaluating with code coverage percentage of tests generated by Pex
          = difficulties with Pex:
          == 2010/07/14: "tests generated between runs of Pex are not always the same due to timeouts"
          == not aware of test double opportunities (i.e. mocks)
          == 2010/09/11: "time - it will give up/timeout to not be stuck"
          == 2010/09/11: "intent - unit testing is (validation +) verification exercise using specification/requirements, neither of which are available"
          === "Parameter of abstract type Stream (System.IO) is somewhat vague; there are many implementations of it that could be used, but for unit tests, a MemoryStream should probably ue used. Pex has no such guidance and seems to [randomly?] pick System.Security.Cryptography.TailStream which I can not find in System.Security nor in MSDN documentation!"
          == 2010/09/11: "no focus - unless code is decorated with exclude/ignore attributes"
          == 2010/09/11: "scope"
          === "testability issue" with certain methods, such as:
          ==== Environment.get_NewLine()
          ==== Environment.get_OSVersion()
          ==== File.*
          ==== FileStream..ctor
          === "uninstrumentable" with memory allocation & garbage collection
          === "uninstrumented" source code not available for analysis
          === "extern" behaviour only available at runtime; special case of "uninstrumented"
          === HttpWebRequest (System.Net) does not have a public constructor; the Remarks of the class say to call WebRequest.Create() (which is not instrumented)
          === Neither does Match (System.Text.RegularExpressions) and it is not instrumented anyway.
          = evaluating with metrics (cyclomatic complexity)
          -->
          <!--
          TODO:
          = number of stateless methods extracted per project
          = number of tests generated by Pex
          = number of tests written by hand
          = observations about difficulties, suitabilities, etc.
          -->
        </command>
        <command name="section" param="Validation">
          <command name="label" param="sec:Validation" />
          To help meet the goal, the proposed SME testability refactoring was applied on selected parts of three open-source projects and then compared against three other strategies.

          <table placement="htbp">
            <tbody spec="p{0.01\textwidth} p{0.24\textwidth} | R{0.15\textwidth} R{0.15\textwidth} | R{0.15\textwidth}">
              <tr>
                <td multicolumn="{2}{l|}">Metrics</td>
                <td multicolumn="{2}{c|}">Strategies</td>
                <td />
              </tr>
              <tr>
                <td />
                <td>Projects</td>
                <td>Do nothing</td>
                <td>SME</td>
                <td>Difference</td>
              </tr>
              <hline />
              <tr>
                <td multicolumn="{2}{l|}">MI MT <footnote>Complexity of unit tests: A higher number indicates better maintainability and, consequently, lower complexity.</footnote> (average)</td>
                <td>77.33</td>
                <td>85.33</td>
                <td>+8.00</td>
              </tr>
              <tr>
                <td />
                <td><tt>Textile</tt></td>
                <td>78.00</td>
                <td>85.00</td>
                <td>+7.00</td>
              </tr>
              <tr>
                <td />
                <td><tt>KeePassLib</tt></td>
                <td>70.00</td>
                <td>81.00</td>
                <td>+11.00</td>
              </tr>
              <tr>
                <td />
                <td><tt>AtomicCms</tt></td>
                <td>84.00</td>
                <td>90.00</td>
                <td>+6.00</td>
              </tr>
              <tr>
                <td multicolumn="{2}{l|}">PIC <footnote>Public interface changes: A lower number is better.</footnote> (average)</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
              </tr>
              <tr>
                <td />
                <td><tt>Textile</tt></td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
              </tr>
              <tr>
                <td />
                <td><tt>KeePassLib</tt></td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
              </tr>
              <tr>
                <td />
                <td><tt>AtomicCms</tt></td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
              </tr>
              <tr>
                <td multicolumn="{2}{l|}">VSP/TSP <footnote>The percentage of branches covered using concolic testing. A higher number is better.</footnote> (average)</td>
                <td>52.92%</td>
                <td>57.92%</td>
                <td>+5.00%</td>
              </tr>
              <tr>
                <td />
                <td><tt>Textile</tt></td>
                <td>59.79%</td>
                <td>67.02%</td>
                <td>+7.23%</td>
              </tr>
              <tr>
                <td />
                <td><tt>KeePassLib</tt></td>
                <td>45.90%</td>
                <td>49.18%</td>
                <td>+3.28%</td>
              </tr>
              <tr>
                <td />
                <td><tt>AtomicCms</tt></td>
                <td>50.24%</td>
                <td>55.23%</td>
                <td>+4.99%</td>
              </tr>
            </tbody>
            <command name="caption" param="Comparison of the results between \texttt{base} and \texttt{manual}, on average and per-project." />
            <command name="label" param="tbl:TransposedResults" />
          </table>

          As can be seen in sections <see ref="sec:Results" /> and <see ref="sec:DetailedResults" /> (summarized in table <see ref="tbl:TransposedResults" />), the application of SME on the three test projects had the following general effects on the metrics, relative to the <tt>base</tt> version:
          <block param="enumerate">
            <command name="item"> The complexity of the manually-written unit tests went down.</command>
            <command name="item"> Zero changes to the public interface of the class under test were necessary.</command>
            <command name="item"> The percentage of branches covered using concolic testing went up.</command>
          </block>
          Given the three metrics are better than or equal to the baseline, we have been able to reach the thesis goal to improve the testability of classes that suffer from the "state problem".
          <!-- Cross-reference with Scope and discuss observed trade-offs of other potential approaches -->
        </command>
        <command name="section" param="Summary">
          This chapter introduced the mechanism used to compare SME against three other strategies, the open-source projects with which the experiments and metrics were carried out as well as what tools were used and how.  The results showed that SME improved testing and how the goal was validated.
        </command>
      </command>
      <command name="chapter" param="Conclusion">
        <command name="label" param="chapter:Conclusion" />
        <command name="section" param="Introduction">
          <!-- what the chapter is about -->
          This chapter describes the work that was performed, discusses the results and concludes with ideas for further research.
        </command>
        <command name="section" param="Synopsis">
          <!-- Can be thought of as the companion to the "Outline" section or maybe the Abstract chapter -->
          In chapter <see ref="chapter:Introduction" />, the "state problem" was introduced as a specific problem in the general field of software testing.  Section <see ref="sec:Motivation" /> motivated the importance of the "state problem" as a research topic and section <see ref="sec:Goal" /> introduced the goal of this thesis:  to improve the testability of classes that suffer from the state problem - because they contain hidden, mutable state - while minimally affecting functionality, maintainability and the public interface of the code under test.  These three conditions were converted into three metrics from which the effectiveness of any proposed approach could be evaluated:  complexity of the unit tests, number of changes to the public interface of the class under test and percentage of branches covered using concolic testing.  The chapter concluded with the following objectives in section <see ref="sec:Objectives" />: the development of an approach that addresses the goal, the development of an automated evaluation mechanism to validate the proposed approach, the development of the PIC tool, the application of the approach (as well as two others, for relative comparison purposes) on select open-source projects and the application of the evaluation on the modified open-source projects.

          Related background and work was presented in chapter <see ref="chapter:Background" /> to explain the problem space, establish context and cover previous attempts at solving similar problems in the fields of test generation and program transformation.

          Chapter <see ref="chapter:Approach" /> describes the stateless method extraction approach in section <see ref="sec:Design" />, with many source code examples presented.  Suitability is then discussed in section <see ref="sec:Suitability" />, covering cases other than HMS where SME can be used, followed by SME's best conditions for applicability in section <see ref="sec:Applicability" />.  The PIC tool was described in section <see ref="sec:PublicInterfaceComparer" /> and the chapter concluded with a discussion of intents and their associated consequences in section <see ref="sec:Decisions" />.

          In chapter <see ref="chapter:ResultsValidation" />, an evaluation mechanism was described in section <see ref="sec:EvaluationDesign" /> after which the proposed approach, as well as two others, were applied on three open-source projects so that each approach could be compared against each other as well as against the baseline source code.  Empirical summary and detailed results were presented in sections <see ref="sec:Results" /> and <see ref="sec:DetailedResults" />, respectively.  Lastly, in section <see ref="sec:Validation" /> the results were cross-referenced with the goal's metrics and were shown to validate our approach through concolic testing code coverage increases between 3 to 7 percent, unit test complexity decreases between 6 and 11 points and no changes to the public interface.
        </command>
        <command name="section" param="Bias">
          <command name="label" param="subsec:threats" />
          The following examples identify ways to mitigate bias and its corresponding risk to our results.
          <block param="enumerate">
            <command name="item"> Selection of the open-source projects.
            
              If SME could be automated, it could be applied on a much larger selection of projects - at random or exhaustively - and thus could reduce the bias inherent in the author's selection.
            </command>
            <command name="newpage" />
            <command name="item"> Selection of the representative methods in said open-source projects.
            
              The methods listed in table <see ref="tbl:InterestingMethods" /> were selected at the author's discretion to be targeted for manually-written unit tests.  Writing tests for a random selection of methods or - time-permitting - all methods in all projects would reduce bias, but this could come at the expense of increasing bias in the selection of open-source projects, because the writing of unit tests is a time-consuming process and less projects would have to be selected as a result.
            </command>
            <command name="item"> Manually-written tests.

              The tests that were written for the complexity evaluation suffer from the author's bias and ability.  One way to mitigate this bias - and at the same time reduce the amount of manual labour involved in the evaluation - is to avoid the need for human-generated tests in the first place and to measure the complexity of the tests generated by a computer, such as those by Pex.  This may not be ideal, either, as Pex-generated tests may not necessarily be written to be maintained by humans, but it would have the advantage of objectivity.
            </command>
            <command name="item"> The goal's metrics and the tools used to evaluate them.

              Although the CMPT implements a slight variation of the industry-standard Maintainability Index, said metric is a bit dated (it was originally released in 1997) and has been declared "legacy" by Carnegie Mellon University's Software Engineering Institute.  Nevertheless, the notion of <em>complexity</em> may vary from maintainer to maintainer and thus the measure of the <em>complexity of the unit tests</em> metric is probably best left to the maintainer(s) of each project, even at the expense of the objectivity of a completely-automated evaluation.

              The <em>Public Interface Comparer</em> tool was written by the author (see section <see ref="sec:PublicInterfaceComparer" />) and could contain defects that affect the accuracy of the results.  Some further testing of the tool could reduce its threats to validity.

              The choice of Pex - a <em>concolic testing</em> tool - as a test generator may not be optimal given the <em>state problem</em> was originally reported for <em>evolutionary testing</em> tools.  The unavailability of an ET tool for the .NET platform lead to the use of Pex as a stand-in.  This threat to validity could be reduced by repeating the evaluation in a language or on a platform where an ET tool is available, although new open-source projects would have to be selected and the other parts of the evaluation would have to be ported or replaced with equivalents, such as using JUnit instead of NUnit and Emma instead of NCover.
            </command>
            <command name="item"> Stochastic behaviour of concolic testing.

              Although not as severe as that of metaheuristic search techniques, the Pex tool did present some slight variations in its results due to the use of timeouts in the constraint solver and the nature of running the evaluation on non-dedicated hardware <footnote>Since Pex is configured to be single-threaded and will only saturate one CPU core per run, three independent runs were often scheduled simultaneously on the author's 4-core workstation computer to reduce the total amount of time to wait for the results.  It is likely the runs would have been competing for resources amongst themselves and other processes running on the computer.</footnote>.  The use of dedicated hardware could reduce the variability of the results, while an increase in the number of runs would allow the use of averages to smooth out variability.  However, given the standard deviation observed after 7 runs was no more than 0.28% and averaged 0.14%, this variability was deemed inconsequential compared to the difference between strategies, which was on the order of 3% to 7%.
            </command>
          </block>
          
          <!-- TODO:
          = the evaluation design itself?  For example, an evaluation designed by someone else would probably be better.
          = Lakhotia raises the issue of "stochastic behaviour of the metaheuristic search" and says he's repeated the experiments 30 times; we saw such a small variation with 5 times we didn't feel it was important to mention until now
          = 
          -->
        </command>
        <command name="section" param="Future Work">
          <!-- best ideas of next steps -->
          As was seen in sub-section <see ref="subsec:Strategies" />, there is more than one possible strategy for addressing HMS and there are very likely more strategies, both competing and complementing to SME.  It would be interesting to compare SME to a non-trivial HMS-oriented testability refactoring, both head-to-head and working together.  Example strategies include Binder's "Built-in Test Driver" and "Private Access Driver" <see cite="binder00testharness" />, extracting test "helper" methods <footnote>A variant on SME, the "test helper method extraction" idea adds methods to the test class, abstracting out the unwieldy arrange phase.</footnote> and introducing more "testing seams" <see cite="hevery08staticmethods" />.
          
          As discussed in sub-section <see ref="subsec:threats" />, one way to increase confidence in the results would be to repeat the evaluation with more projects and this would be substantially easier to achieve if the SME technique could be applied automatically, by writing a program able to perform SME on arbitrary source code.

          Although it may be possible to automate the application of SME on the source code of individual projects, most projects have dependencies for which source code is not always available, including that of the base framework.  Some mechanism to manually annotate the API of such opaque dependencies regarding immutability of the classes and statelessness of the methods available would very likely help guide SME, especially for the identification of candidate blocks and simplification of inputs.
          
          <!-- TODO: measure MI of open-source projects' existing MT, submit changes to projects, track MI and coverage as time goes on -->
          <!-- TODO: as mentioned in the threats to validity, different approaches and their trade-offs could be discussed/compared. -->
          <!-- TODO: open-source software vs. closed-source, burdens of maintenance and contracts, etc. -->
        </command>
        <command name="section" param="Closing Thoughts">
          A belief behind this thesis is that a class that is difficult to test because of HMS can be worked around by mechanically transforming its implementation in such a way that simple tests are then trivial to write.  While transforming a class in a manner invisible to its consumers for the purposes of increasing its testability probably has the least overall impact, it is possible - even likely - a better design would provide even better testability.  Such a design change might be risky - or even impossible - depending on the project's non-functional requirements, life cycle, maturity, business pressures and other factors.  The game then becomes that of trade-offs and risks vs. rewards.

          On the other hand and at a higher level, since "testing can only show the presence of defects and not their absence" <see cite="dijkstra69structuredprogramming" />, is an increase in the quantity and/or quality of testing really the best way to address the problem of software quality, given that correctness proofs can be simpler and more powerful <see cite="dijkstra88crueltycomputing" />?  This is probably a question of compatibility:  if a software project was already built with a formal approach, a change in requirements (or formal functional specification) is probably best addressed with corresponding changes to both the program and the proof, whereas in a less formal setting, a similar change in requirements is probably best addressed with an equally informal approach.
          
          In a world where "worse is better" <see cite="gabriel89worsebetter" /> and "something is infinitely better than nothing" <see cite="christensen11reinventingit" />, there are pressures and requirements for incrementally making software better.  The next time a software project needs to be made better due to the presence of hidden, mutable state, there is now a strategy that can improve its testability with minimal impact: stateless method extraction.
        </command>
          <!-- TODO:
          = unsuitability of SME?
          == under-engineered code (big ball of mud)
          == over-engineered code (too many interactions between classes to isolate stateless functionality)
          == not meant as a "extract all methods as statics" hammer
          -->
      </command>
    </command>
    <command name="appendix">
      <!-- material of length that would impede the flow of the -->
      <!-- main body: program listings, long data results, long mathematical -->
      <!-- proofs -->
      <command name="chapter" param="Acronyms">
        <!-- TODO: do we need to turn this into a glossary with explanations? -->
        <block param="description">
          <command name="item" opt="API"> Application Programming Interface</command>
          <command name="item" opt="CT"> Concolic Testing</command>
          <command name="item" opt="CGT"> Computer-Generated Tests</command>
          <command name="item" opt="CMPT"> Code Metrics PowerTool</command>
          <command name="item" opt="CUT"> Class Under Test</command>
          <command name="item" opt="ET"> Evolutionary Testing</command>
          <command name="item" opt="GA"> Genetic Algorithms</command>
          <command name="item" opt="HGT"> Human-Generated Tests</command>
          <command name="item" opt="HMT"> Hidden Mutable State</command>
          <command name="item" opt="IUT"> Implementation Under Test</command>
          <command name="item" opt="MI"> Maintainability Index</command>
          <command name="item" opt="MST"> Metaheuristic Search Technique</command>
          <command name="item" opt="MT"> Manually-written unit Tests</command>
          <command name="item" opt="MUT"> Method Under Test</command>
          <command name="item" opt="OO"> Object-Oriented</command>
          <command name="item" opt="OOP"> Object-Oriented Programming</command>
          <command name="item" opt="PIC"> Public Interface Changes</command>
          <command name="item" opt="RT"> Random Testing</command>
          <command name="item" opt="SBST"> Search-Based Software Testing</command>
          <command name="item" opt="SCA"> Static Code Analysis</command>
          <command name="item" opt="SE"> Symbolic Execution</command>
          <command name="item" opt="SME"> Stateless Method Extraction</command>
          <command name="item" opt="TSP"> Total Sequence Points</command>
          <command name="item" opt="VSP"> Visited Sequence Points</command>
          <command name="item" opt="XSL"> Extensible Stylesheet Language</command>
        </block>
      </command>
      <command name="chapter" param="Representative SME Applications">
        <command name="label" param="appendix:RepresentativeSmeApplications" />
          This appendix contains code samples illustrating the application of SME on the methods targeted for manually-written unit tests - listed in table <see ref="tbl:InterestingMethods" /> - as well as the unit tests targeting the original methods and those targeting the extracted stateless methods.  Table <see ref="tbl:ListingsOfInterestingMethods" /> provides a guide to the code listings.
          <block param="landscape">
            <table placement="p">
              <tabular spec="p{0.005\textwidth} p{0.005\textwidth} p{0.005\textwidth} p{0.7\textwidth} | p{0.07\textwidth} p{0.07\textwidth} p{0.07\textwidth} p{0.07\textwidth}">
                <tr>
                  <td multicolumn="{4}{l|}">Project</td>
                </tr>
                <tr>
                  <td />
                  <td multicolumn="{3}{l|}">Namespace</td>
                  <td multicolumn="{4}{c}">Listings</td>
                </tr>
                <tr>
                  <td />
                  <td />
                  <td multicolumn="{2}{l|}">Class</td>
                  <td>MUT</td>
                  <td>MUT</td>
                  <td>Test</td>
                  <td>Test</td>
                </tr>
                <tr>
                  <td />
                  <td />
                  <td />
                  <td>Method</td>
                  <td>Before</td>
                  <td>After</td>
                  <td>Before</td>
                  <td>After</td>
                </tr>
                <command name="hline" />
                <tr><td multicolumn="{4}{l|}"><tt>Textile</tt></td></tr>
                <region name="Textile.Blocks">
                  <tr>
                    <td></td>
                    <td multicolumn="{3}{l|}"><tt>Textile.Blocks</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td multicolumn="{2}{l|}"><tt>CodeBlockModifier</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td><tt>string ModifyLine(string)</tt></td>
                    <td><see ref="lst:BaseCodeBlockModifierModifyLine" /></td>
                    <td><see ref="lst:ManualCodeBlockModifierModifyLine" /></td>
                    <td><see ref="lst:BaseCodeBlockModifierModifyLineTest" /></td>
                    <td><see ref="lst:ManualCodeBlockModifierModifyLineTest" /></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td><tt>string Conclude(string)</tt></td>
                    <td><see ref="lst:BaseCodeBlockModifierConclude" /></td>
                    <td><see ref="lst:ManualCodeBlockModifierConclude" /></td>
                    <td><see ref="lst:BaseCodeBlockModifierConcludeTest" /></td>
                    <td><see ref="lst:ManualCodeBlockModifierConcludeTest" /></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td><tt>string CodeFormatMatchEvaluator(Match)</tt></td>
                    <td><see ref="lst:BaseCodeBlockModifierCodeFormatMatchEvaluator" /></td>
                    <td><see ref="lst:ManualCodeBlockModifierCodeFormatMatchEvaluator" /></td>
                    <td><see ref="lst:BaseCodeBlockModifierCodeFormatMatchEvaluatorTest" /></td>
                    <td><see ref="lst:ManualCodeBlockModifierCodeFormatMatchEvaluatorTest" /></td>
                  </tr>
                </region>

                <region name="Textile.States">
                  <tr>
                    <td></td>
                    <td multicolumn="{3}{l|}"><tt>Textile.States</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td multicolumn="{2}{l|}"><tt>FootNoteFormatterState</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td><tt>void Enter()</tt></td>
                    <td><see ref="lst:BaseFootNoteFormatterStateEnter" /></td>
                    <td><see ref="lst:ManualFootNoteFormatterStateEnter" /></td>
                    <td><see ref="lst:BaseFootNoteFormatterStateEnterTest" /></td>
                    <td><see ref="lst:ManualFootNoteFormatterStateEnterTest" /></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td><tt>void OnContextAcquired()</tt></td>
                    <td><see ref="lst:BaseFootNoteFormatterStateOnContextAcquired" /></td>
                    <td><see ref="lst:ManualFootNoteFormatterStateOnContextAcquired" /></td>
                    <td><see ref="lst:BaseFootNoteFormatterStateOnContextAcquiredTest" /></td>
                    <td><see ref="lst:ManualFootNoteFormatterStateOnContextAcquiredTest" /></td>
                  </tr>
                </region>

                <tr><td multicolumn="{4}{l|}"><tt>KeePassLib</tt></td></tr>
                <region name="KeePassLib.Cryptography.PasswordGenerator">
                  <tr>
                    <td></td>
                    <td multicolumn="{3}{l|}"><tt>KeePassLib.Cryptography.PasswordGenerator</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td multicolumn="{2}{l|}"><tt>PatternBasedGenerator</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td><tt>string ExpandPattern(string)</tt></td>
                    <td><see ref="lst:BasePatternBasedGeneratorExpandPattern" /></td>
                    <td><see ref="lst:ManualPatternBasedGeneratorExpandPattern" /></td>
                    <td><see ref="lst:BasePatternBasedGeneratorExpandPatternTest" /></td>
                    <td><see ref="lst:ManualPatternBasedGeneratorExpandPatternTest" /></td>
                  </tr>
                </region>
                <region name="KeePassLib.Security">
                  <tr>
                    <td></td>
                    <td multicolumn="{3}{l|}"><tt>KeePassLib.Security</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td multicolumn="{2}{l|}"><tt>XorredBuffer</tt></td>
                  </tr>
                  <tr>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td><tt>byte[] ChangeKey(byte[])</tt></td>
                    <td><see ref="lst:BaseXorredBufferChangeKey" /></td>
                    <td><see ref="lst:ManualXorredBufferChangeKey" /></td>
                    <td><see ref="lst:BaseXorredBufferChangeKeyTest" /></td>
                    <td><see ref="lst:ManualXorredBufferChangeKeyTest" /></td>
                  </tr>
                </region>
                <tr><td multicolumn="{4}{l|}"><tt>AtomicCms</tt></td></tr>
                <region name="AtomicCms.Web.Controllers">
                  <tr>
                    <td />
                    <td multicolumn="{3}{l|}"><tt>AtomicCms.Web.Controllers</tt></td>
                  </tr>
                  <tr>
                    <td />
                    <td />
                    <td multicolumn="{2}{l|}"><tt>AdminMenuItemController</tt></td>
                  </tr>
                  <tr>
                    <td />
                    <td />
                    <td />
                    <td><tt>void FormatResultMessage(IMenuItem, int?)</tt></td>
                    <td><see ref="lst:BaseAdminMenuItemControllerFormatResultMessage" /></td>
                    <td><see ref="lst:ManualAdminMenuItemControllerFormatResultMessage" /></td>
                    <td><see ref="lst:BaseAdminMenuItemControllerFormatResultMessageTest" /></td>
                    <td><see ref="lst:ManualAdminMenuItemControllerFormatResultMessageTest" /></td>
                  </tr>
                </region>
              </tabular>
              <command name="caption" param="Methods targeted for manually-written unit tests and their corresponding listings" />
              <command name="label" param="tbl:ListingsOfInterestingMethods" />
            </table>
          </block>
          <command name="newpage" />
          <block param="landscape">
            <region name="string Conclude(string)">
              <listing label="lst:BaseCodeBlockModifierConclude" file="Textile/base/Textile/Blocks/CodeBlockModifier.cs" linerange="45-53" style="realCode" placement="t">
                C# showing the <tt>base</tt> version of the <tt>Conclude()</tt> method of the <tt>CodeBlockModifier</tt> class of the <tt>Textile</tt> project.
              </listing>
              <listing label="lst:ManualCodeBlockModifierConclude" file="Textile/manual/Textile/Blocks/CodeBlockModifier.cs" linerange="53-66" style="realCode" placement="b">
                C# showing the <tt>manual</tt> version of the <tt>Conclude()</tt> method, after SME.
              </listing>
              <listing label="lst:BaseCodeBlockModifierConcludeTest" file="Textile/base/Textile.ManualTests/Blocks/CodeBlockModifierTest.cs" linerange="21-28" style="realCode">
                C# showing the test for the <tt>base</tt> version of the <tt>Conclude()</tt> method.
              </listing>
              <listing label="lst:ManualCodeBlockModifierConcludeTest" file="Textile/manual/Textile.ManualTests/Blocks/CodeBlockModifierTest.cs" linerange="30-36" style="realCode">
                C# showing the test for the <tt>manual</tt> version of the <tt>Conclude()</tt> method.
              </listing>
            </region>
            <region name="string CodeFormatMatchEvaluator(Match)">
              <listing label="lst:BaseCodeBlockModifierCodeFormatMatchEvaluator" file="Textile/base/Textile/Blocks/CodeBlockModifier.cs" linerange="55-62" style="realCode" placement="t">
                C# showing the <tt>base</tt> version of the <tt>CodeFormatMatchEvaluator()</tt> method of the <tt>CodeBlockModifier</tt> class of the <tt>Textile</tt> project.
              </listing>
              <listing label="lst:ManualCodeBlockModifierCodeFormatMatchEvaluator" file="Textile/manual/Textile/Blocks/CodeBlockModifier.cs" linerange="68-84" style="realCode" placement="b">
                C# showing the <tt>manual</tt> version of the <tt>CodeFormatMatchEvaluator()</tt> method, after SME.
              </listing>
              <listing label="lst:BaseCodeBlockModifierCodeFormatMatchEvaluatorTest" file="Textile/base/Textile.ManualTests/Blocks/CodeBlockModifierTest.cs" linerange="30-42" style="realCode">
                C# showing the test for the <tt>base</tt> version of the <tt>CodeFormatMatchEvaluator()</tt> method.
              </listing>
              <listing label="lst:ManualCodeBlockModifierCodeFormatMatchEvaluatorTest" file="Textile/manual/Textile.ManualTests/Blocks/CodeBlockModifierTest.cs" linerange="38-43" style="realCode">
                C# showing the test for the <tt>manual</tt> version of the <tt>CodeFormatMatchEvaluator()</tt> method.
              </listing>
            </region>
            <region name="void Enter()">
              <listing label="lst:BaseFootNoteFormatterStateEnter" file="Textile/base/Textile/States/FootNoteFormatterState.cs" linerange="33-40" style="realCode" placement="t">
                C# showing the <tt>base</tt> version of the <tt>Enter()</tt> method of the <tt>FootNoteFormatterState</tt> class of the <tt>Textile</tt> project.
              </listing>
              <listing label="lst:ManualFootNoteFormatterStateEnter" file="Textile/manual/Textile/States/FootNoteFormatterState.cs" linerange="33-45" style="realCode" placement="b">
                C# showing the <tt>manual</tt> version of the <tt>Enter()</tt> method, after SME.
              </listing>
              <listing label="lst:BaseFootNoteFormatterStateEnterTest" file="Textile/base/Textile.ManualTests/States/FootNoteFormatterStateTest.cs" linerange="13-30" style="realCode">
                C# showing the test for the <tt>base</tt> version of the <tt>Enter()</tt> method.
              </listing>
              <listing label="lst:ManualFootNoteFormatterStateEnterTest" file="Textile/manual/Textile.ManualTests/States/FootNoteFormatterStateTest.cs" linerange="15-23" style="realCode">
                C# showing the test for the <tt>manual</tt> version of the <tt>Enter()</tt> method.
              </listing>
            </region>
            <region name="void OnContextAcquired()">
              <listing label="lst:BaseFootNoteFormatterStateOnContextAcquired" file="Textile/base/Textile/States/FootNoteFormatterState.cs" linerange="56-60" style="realCode" placement="t">
                C# showing the <tt>base</tt> version of the <tt>OnContextAcquired()</tt> method of the <tt>FootNoteFormatterState</tt> class of the <tt>Textile</tt> project.
              </listing>
              <listing label="lst:ManualFootNoteFormatterStateOnContextAcquired" file="Textile/manual/Textile/States/FootNoteFormatterState.cs" linerange="61-70" style="realCode" placement="b">
                C# showing the <tt>manual</tt> version of the <tt>OnContextAcquired()</tt> method, after SME.
              </listing>
              <listing label="lst:BaseFootNoteFormatterStateOnContextAcquiredTest" file="Textile/base/Textile.ManualTests/States/FootNoteFormatterStateTest.cs" linerange="13-30" style="realCode">
                C# showing the test for the <tt>base</tt> version of the <tt>OnContextAcquired()</tt> method.
              </listing>
              <listing label="lst:ManualFootNoteFormatterStateOnContextAcquiredTest" file="Textile/manual/Textile.ManualTests/States/FootNoteFormatterStateTest.cs" linerange="28-36" style="realCode">
                C# showing the test for the <tt>manual</tt> version of the <tt>OnContextAcquired()</tt> method.
              </listing>
            </region>
            <region name="string ExpandPattern(string)">
              <listing label="lst:BasePatternBasedGeneratorExpandPattern" file="KeePassLib/base/KeePassLib/Cryptography/PasswordGenerator/PatternBasedGenerator.cs" linerange="129-157" style="realCode" placement="p">
                C# showing the <tt>base</tt> version of the <tt>ExpandPattern()</tt> method of the <tt>PatternBasedGenerator</tt> class of the <tt>KeePassLib</tt> project.
              </listing>
              <listing label="lst:ManualPatternBasedGeneratorExpandPattern" file="KeePassLib/manual/KeePassLib/Cryptography/PasswordGenerator/PatternBasedGenerator.cs" linerange="129-157" style="realCode" placement="p">
                C# showing the <tt>manual</tt> version of the <tt>ExpandPattern()</tt> method, after SME.
              </listing>
              <listing label="lst:BasePatternBasedGeneratorExpandPatternTest" file="KeePassLib/base/KeePassLib.ManualTests/Cryptography/PasswordGenerator/PatternBasedGeneratorTest.cs" linerange="14-32" style="realCode">
                C# showing the test for the <tt>base</tt> version of the <tt>ExpandPattern()</tt> method.
              </listing>
              <listing label="lst:ManualPatternBasedGeneratorExpandPatternTest" file="KeePassLib/manual/KeePassLib.ManualTests/Cryptography/PasswordGenerator/PatternBasedGeneratorTest.cs" linerange="12-17" style="realCode">
                C# showing the test for the <tt>manual</tt> version of the <tt>ExpandPattern()</tt> method.
              </listing>
            </region>
            <region name="byte[] ChangeKey(byte[])">
              <listing label="lst:BaseXorredBufferChangeKey" file="KeePassLib/base/KeePassLib/Security/XorredBuffer.cs" linerange="107-127" style="realCode" placement="p">
                C# showing the <tt>base</tt> version of the <tt>ChangeKey()</tt> method of the <tt>XorredBuffer</tt> class of the <tt>KeePassLib</tt> project.
              </listing>
              <listing label="lst:ManualXorredBufferChangeKey" file="KeePassLib/manual/KeePassLib/Security/XorredBuffer.cs" linerange="107-134" style="realCode" placement="p">
                C# showing the <tt>manual</tt> version of the <tt>ChangeKey()</tt> method, after SME.
              </listing>
              <listing label="lst:BaseXorredBufferChangeKeyTest" file="KeePassLib/base/KeePassLib.ManualTests/Security/XorredBufferTest.cs" linerange="12-36" style="realCode">
                C# showing the test for the <tt>base</tt> version of the <tt>ChangeKey()</tt> method.
              </listing>
              <listing label="lst:ManualXorredBufferChangeKeyTest" file="KeePassLib/manual/KeePassLib.ManualTests/Security/XorredBufferTest.cs" linerange="12-34" style="realCode">
                C# showing the test for the <tt>manual</tt> version of the <tt>ChangeKey()</tt> method.
              </listing>
            </region>
            <command name="newpage" />
            <region name="void FormatResultMessage(IMenuItem, int?)">
              <listing label="lst:BaseAdminMenuItemControllerFormatResultMessage" file="AtomicCms/base/AtomicCms/Controllers/AdminMenuItemController.cs" linerange="66-77" style="realCode" placement="t">
                C# showing the <tt>base</tt> version of the <tt>FormatResultMessage()</tt> method of the <tt>AdminMenuItemController</tt> class of the <tt>AtomicCms</tt> project.
              </listing>
              <listing label="lst:ManualAdminMenuItemControllerFormatResultMessage" file="AtomicCms/manual/AtomicCms/Controllers/AdminMenuItemController.cs" linerange="66-84" style="realCode" placement="b">
                C# showing the <tt>manual</tt> version of the <tt>FormatResultMessage()</tt> method, after SME.
              </listing>
              <listing label="lst:BaseAdminMenuItemControllerFormatResultMessageTest" file="AtomicCms/base/AtomicCms.ManualTests/Web/Controllers/AdminMenuItemControllerTest.cs" linerange="114-138" style="realCode">
                C# showing the test for the <tt>base</tt> version of the <tt>FormatResultMessage()</tt> method.
              </listing>
              <listing label="lst:ManualAdminMenuItemControllerFormatResultMessageTest" file="AtomicCms/manual/AtomicCms.ManualTests/Web/Controllers/AdminMenuItemControllerTest.cs" linerange="12-20" style="realCode">
                C# showing the test for the <tt>manual</tt> version of the <tt>FormatResultMessage()</tt> method.
              </listing>
            </region>
          </block>
      </command>
      <command name="chapter" param="SME Applications">
        <command name="label" param="appendix:AllSmeApplications" />
        The following pages list all the methods that were transformed with SME, notes regarding the transformation and the revision in the Subversion repository where the changes took place.
        <!-- TODO: could explain the URL looks like <url>http://code.google.com/p/testoriented/source/detail?r=535</url> -->
        <command name="includepdf" param="SmeApplications.pdf" opt="scale=0.8,offset=1.5em 0,pages={-},fitpaper=true,pagecommand=\thispagestyle{plain}" />
      </command>
      <command name="chapter" param="Raw Data Spreadsheet">
        <command name="label" param="appendix:Spreadsheet" />
        The following pages reproduce the "Raw data" sheet of the online spreadsheet<footnote>The online spreadsheet can be seen at <url>https://docs.google.com/spreadsheet/ccc?key=0Ag6eugnyWA09dG9zQnFtTlQ0Z1dGUjI5TUlFMnpFWWc</url></footnote>, which was used by the "Record results" step described in section <see ref="subsec:HowItWorks" />.  The spreadsheet contains every row submitted to it by this step, with many of these rows created by investigating various tests and tweaks.  Its columns are explained in table <see ref="tbl:SpreadsheetColumns" />.  Notes were occasionally added in the "Notes" column to explain the test or tweak being investigated.
        <table placement="htbp">
          <tbody spec="p{0.2\textwidth} p{0.75\textwidth}">
            <tr><td>Column name</td><td>Description</td></tr>
            <hline />
            <tr><td>Timestamp</td><td>The date and time the result row was inserted</td></tr>
            <tr><td>Batch #</td><td>The revision of the Subversion repository or <tt>private</tt> if run for testing purposes instead of in a batch</td></tr>
            <tr><td>Project</td><td>The name of the project</td></tr>
            <tr><td>Strategy</td><td>The name of the strategy employed</td></tr>
            <tr><td>TSP</td><td>Total Sequence Points, the denominator for code coverage percentage calculation</td></tr>
            <tr><td>VSP</td><td>Visited Sequence Points, the numerator for code coverage percentage calculation</td></tr>
            <tr><td>PIC</td><td>Public Interface Changes</td></tr>
            <tr><td>MI IUT</td><td>Maintainability Index of the Implementation Under Test</td></tr>
            <tr><td>MI MT</td><td>Maintainability Index of the Manually-written unit Tests</td></tr>
          </tbody>
          <command name="caption" param="Names and descriptions of the columns in the ``Raw data&quot; sheet of the online results spreadsheet." />
          <command name="label" param="tbl:SpreadsheetColumns" />
        </table>
        <command name="includepdf" param="RawDataSpreadsheet.pdf" opt="scale=0.8,offset=1.5em 0,pages={-},fitpaper=true,pagecommand=\thispagestyle{plain}" />
      </command>
    </command>
    <command name="bibliographystyle" param="abbrv" />
    <command name="bibliography" param="thesis" />
  </document>
</iTeX>