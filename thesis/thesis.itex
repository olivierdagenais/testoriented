<?xml version="1.0" encoding="UTF-8"?>
<iTeX>
  <preamble><!-- !TEX TS-program = pdflatex -->
    <!-- !TEX encoding = UTF-8 Unicode -->

    <command name="documentclass" opt="12pt" param="dalthesis" />

    <region comment='disable turning "fi", "ff", etc. into one character'>
      <command name="usepackage" param="fontspec" />
      <command name="setmonofont" param="Courier New" />
      <command name="setmainfont" opt="Mapping=tex-text,Ligatures={NoCommon,NoRare}" param="Latin Modern Roman" />
    </region>

    <command name="usepackage" param="array" />

    <region comment='the "listings" package is used for source code snippets'>
      <command name="usepackage" param="listings" />
      <command name="lstset" param="tabsize=2" />
      <command name="lstdefinestyle" param="realCode}{basicstyle=\tiny\ttfamily, numbers=left, numberstyle=\tiny\ttfamily" />
      <command name="lstdefinestyle" param="pseudoCode}{basicstyle=\small, numbers=none" />
      <!-- Override the lstinputlisting command to surround it inside braces,
      otherwise the style parameter does not work:
        http://tex.stackexchange.com/q/21663/1892
        http://stackoverflow.com/questions/2908908/#2909530
      -->
      <raw>\let\originallstinputlisting\lstinputlisting</raw>
      <raw>\renewcommand{\lstinputlisting}[2][]{{\originallstinputlisting[{#1}]{#2}}}</raw>
    </region>

    <region comment="URLs and references are hyperlinked">
      <command name="usepackage" param="url" />
      <command name="usepackage" param="hyperref" opt="pdftitle={Stateless Programming And Testing: Extracting a functional layer from object-oriented code},pdfauthor={Olivier Dagenais},colorlinks=true,linkcolor=black,anchorcolor=black,citecolor=black,citecolor=black,urlcolor=black,pdftex=true" />
    </region>

    <command name="usepackage" param="nameref" />
  </preamble>
  <document>
    <region name="Title page">
      <command name="title" param="Stateless Programming And Testing: \\ Extracting a functional layer from object-oriented code" />
      <command name="author" param="Olivier Dagenais" />
      <command name="submitdate" param="July 29, 2011" />
      <command name="copyrightyear" param="2011" />
      <command name="degree" param="Master of Computer Science" />
    </region>

    <command name="frontmatter">
      <region name="[List of] Listings">
        <command name="addcontentsline" param="toc}{chapter}{Listings" />
        <command name="lstlistoflistings" />
        <command name="clearpage" />
      </region>
      <block param="abstract">
        <!-- An abstract is required in all theses. -->
        <!-- Make sure that it fits on one page! -->
      </block>
      <block param="acknowledgements">
        <!-- This is the acknowledgements. -->
        <!-- It is optional. -->
      </block>
    </command>
    <command name="mainmatter">
      <command name="chapter" param="Introduction">
        <command name="section" param="Introduction">
          This chapter introduces the problem and the motivation for solving it, as well as the overall goal and specific objectives.  It concludes with an overview of the rest of the document.
        </command>
        <command name="section" param="Problem">
          Software has advanced considerably in the last several years, but has software quality kept up?  We do not always know how good a program or component is or if it is free of defects, if only those defects that will affect us, directly or otherwise.  Software defects can range from the benign, such as incorrect colors and typographical errors in the interface or output, to very serious, such as causing the destruction of a rocket carrying four satellites <see cite="lions96ariane, esa05clustermission" /> or causing the death of several patients <see cite="leveson95medicaldevices" />.

          Programming languages and compilers evolved to add features that make it easier to write code, although those features do not always make it easier to test the same code.  Object-oriented programming (OOP), for example, has introduced constructs and paradigms designed to make abstraction, inheritance and polymorphism easier, but at the same time introduced a feature that can make testing more difficult:  encapsulation (information hiding) in the form of instance state.  Encapsulation allows an object to hide its implementation details so as to present a simpler interface to callers.  Indeed, Alan Kay describes this simpler, higher-level interaction between objects as "goals", replacing low-level assignments: "Again, the whole point of OOP is <u>not</u> to have to worry about what is <em>inside</em> an object." <see cite="kay93earlyhistory" />

          Hidden and mutable instance state poses a problem for automated unit testing because that instance state may come into play when exercising a specific scenario <see cite="binder00testharness" />.  Since the instance state is mutable, the values may not be initialized at instance construction or can change as instance methods are called.  Because the instance state is hidden, there exists, by definition, no way to manipulate this instance state directly.  Separately, hidden (but immutable) instance state or mutable (but visible) instance state do not provide too many difficulties for test writing.  It is the combination of the hidden and mutable properties that makes it difficult to write tests.

          <command name="subsection" param="Hidden mutable state, described">
            Hidden mutable state (HMS) manifests itself in a few different forms:
            <block param="itemize">
              <command name="item"> Instance state that cannot be set from the constructor or a factory method.</command>
              <command name="item"> Instance state that cannot be directly set from a setter method or property.</command>
              <command name="item"> A constructor or direct factory method is not available.  For example, an instance can only be created as a by-product of a method call on another class.</command>
              <command name="item"> Instance state points to objects with their own hidden mutable state.</command>
            </block>
            In summary, a class with hidden mutable state has variables or fields that must be set or modified indirectly as a result of calling a method that, although not necessarily directly related, modifies one or more variables or fields.
          </command>

          Hidden mutable state results in difficult-to-test code, which means it remains untested, even despite the many automated test frameworks and systems available <see cite="aberdour07dotnetunit" />.  This is likely due to a trade-off between ease of maintenance and testability, where testability was ultimately not favoured.

          We still want to test the code, but we must first surmount the difficult-to-test obstacle that hidden mutable state introduces:
          <block param="quote">
            "It is often difficult to control the pretest state of the [Implementation Under Test (IUT)].  The instance variables of the IUT are encapsulated and often composed of still more uncontrollable objects.  The interface of the IUT is typically insufficient for testing purposes. (...) Although existing IUT methods can be used to control state, they often do not provide all access needed and can produce spurious test results if they are buggy.  They maybe not even exist, if their development has been deferred to a later increment or they are part of an abstract class. (...) Observing the post-test state of the IUT is often difficult, for the same reasons that controlling the pretest state is difficult." <see cite="binder00testharness" />
          </block>

          In the process of testing a method that uses hidden instance state (as input, output or both), it usually becomes necessary to write the unit test such that it will indirectly orchestrate said instance state so that specific scenarios can be implemented.  This makes the test method difficult to maintain because the test will be more unwieldy and less obvious - especially in the "arrange" phase - which may discourage the creation of such tests.

          An example of the state problem can be seen in listings <see ref="lst:StatefulSmokeDetector" /> and <see ref="lst:StatefulSmokeDetectorTest" />.  This demonstrates how having all the instance fields private forces any test wishing to bring the object to a certain state - such as "alarm sounds while detection decays" - to repeatedly call the <tt>Cycle()</tt> method with various values provided to the <tt>level</tt> parameter.  By the same token, the only observable state for verification is the return value of the method, although, in this particular instance, this should be sufficient for most test scenarios.
        </command>
        <command name="section" param="Motivation">
          <!-- TODO:
          = should I motivate [unit] testing more, like I did in my paper?
          = how about talking about the applicability to code that is currently without tests or with insufficient tests
          -->
          Lest we could somehow perform the practically impossible "complete testing" (in other words, exhaustively trying all possible inputs), testing can only show the presence of defects and not their absence <see cite="dijkstra69structuredprogramming" />.  A good set of automated tests, on the other hand, can catch software regressions that may be introduced through the addition of a feature or the removal of a defect.  Finding - and fixing - regressions as early as possible ensures the fixing cost is minimized <see cite="spolsky00joeltest, patton05softwaretesting" />.  A good set of automated tests is henceforth defined as one that can catch such software regressions.

          <!-- TODO: should the listings use a figure with subfloats, instead? -->
          <region name="table and two stateful code listings">
            <raw>\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}</raw>
            <command name="lstinputlisting"
              opt="label=lst:StatefulSmokeDetector,caption=SmokeDetector class with hidden mutable state,style=realCode"
              param="Stateful/SmokeDetector.cs" />
            <raw>&amp;</raw>
            <command name="lstinputlisting"
              opt="label=lst:StatefulSmokeDetectorTest,caption=Test class for the SmokeDetector,style=realCode"
              param="Stateful/SmokeDetectorTest.cs" />
            <raw>\end{tabular}</raw>
          </region>

          A metric commonly used to represent confidence in a set of automated tests is code coverage percentage, usually in the form of statement coverage <see cite="sink06advocatingcoverage" />.  Code that is covered might be - but is not necessarily - tested, but uncovered code is definitely untested code <see cite="binder00classes" />.  Shipping software with untested code is like serving a dish that has not yet been tasted. <!-- can quote [Rapps+85, 367], which is reprinted in Binder, page 67 -->

          HMS does not just present trouble to tests written by programmers - henceforth referred to as human-generated tests (HGT) - but also to computer-generated tests (CGT), such as those generated through Evolutionary Testing (ET), a form of Search Based Software Testing.  <!-- TODO: does Concolic Testing also suffer from the state problem? -->  Indeed, McMinn reported on the difficulty HMS brought to ET:
          <block param="quote">
            "States can cause a variety of problems for ET, since test goals involving states can be dependent on the entire history of input to the test object, as well as just the current input." <see cite="mcminn03thestate" />
          </block>

          Although it is possible to work around some HMS with a noteworthy "arrange" phase, this is not always desirable as it can increase the maintenance overhead and costs to write the unit tests, both for human- and computer-generated tests.  There are other obvious options available, such as increasing the visibility of the mutable state or converting the state from mutable to read-only.  Unfortunately, both of these options would likely change the public interface of the class under test to an unacceptable level (such as breaking encapsulation), not to mention the associated risk in performing non-trivial modifications (in the latter case) without the safety net of sufficient tests.

          One perhaps less obvious option is the extraction of a subset of the state<em>ful</em> functionality in the form of a state<em>less</em> method which has all its inputs and outputs available to the test driver, while sourcing those inputs and outputs from and to the very instance fields they represent within the implementation itself.  An example of this can be seen in listings <see ref="lst:StatelessSmokeDetector" /> and <see ref="lst:StatelessSmokeDetectorTest" />.  The original implementation of the <tt>Cycle()</tt> method has been trivially extracted into a static overload that accepts all its input and emits all its output through parameters and the method return value.  The <tt>AccumulateDetection()</tt> test method can then be written to supply values for all parameters, while keeping the fields that the parameters would be initialized from safe from modification.  Indeed, the previous test is still there, unchanged, since the <tt>SmokeDetector</tt>'s public interface did not change as a result of performing this transformation.

          <!-- TODO: should the listings use a figure with subfloats, instead? -->
          <region name="table and two stateless code listings">
            <raw>\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}</raw>
            <command name="lstinputlisting"
              opt="label=lst:StatelessSmokeDetector,caption=SmokeDetector class with a stateless method extracted,style=realCode"
              param="Stateless/SmokeDetector.cs" />
            <raw>&amp;</raw>
            <command name="lstinputlisting"
              opt="label=lst:StatelessSmokeDetectorTest,caption=Test class for SmokeDetector exploiting the new Cycle() method overload,style=realCode"
              param="Stateless/SmokeDetectorTest.cs" />
            <raw>\end{tabular}</raw>
          </region>
        </command>
        <command name="section" param="Goal">
          <!-- Can address only part of the problem
          Something abstract/general, such as "world hunger", or a subset of it "hunger in Ottawa"
          Can be written retroactively, after the results have been written -->
          If we are to overcome the difficulties of HMS, can we do so with minimal changes to the public interface and with minimal risk of introducing regressions?  Can the unit tests be kept parsimonious, yet cover all the important edge cases?  Is there something we can do to make code containing hidden mutable state more easily testable?

          The goal of this thesis is to improve the testability of classes that suffer from the "state problem" - because they contain HMS - while minimally affecting functionality, maintainability and the public interface of the code under test.  The goal is to be validated according to the following metrics:

          <block param="enumerate">
            <command name="item"> Complexity of the unit tests.
            <!--
- Applying the Single Responsibility Principle (from SOLID) leads to extracting small methods
- stateless methods are referentially transparent
- "Why Functional Programming Matters" argues "We conclude that since modularity is the key to successful programming, functional programming offers important advantages for software development."
- what if I show there are no changes to any of the common metrics when SME is used?  That would count as "no worse than before"
- if the MUT is "testable", the test will be small (low number of statements)
- LOC seems to be bad when evaluating benchmarks and baselines and comparing against other languages (i.e. Jones' business), but otherwise OK
- I could present the results with the appropriate caveats (i.e. less logical SLOC per unit test method means simpler tests, but it also means entirely different tests; tests that simply were not possible before.  For example, before, the test would have been monolithic, whereas now there could be three small, focused tests that perform the same work)
- unless I have a source that says smaller methods are better/make better tests, etc., I don't have much to go by for size of unit tests
- many of my examples have been too conveniently transformable; there's lots of code I encounter that would be more difficult to test and SME wouldn't help - there's something more complicated needed, such as extracting a new class (single responsibility principle)
- Binder, chapter 13, talks about "Bottom-up Integration" which reads "Components with the least number of dependencies are tested first.  When these components pass, their drivers are replaced with their clients; another round of testing then begins."
- Binder, chapter 19 has "Test Case/Test Suite Method" which describes a lot of xUnit.
- Binder page 69 talks about defect density relative to number of code changes
            -->
            </command>
            <command name="item"> Number of changes to the public interface of the class under test.</command>
            <command name="item"> Percentage of branches covered using concolic testing <see cite="lakhotia10empiricalinvestigation" />.
            <!-- TODO: can maintainability be measured? -->
            <!-- TODO:
            = can I measure the risk of introducing defects or regressions?
            = in other words, what is the safety of the testability transformation/refactoring?
            -->
            </command>
          </block>
          <!--
          = even though I mention ET in the motivation section, I have no goal to evaluate anything for ET???
          = is there a mention of instance state (i.e. HMS) being a problem for Pex or concolic testing in general?
          == my experiments with Pex were designed to have it be the objective evaluator, such that if Pex is unable to create an instance of a class, it is unlikely a human will have an easy time.  This is mostly for the case where a class has no constructor and no easy factory method.
          == Pex is documented as handling ALL state with the help of a shadow interpreter
          == "But then Pex may not know how to create an object through the publicly available constructors such that the object's private fields are in the desired state." (Pex)
          == "If the class is visible and has a visible default constructor, Pex can create an instance of the class. If all the fields are visible, it can generate values for them as well. However, if the fields are encapsulated with properties or not exposed to the outside world, Pex requires help to create the object so as to achieve a better code coverage." http://msdn.microsoft.com/en-us/magazine/ee819140.aspx
          ==
          """
          Warning: field xxx is not public; Pex needs help to construct object (or similar)

Pex generates test inputs, and part of the inputs may be objects with fields. Here, Pex wants to generate an instance of an object which has a private field, and Pex believes that an interesting program behavior will occur when this private field has a particular value. However, while possible with Reflection, Pex does not dare to manufacture objects with arbitrary field values. Instead, in those cases it relies on the user to provide hints how to use the public methods of a class to create an object and bring it into a state where its private field has the desired value.
          """
http://research.microsoft.com/en-us/um/redmond/projects/pex/wiki/pex%20needs%20help%20to%20construct%20object.html
          === I should be able to find instances where Pex can not
          -->
        </command>
        <command name="section" param="Objectives">
          <!-- (what you will produce to meet your goal)
          action items to address goal -->
          To meet the goal, a testability refactoring <see cite="harman11refactoringtestability" /> algorithm called "stateless method extraction" (SME) is proposed and explained/detailed.  The SME algorithm transforms the source code of the implementation under test (IUT) to introduce a functional, or "externally state-free", software layer to specifically work around many of the testability problems of HMS and to generally increase the testability of the code under test.  The SME algorithm's efficiency and effectiveness will be evaluated by comparing the results of the algorithm's application to other testing approaches.
        </command>
        <command name="section" param="Outline">
          ...
          The <!-- ref: Approach --> chapter covers the details, the how-tos and the applicability of the proposed testability refactoring.
        </command>
        <command name="section" param="Summary">
          <!-- key points of what was presented and linkage to next chapter -->
          ...
        </command>
      </command>
      <command name="chapter" param="Background">
        <command name="section" param="Introduction">
          This chapter presents an overview of the related concepts from object-oriented (OO) programming to automated testing to computer-generated tests, introduces related work, establishes context within that work and defines the scope of the thesis.
        </command>
        <command name="section" param="Object Oriented Programming">
          This thesis focuses on testing programs written with OO languages, as opposed to procedural or functional languages because the intent is to solve a problem specific to OO languages:  hidden mutable state.  Although procedural languages (such as C) allow programs to have mutable state, the state is not hidden.  Functional languages (such as Lisp) on the other hand, allow programs to be written using immutable state through the use of set-once variables.

          <command name="subsection" param="Terminology">
            OO languages will generally have a basic set of features, the most important of which are described here for clarity.
            <block param="description">
              <command name="item" opt="class"> The definition for an object.</command>
              <command name="item" opt="instance"> A run-time manifestation of a class, each of which has its own scope.</command>
              <command name="item" opt="static"> A scope for the definition of a class.</command>
              <command name="item" opt="field"> A variable associated with a class (static field) or with an instance (instance field).</command>
              <command name="item" opt="method"> A set of operations attached to a class (static method) or to an instance (instance method).</command>
              <command name="item" opt="constructor"> A special method that is called when an instance of a class is created.</command>
              <command name="item" opt="factory method"> A method whose purpose is to create instances of a class, but not necessarily of the class on which it is found.</command>
              <command name="item" opt="overload"> Two (or more) methods that have the same name but different parameter numbers and/or types are said to be <em>overloads</em> of the same method.</command>
              <command name="item" opt="interface"> A contract (usually in the form of a list of methods) for classes to implement which enables their instances to be interchangeable with other implementations of the interface.</command>
              <command name="item" opt="property"> A method whose purpose is to allow the reading or reading and writing of a field's value.  Some languages support this directly while others offer a convention of "getter" and "setter" methods, instead.</command>
              <!-- TODO: encapsulation? -->
            </block>
          </command>
        </command>
        <command name="section" param="Automated testing">
          A proper introduction to automated testing, especially as it pertains to OO programs would fill a book and indeed it has.  The reader is encouraged to consult <em>Testing Object-Oriented Systems</em> by Robert V. Binder <see cite="binder00testharness" /> for details beyond this chapter's overview.

          Generally, a test is said to be automated if there exists a program that can: start the IUT or a subset thereof, initialize some suitable inputs for the scenario to be verified, provide these inputs to the IUT and then verify the resulting output, without any intervening assistance.
          <command name="subsection" param="Testing frameworks">
            Automated testing frameworks provide developers with the ability to write and organize test scenarios, execute them sequentially and independently from one another and finally report on their successes.

            This thesis focuses on testing frameworks <see cite="beck99simplesmalltalk" /> that allow the test development environment to be identical to the implementation development environment, collectively called XUnit <see cite="fowler06xunit" />.  A single test scenario can be implemented as a <em>test method</em> in a <em>test class</em>, exercising functionality in the method under test (MUT) in another class; the class under test (CUT).  A collection of test classes is known as a <em>test suite</em>.

            Test methods will generally have three phases - arrange, act and assert - although the functionality is not always separated as such and might be intermixed or even be located elsewhere in the test class.  The <em>arrange</em> phase concerns itself with preparing the CUT and/or the environment, effectively setting the indirect inputs for the MUT and optionally initializing complex direct inputs.  The <em>act</em> phase contains code that calls the MUT with its direct inputs and collects the direct outputs, if any.  The <em>assert</em> phase derives any indirect outputs, if any, and verifies the <em>actual</em> outputs against the <em>expected</em> outputs, cleaning up the environment afterward, as necessary.

            The terms <em>test inputs</em> and <em>test outputs</em> will henceforth be used to refer to both their direct and indirect sets.  It is worth noting that because exhaustive testing is not feasible, test suites will usually contain scenarios that sample only a fraction of the possible input space.  In those cases, the test inputs will have been selected to represent typical use, boundary conditions and other potential areas for defects.  Such classes of values for the test inputs earns them the "interesting and relevant" designation.
          </command>
          <command name="subsection" param="Test scope">
            As alluded to in the previous sub-section, this thesis concerns itself with automated testing at the lowest level by focusing the test scenarios on methods, which is also known as <em>unit testing</em>.  This is in contrast to <em>integration testing</em> which concerns itself with the interaction between a class and another class and/or some external environment such as a file system or a network, and <em>subsystem testing</em> which involves observing the interaction between a class and several other classes and/or external components such as a database or a web service.
          </command>
          <command name="subsection" param="Code coverage">
            An IUT can be automatically <em>instrumented</em> to record which statements and expressions are executed during an automated test run.  The resulting report is known as <em>statement coverage</em> and will usually correlate its results with the original source code by highlighting the statements and expressions that were executed  <see cite="binder00classes" />.  This report will also include enough data to determine the coverage percentage - which is computed as the number of statements executed divided by the total number of statements - at the method, class, namespace and program levels <see cite="sink06advocatingcoverage" />.

            Code coverage can be used to determine the completeness of the test suite or, more precisely, to identify areas of the IUT that are untouched by the tests.  The presence of uncovered code can also reveal surprises in the implementation although its best use remains the identification of missing test scenarios.
          </command>
        </command>
        <command name="section" param="Motivation for Computer-Generated Tests">
          It may not always be possible or feasible to have a programmer write automated tests for a component or an implementation.  Reasons provided by Bühler and Wegener <see cite="buehler08evolutionaryfunctional" /> include the simultaneous satisfaction of functional, real-time and safety requirements as well as the very large test space resulting from the interaction of 50-70 independently-developed embedded systems.  The nature of the assembled system - in this case a premium vehicle - also makes manual testing, such as driving the vehicle in an environment suitable for each scenario, prohibitively expensive.  Bühler and Wegener go on to suggest generating tests automatically to work around these obstacles and thus reduce costs.  Evolutionary testing (ET), "the application of evolutionary computation to test automation" <see cite="buehler08evolutionaryfunctional" />, is therefore suggested to automatically and efficiently sample the test input space.  ET will usually be implemented using genetic algorithms (GA), which are well-suited to a mix of exploration and exploitation in the search space <see cite="mcminn04searchbased" />.

          Binder writes:
          <block param="quote">
            "Automatic test generation can be used without having to pregenerate expected results.  Although generating input values automatically is easy, generating the corresponding expected results automatically is usually difficult." <see cite="binder00assertions" />
          </block>
          Even if tests are automatically generated without the use of an oracle (human or otherwise), the generated test suite can still serve as a baseline and could be used to detect changes in the outputs as a result of adding features or fixing defects.  These changes in the outputs could indicate a regression, just as changes in the outputs of human-generated tests would.

          In the present case, there's an additional reason computer-generated tests are interesting:  we can use an automatic structural test generator to objectively compare the testability of source code under various transformations.

          More details about the various flavours and uses of computer-generated tests are provided in the following sections.
        </command>
        <command name="section" param="Approaches to Computer-Generated Tests">
          There are three major approaches in generating tests <see cite="lakhotia10empiricalinvestigation" />.
          <command name="subsection" param="Random Testing">
            Random testing (RT), as the name implies, consists of generating inputs based on random numbers and is thus undirected.  RT does not perform as well as ET <see cite="wegener01evolutionarytest" />, although it has been used as a baseline for comparing other test generators <see cite="lakhotia10empiricalinvestigation" />.
          </command>
          <command name="subsection" param="Search Based Software Testing">
            Search-based software testing (SBST) is the application of a metaheuristic search technique (MST) to the problem of generating test inputs <see cite="mcminn04searchbased" />.  The technique is based around optimization of an <em>objective function</em>, trying to improve an initial solution based on feedback by said objective function - either by maximizing or minimizing its value, depending on the desired outcome - effectively making it a guided quest for global optima in the search space.

            For test input generation, the search space is the domain of the test inputs and the objective function is carefully constructed to reward interesting and relevant test inputs.  The nature of "interesting and relevant" depends on the <em>intent</em> of the testing exercise.  Consult the following section for the major intents, but suffice it to say that the biggest difficulty of SBST lies in the definition of the objective function <see cite="baresel02fitnessfunction" />.

            The general flow of MST implementations is to start with one or more "initial solutions", created either with domain knowledge or at random, and apply the objective function on the solution(s) to establish a solution score.  If no solution score exceeds a pre-defined threshold, tweak the solution(s) according to some heuristic and repeat the process with the new solution(s) until either no improvement in score is detected or some pre-defined time or iteration threshold is reached.

            The simplest heuristic is called "hill climbing", a strategy that focuses on the best objective function value in the neighborhood of the current solution's search space.  This greedy exploit-only strategy will often cause a hill climber to get stuck in local optima.

            An improvement to hill climbing was proposed in the "simulated annealing" heuristic whereby solutions with worse objective function values will be considered with a probability decreasing with the number of iterations, allowing more of the search space to be explored in the beginning and ending with a hill climber-like exploitation.

            One of the better MST heuristics is "genetic algorithms (GA)", a class of "evolutionary algorithms".  It is designed to simulate the process of natural selection (sometimes known as "survival of the fittest") by modeling a <em>population</em> of solutions as chromosomes and providing ways for pairs of solutions to "breed" through recombination (splicing part of one parent with part of the other and also combining the remaining two parts), providing the next generation of solutions.  The simulation is made more authentic through the use of mutations (random, low-probability alterations to the chromosome) and various reproduction selection mechanisms, such as fitness-proportional selection and tournament selection.  Through this simulation, solutions will appear to evolve across the generations and, given appropriately-tuned parameters, the population of solutions will be diverse and "fit", thus providing a good balance of exploration and exploitation of the search space.
          </command>
          <command name="subsection" param="Concolic Testing">
            Concolic testing (CT) is the combination of <u>conc</u>rete and symb<u>olic</u> execution applied to the problem of test data generation.  It is also known as dynamic symbolic execution <see cite="mcminn04searchbased" />.

            Symbolic execution (SE) is a simulated execution of a given path through the program using symbols in place of input values, and keeping track of expressions instead of concrete values as assignments and operations take place <see cite="king76symbolicexecution" />.  For a program operating exclusively with integers, one could say SE is the algebraic equivalent of the arithmetic operations that would be evaluated with concrete execution.  The resulting output of SE is generally a system of constraints on the inputs for executing the given path.

            Concrete execution - running an instrumented version of the program - can be combined with SE such that the two executions are correlated to verify the generated constraints against concrete values.  Often times, this correlation allows the simplification of these constraints, for example by removing non-linear sub-expressions <see cite="mcminn04searchbased" />.  A constraint solver can then be used to find test input values that cause the execution of specific paths through the IUT <see cite="tillman08pex" />.
          </command>
        </command>
        <command name="section" param="Intents of Computer-Generated Tests">
          There are four major uses for Computer-Generated Tests (CGT).  They differ mostly in the choice of executable statement(s) to target and are not usually specific to any approach in particular.  The exception is non-functional testing, which does not target any executable statement in particular and is more suited to an optimization approach (such as SBST).
          <command name="subsection" param="Structural Testing">
            Coupling an automated test generator with a code coverage tool makes it possible to discover which inputs can be used to reach otherwise hard-to-cover areas as well as areas of the code where no inputs can be found to reach them (within a pre-defined search time).  This could indicate that the code is unreachable because it contains, for example, conflicting pre-conditions.  Structural testing will generally attempt to execute all statements of an IUT at least once.
          </command>
          <command name="subsection" param="Functional Testing">
            Functional testing is a form of verification that uses a machine-readable form of the specification <see cite="mcminn04searchbased" />.  One way of doing so is with a formal specification expressed as disjunctions that represent <em>routes</em> (or paths) through the program.  These routes can then be tested individually using structural testing.

            An easier approach is to automatically turn the specification into pre-conditions and post-conditions.  The objective is then to find test inputs that conform to all pre-conditions but that cause post-conditions to fail, in effect targeting the fault branch of the post-conditions.

            A third approach is to encode the specification's requirements as a component of a simulator.  For example, Bühler and Wegener evaluated the functionality of a brake assist system using a simulator to find instances where the system either did not enhance the driver's brake torque in a critical situation or provided too much braking in a non-critical situation <see cite="buehler08evolutionaryfunctional" />.
          </command>
          <command name="subsection" param="Grey-Box Testing">
            The objectives of grey-box testing are to attempt to get assertions already embedded in a program to be violated and to trigger exception conditions.  Some of the work even temporarily turned specially-formatted comments into executable assertions for the purposes of targeting their fault branches for execution <see cite="mcminn04searchbased" />.
          </command>
          <command name="subsection" param="Non-Functional Testing">
            Non-functional testing concerns itself with verifying non-functional requirements, such as constraints on execution time, working memory, long-term storage and processor load, usually for embedded and real-time systems.  Test inputs are sought which cause the program to exceed pre-defined thresholds, such as taking more time than usual or consuming more memory than expected.  This can be measured by instrumentation external to the IUT, such as the operating system's timers and counters, or by using a simulator <see cite="sthamer02usingevolutionary" />.
          </command>
        </command>
        <command name="section" param="Related work">
          <command name="subsection" param="The state problem">
            <block param="quote">
              "Side-effects, by which I mean changes to the values stored in fields of objects or elements of arrays, are clearly intended to be used frequently in Java. However, the presence of side-effects can make it harder to reason about a program, because there is invisble [sic] state to the side of computations which changes. That means a reader needs to keep track of both the visible aspects of a program and the hidden values off to the side that may change." <see cite="haahr99programmingstyle" />

              "Although encapsulation does not directly contribute to the occurrence of bugs, it can present an obstacle to testing.  Testing requires accurate reporting of the concrete and abstract states of an object and the ability to set state easily.  Object-oriented languages make it difficult - if not impossible - to directly set or get the concrete state." <see cite="binder00withnecessary" />
            </block>
            McMinn identified the "State Problem" in the context of evolutionary testing and described a few possible solutions that enhanced the ET system to compensate for problems brought on by state <see cite="mcminn03thestate" />.  Difficulties with internal state are also mentioned by Bühler and Wegener <see cite="buehler08evolutionaryfunctional" />, Harman et al. <see cite="harman09aop" />, Tillman and de Halleux <see cite="tillman08pex" /> and Baresel et al. <see cite="baresel02fitnessfunction" />.

            Difficulties associated with internal state can be reduced or worked around with better analysis, such as data dependency analysis <see cite="korel05datadependence" />.  Since said analysis can often be time-consuming, techniques, such as program slicing <see cite="tip95surveyslicing" />, were developed to help reduce the search space.  McMinn went on to develop a technique that enhances the search to look for method call sequences and combines the chaining approach with evolutionary search <see cite="mcminn05evolutionarysearch" />.

            Another approach to generate tests for programs with state - specifically those written in OO programming languages - was proposed by Wappler and Wegener <see cite="wappler06evolutionaryunit" />.  Their two-phase technique, called "strongly-typed genetic programming", consists of first using genetic programming to generate a sequence of methods to call (creating instances of classes as necessary), then using a genetic algorithm to find suitable values for the parameters of the generated method calls.
            <!-- TODO: discuss Microsoft's PrivateObject -->
          </command>
          <command name="subsection" param="The case for functional programming">
            <block param="quote">
             "However, the functional style is also perfectly adapted to incremental testing:  programs written in this style can also be <em>tested</em> one function at a time.  When a function neither examines nor alters external state, any bugs will appear immediately. Such a function can affect the outside world only through its return values. Insofar as these are what you expected, you can trust the code which produced them." <see cite="graham93onlisp" />
            </block>
            "Imperative functional programming" is argued by Reddy <see cite="reddy96imperativefunctional" /> and appears to push the idea of a <em>public</em> functional programming interface built on top of imperative features.  This is in contrast to the present thesis, which would see an <em>internal</em> functional programming interface (built on top of imperative features) as a building block for a possibly pre-existing object-oriented interface.

            Van-Roy and Haridi support the spirit of the proposed approach, declaring "We find that a good rule of thumb for complex systems is to keep as many components as possible declarative.  State should not be 'smeared out' over many components.  It should be concentrated in just a few carefully selected components." <see cite="vanroy04conceptstechniques" />  Support is also provided by Wampler: "Side-effect-free functions make excellent building blocks for reuse, since they don't depend on the context in which they run. Compared to functions with side effects, they are also easier to design, comprehend, optimize, and test." <see cite="wampler11functionalprogramming" />

            Hevery, on the other hand, appears to disagree with the proposed approach <see cite="hevery08staticmethods" /> and argues for a pure object-oriented approach <see cite="hevery09thinkoo" />.  Haahr nevertheless argues for "referential transparency" <see cite="haahr99programmingstyle" /> to not only make computations easier to understand but also easier to parallelize.
          </command>
          <command name="subsection" param="The case for testability transformations">
            <block param="quote">
              "It could be said that the algorithm for side-effect removal creates an `almost functional' language, in which all state changes are expressed using the assignment statement. This would return the programming paradigm to that considered by the initial work on the Axiomatic Method, where axiomatic semantics is comparatively elegant and easy to define and use. This, perhaps, provides further additional anecdotal evidence that side-effects are hard to reason about and that their removal is worthwhile for comprehension." <see cite="harman01sideeffect" />
            </block>
            Because programs are not always easily testable as written, it has been suggested by Harman et al. to automatically create an alternate (and temporary) version of the program that is easier to analyze or test by applying some transformations <see cite="harman04testabilitytransformation" />.  These transformations can be as simple as "flag removal"; the inline expansion of a boolean variable with its underlying expression <see cite="harman02improvingevolutionary" />.  Another example would be the removal of expressions with side-effects <see cite="harman01sideeffect" />.

            The general idea of testability transformation was further developed by Korel et al. <see cite="korel05datadependence" /> as well as McMinn et al. <see cite="mcminn08empiricalevaluation" />, among others.  Program slicing could also be considered a testability transformation <see cite="harman09aop" />.  Harman eventually goes one step further and suggests "testability refactoring": a permanent program transformation that has the simultaneous goals of making the program easier to test and better (or at least no worse) for the programmer <see cite="harman11refactoringtestability" />.
          </command>
          <command name="subsection" param="The case for simplicity">
            <block param="quote">
              "A low cyclomatic complexity generally indicates a method that is easy to understand, test, and maintain." <see cite="msdn10avoidcomplexity" />
            </block>
            McCabe introduced the concept of "cyclomatic complexity" with the intention of evaluating the difficulty involved when testing programs based on their structure <see cite="mccabe76complexitymeasure" />.  Indeed, McCabe even discussed the possibility of reducing a program's structure to reduce the testing effort, in an effort to make software that is both testable and maintainable.

            Hevery created the Testability Explorer tool to compute the "Non-Mockable Total Recursive Cyclomatic Complexity" metric, compute the "Demeter" metric as well as count the number of global mutable fields in Java programs <see cite="hevery08testabilityexplorer" />.  The first metric is an evolution of McCabe's metric for OO programs while the other two metrics also help to reduce the testing effort through smaller call chains (Demeter) and less "spooky action at a distance" (surprise side-effects) by reducing the use of mutable global fields <see cite="hevery08flawbrittle" />.
          </command>
        </command>
        <command name="section" param="Scope">
          The present thesis focuses on addressing the glass-box unit testing difficulties introduced by hidden mutable state, in the context of object-oriented software, through the use of stateless method extraction.  In other words, the implementation under test is available for inspection as tests are written on a per-method basis for classes that contain private instance fields whose values are altered by calls to instance methods.

          Considerations outside the scope of this thesis therefore include:
          <block param="itemize">
            <command name="item"> Opaque-box testing</command>
            <command name="item"> Integration (or other high-level) testing</command>
            <command name="item"> Non-object-oriented software</command>
          </block>

          Additional considerations outside the scope of this thesis include:
          <block param="itemize">
            <command name="item"> Testing of hidden state mutations.  These must still be tested, but those tests are not covered by this thesis.</command>
            <command name="item"> Run-time performance of IUT or unit tests</command>
            <command name="item"> Performance of SBST (such as ET) on IUT</command>
            <!-- Is the last one really reasonable since the basis of this thesis was the ET-related "state problem"?  Shouldn't I be able to show some progress on that front? -->
          </block>

          Stateless method extraction is to be compared against other approaches for unit testing OO software containing hidden mutable state;  see table <see ref="tbl:ScopeTable" />.

          <block param="table" opt="htbp">
            <raw>\begin{tabular}{l >{\centering}m{2cm} >{\centering}m{2cm} >{\centering}m{2cm} >{\centering}m{2cm} }</raw>
              <raw>&amp; \multicolumn{4}{c}{Features}\tabularnewline</raw>
              <!-- TODO: should we consider/measure the effect on the arrange phase? -->
              <raw>\multicolumn{1}{c}{Approach}</raw> <raw>&amp;</raw> Transforms IUT <raw>&amp;</raw> Transforms (Affects?) tests <raw>&amp;</raw> Affects public interface <raw>&amp;</raw> Requires tool <raw>\tabularnewline</raw>
              <command name="hline" />
              Stateless method extraction <raw>&amp;</raw> Y <raw>&amp;</raw> N <raw>&amp;</raw> N <raw>&amp;</raw> N <raw>\tabularnewline</raw>
              Isolated test methods <raw>&amp;</raw> N <raw>&amp;</raw> N <raw>&amp;</raw> N <raw>&amp;</raw> N <raw>\tabularnewline</raw>
              Test helper methods <raw>&amp;</raw> N <raw>&amp;</raw> Y <raw>&amp;</raw> N <raw>&amp;</raw> N <raw>\tabularnewline</raw>
              Reflection-based helpers <raw>&amp;</raw> N <raw>&amp;</raw> Y <raw>&amp;</raw> N <raw>&amp;</raw> Y <raw>\tabularnewline</raw>
              Making mutable state visible <raw>&amp;</raw> Y <raw>&amp;</raw> N <raw>&amp;</raw> N <raw>&amp;</raw> N <raw>\tabularnewline</raw>
              Making hidden state mutable <raw>&amp;</raw> Y <raw>&amp;</raw> N <raw>&amp;</raw> Y <raw>&amp;</raw> N <raw>\tabularnewline</raw>
            <raw>\end{tabular}</raw>
            <command name="caption" param="Approach vs. Features" />
            <command name="label" param="tbl:ScopeTable" />
          </block>
          <!--
TODO: what about simply refactoring so that processing is taking place closer to the objects involved?  For example, instead of computing the great-circle distance in a method of the FlyingSalespersonProblem class, have it be an instance method on LatLon: GreatCircleDistance(LatLon destination), which might also allow LatLon to keep a cache of the Sin() and Cos() of the radian version of Lat (as well as the radian version of Lon) for further performance.  There probably is more risk involved when moving the functionality like that, although the risk would most likely be proportional to the test coverage (as it would be in general).

          = contrast with isolated, stand-alone tests
          = contrast with test helper methods
          == For example, DeepZoomImageTest.TestComputeLevelSize() that creates two instances per call:
          Assert.AreEqual (new Size (1200, 1500), TestComputeLevelSize (PortraitImageSize, 12));
          vs. the original stateless method that could be called directly:
          Assert.AreEqual (new Size (1200, 1500), DeepZoomImage.ComputeLevelSize (PortraitImageSize, 12));
          === For that particular one, because my settings class performs work in the constructor, there are some properties which MUST be provided.
          == how about test helper properties?
          == they shift complexity instead of removing it altogether.  I need to find some way to prove that this leads to more brittle tests.  Perhaps the fact that the stateless method is reusable vs. the test helper method is not?
          = constrast with factory methods:
          """
          As an alternative to employing only existing constructors to configure objects,
the user may also provide factory methods, which could invoke a sequence of
method calls to construct and configure a new object, possibly creating cyclic
references as well.
          """ Pex, last paragraph of section 3.4
          = contrast with visible, mutable state
          == changes current public interface
          = contrast with hidden, immutable state
          == changes current public interface
          -->
        </command>
        <command name="section" param="Summary">
          <!-- key points of what was presented and linkage to next chapter -->
          ...
        </command>
      </command>
      <command name="chapter" param="Approach">
        <command name="section" param="Introduction">
          <!-- what the chapter is about -->
          ...
        </command>
        <command name="section" param="Design">
          Stateless method extraction's intent is to separate the interaction between the hidden mutable state in a class and the inputs and outputs of said class' instance methods.  This decoupling allows programmers to first focus their unit tests on the pure computation aspects, then on the object-oriented layer above the stateless methods.

          It is important to note that SME relies on all its steps applying modifications to the source code that will not alter any of the behaviours and functionality present before SME was performed.  That is to say, all the operations performed should be pure refactorings <see cite="fowler00refactoring" /> and no functional changes are to be performed during the process.  These rules help ensure the use of SME is invisible to end-users and has the least chance of breaking the affected methods.

          <command name="subsection" param="Overview">
            Stateless method extraction is performed in six high-level steps:
            <block param="enumerate">
              <command name="item"> Identification of a candidate block.
                <br />
                A "candidate block" is a functionality subset of an instance method that looks promising to turn into a stateless method.
              </command>
              <command name="item"> Re-ordering of incidental operations.
                <br />
                On some occasions, it may be necessary to move out of the candidate block some statements that are not relevant to the functionality subset and/or whose ordering is not critical (such as logging).
              </command>
              <command name="item"> Assignment of inputs and outputs to local variables.
                <br />
                Identify the new method's input and output parameters then create local variables for them.
              </command>
              <command name="item"> Simplification of inputs.
                <br />
                Optimize the input parameters to be native or built-in types.
              </command>
              <command name="item"> Extraction of the candidate block into a method.
                <br />
                The candidate block should now be easily converted into a stateless method.
              </command>
              <command name="item"> Re-inline any variables created to facilitate a refactor.
                <br />
                This reverses the actions of step #3 so the refactor has as little impact on the original code as possible and only contains the necessary changes.
              </command>
            </block>
            Refer to listing <see ref="lst:Procedure" /> for a pseudo-code version of the stateless method extraction procedure.  The following sub-sections will cover the individual steps in greater detail.
            <!-- TODO: should this be an "algorithmic" block, instead? -->
            <command name="lstinputlisting"
              opt="label=lst:Procedure,caption=General procedure for extracting stateless methods,style=pseudoCode"
              param="Procedure.pc" />
          </command>
          <command name="subsection" param="Step 1: Identification of a candidate block">
            <command name="label" param="subsec:Step1" />
            The first step of SME consists of identifying, in an instance method, one or more functionality subsets that would be good candidates for extraction and subsequent unit testing.  That is to say it is not necessary to extract the entire body of an instance method if there are parts of the method that would be more suitable to extract and unit test separately.  It is also possible a method will contain no candidate blocks to extract; the technique need not be forcibly applied if no unit testing advantages can be realized.

            The criteria for establishing candidacy of a block consist of:
            <block param="enumerate">
              <command name="item"> A continuous set of stateless statements.
                <br />
                Stateless statements are defined as depending directly on their inputs and without side-effects.  Statements that interpret input parameters to interact with the environment (such as reading/writing files and sending/receiving network traffic) are not considered stateless.  Statements may produce effects (such as assignment and return values) but may not cause other values to change as a result of execution (such as modifying HMS), as this would defeat the purpose.  Section <see ref="subsec:Step2" /> describes how to deal with non-stateless statements.
              </command>
              <command name="item"> Inputs (local variables, fields and/or method parameters): at least 1 but no more than 6.</command>
              <command name="item"> Outputs (local variables, fields and/or return values): at least 1 but no more than 3.
                <br />
                At least one non-trivial result must be produced by processing the input(s).
              </command>
            </block>
            Categories of interesting candidate blocks include:
            <block param="itemize">
              <command name="item"> Implementations of mathematical formulas.
                <br />
                For example, converting from degrees to radians or computing the great circle distance (the shortest path between two points on a sphere), both of which are shown being performed inline in listing <see ref="lst:StatefulComputeTourLength" />.
              </command>
              <command name="item"> Processing of a single element where such processing currently takes place while looping through a sequence of elements.
                <br />
                For a before-after example, refer to listings <see ref="lst:StatefulGenerateXml" /> and <see ref="lst:StatelessGenerateXml" />.
              </command>
              <command name="item"> String parsing, especially when using a regular expression.
                This allows the parsing to be separated from the use of its results, so that the parsing and the subsequent computations can be tested separately.
              </command>
              <command name="item"> Filling in of templates.
                <br />
                This can be considered the reverse of string parsing and usually involves combining a few inputs to yield a meaninful string representation.  An example of this category can be found in the <tt>GenerateItemNode()</tt> method extracted in listing <see ref="lst:StatelessGenerateXml" />.
              </command>
            </block>
            <command name="lstinputlisting"
              opt="caption=ComputeTourLength() method with some inlined mathematical formulas,label=lst:StatefulComputeTourLength,style=realCode,linerange=38-60"
              param="Stateful/FlyingSalespersonProblem.cs" />
            <region name="table and two code listings for partial loop block extraction">
              <raw>\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatefulGenerateXml,caption=GenerateXml() method with a candidate block between lines 19-30,style=realCode,linerange=40-78"
                param="Stateful/ImageCollection.cs" />
              <raw>&amp;</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatelessGenerateXml,caption=GenerateXml() method with the candidate block extracted as the GenerateItemNode() method,style=realCode,linerange=40-87"
                param="Stateless/ImageCollection.cs" />
              <raw>\end{tabular}</raw>
            </region>
            It follows that there are uninteresting categories of blocks, such as:
            <block param="itemize">
              <command name="item"> Trivial state changes.
                <br />
                A good example is a Reset() method that sets a number of instance fields to a specific set of values, such as constants.  The whole point of such a method is to mutate hidden state and thus there would likely be very little functionality that could be tested in isolation.
              </command>
              <command name="item"> Too many inputs and/or outputs.
                <br />
                This category could be considered a more general case of the previous category but there are instances where it may not make sense to break up some processing for readability, maintenance or performance reasons.
              </command>
              <command name="item"> Not enough outputs.
                <br />
                An example of a block in this category would be an instance method calling instance methods on its fields in such a way that there are no observable changes to the fields' own hidden mutable state.  Extracting that block would likely provide no unit testing advantage and is thus uninteresting.
              </command>
              <command name="item"> Too many interactions with the environment.
                <br />
                If an instance method consists mostly of, say, file system or database processing, there may be very little functionality left that is stateless and would benefit from extraction and isolated unit testing.
              </command>
            </block>
          </command>
          <command name="subsection" param="Step 2: Re-ordering of incidental operations">
            <command name="label" param="subsec:Step2" />
            The second SME step is about finding and, if necessary, moving statements that are either unrelated to a computation or statements that are not stateless (such as those that cause side-effects) out of the candidate block, but only if the original instance method's functionality will not be adversely affected by the move.  If the functionality would indeed be adversely affected by the re-ordering of unrelated or non-stateless statements, the candidate block should be split such that its new endpoint is just before said unrelated or non-stateless statement, and a subsequent candidate block could be attempted just after.

            <region name="table and two code listings for operation re-ordering">
              <raw>\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatefulGenerateXmlIntermixed,caption=GenerateXmlIntermixed() method with a candidate block between lines 18-33,style=realCode,linerange=80-118"
                param="Stateful/ImageCollection.cs" />
              <raw>&amp;</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatefulGenerateXmlUnmixed,caption=GenerateXml() method with a shorter candidate block between lines 19-30,style=realCode,linerange=40-78"
                param="Stateful/ImageCollection.cs" />
              <raw>\end{tabular}</raw>
            </region>

            An example of unrelated statements can be seen in listing <see ref="lst:StatefulGenerateXmlIntermixed" />, specifically in the candidate block identified between lines 18 and 33.  The majority of the operations in the block concern themselves with the creation and configuration of the <tt>itemNode</tt> instance while at least 3 of them perform tasks incidental to the <tt>itemNode</tt> configuration:  lines 21, 23 and 25.  Line 20 does augment <tt>itemNode</tt>, but does so with a trivial operation (the <tt>Add()</tt> method call) and so its inclusion in the candidate block could be argued either way.  For the purposes of this example, line 20 will be considered incidental.  The candidate block could be shrunk by re-ordering all the operations identified as incidental without affecting the functionality.  In particular, the <tt>mortonNumber++;</tt> operation on line 23 is only sensitive to ordering insofar as <tt>itemNode.SetAttributeValue("N", mortonNumber);</tt> on line 22 is concerned and thus could be moved down and out of the candidate block.  Lines 20 and 21 depend on one another as well as line 19 (the creation of the <tt>itemNode</tt> instance), but the behaviour would be the same if they appeared at the end of the block (the XML API used in the example guarantees this) and therefore, because they have no advantage being located immediately after the creation of <tt>itemNode</tt>, they can be safely moved out of the candidate block.  The last incidental operation is <tt>maxPostId = Math.Max(maxPostId, postId);</tt> on line 25.  Its only dependency is the <tt>postId</tt> loop variable and thus could be moved up to be the very first operation in the loop.  Listing <see ref="lst:StatefulGenerateXmlUnmixed" /> illustrates the result of re-ordering the lines containing incidental operations and the smaller, simpler candidate block obtained.
            <!-- TODO: can also argue the decision to keep the path manipulation code (fileName and relativeDziSubPath) in the candidate block vs. moving it out.  There's no change in the number of parameters to GenerateItemNode(), but it might make for even smaller/simpler tests that are more focused? -->

            A statement is said to be non-stateless if values or data not explicitly specified by parameters or the return value are modified as a result of execution.  This can be as simple as an instance method modifying hidden mutable state, a method modifying global state or a method interpreting its parameters for interaction with the environment, such as using a string parameter as the name of a file to create or delete or the name of a database table to read from or write to.  Non-stateless operations will generally be more difficult to re-order because, by definition, they cause or depend on side-effects and standard data dependency analysis will not be useful.

            An example of a non-stateless method in the middle of a candidate block can be seen at line 24 of listing <see ref="lst:StatefulSubversionClient" />.  The <tt>ExecuteSvn()</tt> method, defined at line 50, starts a sub-process and returns the contents of <tt>StandardOutput</tt> and thus is said to interact with the environment, making it definitely non-stateless.  In this particular case, because the <tt>ExecuteSvn()</tt> method depends on the computations immediately above it and provides input needed by the computations immediately below it, it can not be moved before or after the candidate block (lines 14-44).  This causes the original candidate block to be split into parts excluding the immovable, non-stateless method with the first half being lines 14-22 and the second half lines 26-44.  Listing  <see ref="lst:StatelessSubversionClient" /> shows the two stateless methods that were extracted from the split candidate block: <tt>CreateInfoArguments()</tt> and <tt>ParseInfoFromXml()</tt>.

            <region name="table and two code listings for candidate block splitting">
              <raw>\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatefulSubversionClient,caption=The Info() method has a candidate block between lines 14-42,style=realCode,linerange=6-66"
                param="Stateful/SubversionClient.cs" />
              <raw>&amp;</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatelessSubversionClient,caption=Two stateless methods were extracted from the Info() method,style=realCode,linerange=6-62"
                param="Stateless/SubversionClient.cs" />
              <raw>\end{tabular}</raw>
            </region>

            It could also be the case that the original instance method is computing several outputs simultaneously and such statements are intermixed.  If the outputs are independently-computed (or their computations share some intermediate results, then diverge), it may be worth investigating the separation of their computations by re-ordering statements such that they can then be extracted, and subsequently unit tested, independently.  An example of intermixed computations can be seen in listing <see ref="lst:StatefulCartesianCoordinate" /> between lines 20 and 24, while another version of the method with the computations separated through re-ordering can be seen in listing <see ref="lst:StatelessCartesianCoordinate" />.

            <region name="table and two code listings for math re-ordering">
              <raw>\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatefulCartesianCoordinate,caption=The ToPolar() method interleaves computations for r and theta,style=realCode,linerange=3-27"
                param="Stateful/CartesianCoordinate.cs" />
              <raw>&amp;</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatelessCartesianCoordinate,caption=The ToPolar() method with the computations separated,style=realCode,linerange=3-27"
                param="Stateless/CartesianCoordinate.cs" />
              <raw>\end{tabular}</raw>
            </region>

            Incidental operation re-ordering can be considered a form of program slicing <see cite="tip95surveyslicing" /> in that data dependency analysis <see cite="korel05datadependence" /> can be used to identify a subset of computations of a method responsible for one of the outputs and isolate them.  Assuming all the discarded operations were stateless, it would be safe to say that the remaining operations can execute one immediately after the other and still produce the same result, the same way lines 18, 20 and 22 in listing <see ref="lst:StatefulCartesianCoordinate" /> are necessary for the computation of <tt>r</tt> and can be re-arranged to be consecutive, as seen in lines 18, 19 and 20 in listing <see ref="lst:StatelessCartesianCoordinate" />.
          </command>
          <command name="subsection" param="Step 3: Assignment of inputs and outputs to local variables">
            <command name="label" param="subsec:Step3" />
            The third step concerns the [temporary] introduction of local variables for each of the input and output parameters.  This makes the upcoming stateless method parameters and return values explicit so that it is easier to provide them with suitable names, easier to evaluate their simplicity (consult Section <see ref="subsec:Step4" /> for details) and to more clearly delineate the candidate block so that it is easier to extract it using existing "extract method" refactoring tools.

            The local variables introduced during this step should be remembered to allow their re-inlining to be performed again at the end of the current iteration, as described in Section <see ref="subsec:Step6" />.
          </command>
          <command name="subsection" param="Step 4: Simplification of inputs">
            <command name="label" param="subsec:Step4" />
            Stateless method extraction's fourth step entails finding the simplest types that can be used for the parameters and return values without causing an undue increase in their numbers.  Any type with an easy construction (a single call to a constructor or a factory method) and without side-effects while reading its component values (typical of an immutable instance) is considered "simple" for the purpose of SME.

            <region name="table and two code listings for Vector math">
              <raw>\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatefulVector,caption=The original Vector and Plane classes,style=realCode,linerange=3-39"
                param="Stateful/Plane.cs" />
              <raw>&amp;</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatelessVector,caption=The Plane class had two stateless methods extracted from it,style=realCode,linerange=3-41"
                param="Stateless/Plane.cs" />
              <raw>\end{tabular}</raw>
            </region>

            As a first example of possible input simplification, suppose the candidate block's purpose is to compute the dot product of two 3D vectors and the parameters are currently two instances of a <tt>Vector</tt> type (refer to lines 33-34 of listing <see ref="lst:StatefulVector" /> for the candidate block and lines 36-38 of listing <see ref="lst:StatelessVector" /> for the extracted version).  The stateless method could also be written to accept 6 parameters representing both triplets of the vectors' values.  Assuming a <tt>Vector</tt> instance can be created in one statement (a call to its constructor, in this case) and reading its component values can cause no side-effects, it may be worth keeping the input parameters as two <tt>Vector</tt> instances for readability reasons.  It is worth noting that an argument could also be made to make the new <tt>DotProduct()</tt> method accept the 6 component values so that the method could be subsequently re-used to calculate dot products of vectors not expressed using instances of <tt>Vector</tt>.

            <region name="table and two code listings for Match-based formatting">
              <raw>\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatefulCodeFormatMatchEvaluator,caption=The original CodeBlockModifier class,style=realCode,linerange=35-64"
                param="Stateful/CodeBlockModifier.cs" />
              <raw>&amp;</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatelessCodeFormatMatchEvaluator,caption=The CodeBlockModifier class with testability extractions,style=realCode,linerange=35-78"
                param="Stateless/CodeBlockModifier.cs" />
              <raw>\end{tabular}</raw>
            </region>

            On the other hand, suppose the candidate block's purpose is to reformat text based on the results of a regular expression match, as shown between lines 22-27 in listing <see ref="lst:StatefulCodeFormatMatchEvaluator" />.  In this case, because the input parameter is of a type that is difficult to create <footnote>The <tt>Match</tt> class has no visible constructors.  The only way to create an instance is through the return value of the <tt>Match()</tt> method overloads on the <tt>Regex</tt> class.</footnote>, it is easy to argue that the method's parameters should be four strings (consult lines 38-41 of listing <see ref="lst:StatelessCodeFormatMatchEvaluator" /> to see the extracted method) instead of one <tt>Match</tt> instance, given how trivial strings are to create versus the complexity involved in creating said <tt>Match</tt> instance.  Indeed, as listings <see ref="lst:StatefulCodeFormatMatchEvaluatorTest" /> and <see ref="lst:StatelessCodeFormatMatchEvaluatorTest" /> show, the original method must either be tested indirectly (through calling the <tt>ModifyLine()</tt> method) or by creating a <tt>Match</tt> instance (in a rather pathological way, lest the original regular expression pattern is refactored for re-use as in lines 12-13 of listing <see ref="lst:StatelessCodeFormatMatchEvaluator" />), while the extracted stateless <tt>BuildCodeElementString()</tt> method can be tested directly.

            <region name="table and two code listings for Match-based formatting tests">
              <raw>\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatefulCodeFormatMatchEvaluatorTest,caption=Two ways to test the CodeFormatMatchEvaluator() method,style=realCode,linerange=7-36"
                param="Stateful/CodeBlockModifierTest.cs" />
              <raw>&amp;</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatelessCodeFormatMatchEvaluatorTest,caption=Parsing and formatting can be tested directly and separately,style=realCode,linerange=19-50"
                param="Stateless/CodeBlockModifierTest.cs" />
              <raw>\end{tabular}</raw>
            </region>
          </command>
          <command name="subsection" param="Step 5: Extraction of the candidate block into a method">
            <command name="label" param="subsec:Step5" />
            The fifth step consists of replacing the candidate block with a call to a new method into which the contents of the candidate block was moved.  The names and types of the parameters will come from the local variables introduced in step 3, as would the names and types of the new method's local variables representing the return values.  The name of the extracted method should describe how the parameters are processed to produce the return values, although the new method could become an overload of the original method.

            The newly-extracted method, by virtue of the candidate block processing in the previous steps, should read and write only from and to its input parameters and return values, otherwise it would not qualify as [externally] "stateless".  To help prevent the accidental interaction with any instance fields, the method should be marked as being scoped to the class (as opposed to being scoped to instances), which is done in many programming languages by decorating the method with the <tt>static</tt> keyword.

            Many modern development environments have built-in refactoring tools that include an "extract method" action <see cite="msdn05extractmethod, eclipse08extractmethod" />, which makes this step almost trivial.
          </command>
          <command name="subsection" param="Step 6: Re-inline any variables created to facilitate a refactor">
            <command name="label" param="subsec:Step6" />
            The SME technique's sixth and final step cleans up the temporary refactoring performed as part of step 3.  This is done by performing an inline expansion of the local variables introduced to represent the new method's input parameters and return values.
          </command>
            <!-- examples
sum-of-squares is an excellent example of statlessness that can be exploited for parallel processing after seperating the computation from the looping

[re: formulas]
Notice how the SME refactoring not only makes testing trivial but also makes the processing in the original method a lot more obvious and transparent:  once ToRadians() and CalculateGreatCircleDistance() are tested the implementation of ComputeTourLength() is easier to read and it becomes easier to re-use these two methods elsewhere.

The candidate block selection in this one could be debatable:  do we include the ToRadians() calls?  If we don't, we still need to provide the method 4 doubles as input (no change there) and the radian versions of the angles are therefore only used to call CalculateGreatCircleDistance (which suggests they should follow the rest of the math).  Also, from a testing perspective, it will be more intuitive to provide the CalculateGreatCircleDistance() method angles in degrees rather than in radians.

At the same time, we don't want to have the parameters be _cities, _visitingOrder, i and j (no change in number) since the first two aren't the simplest types because they require non-trivial construction.  Indeed, those are the parameters that are set-up and provided in the stateful version, so we would not be gaining very much (we trade the division by two and the creation of FSP by the creation of those two arrays).

We *could* get the parameters to CalculateGreatCircleDistance to be two LatLon instances (from and to, only 2) because we know we can create those in one step (and there are no side-effects from reading their Lat and Lon properties), but that might not always be the case.  The tests would now look like:

    var actual = FlyingSalespersonProblem.
      CalculateGreatCircleDistance(
        new LatLon(36.12, -86.67),
        new LatLon(33.94, -118.40)
      );
    Assert.AreEqual(2887.26, actual, 0.01);

The algorithm/procedure favours the simplest types because it doesn't need knowledge of construction complexity and it would make the job of SBST/constraint solvers easiest.  There's no accounting for taste, so if a programmer decides it's better for them to use LatLon instances, then so be it.


[re: loop processing]
Notice how it is now possible to test a single instance of the <I /> element, as opposed to needing to provide a sequence of inputs (which may have restrictions of their own) and asserting/testing surrounding output (or, worse yet, if there is lots of surrounding output, it may lead to some lazy "find an instance of this in all of that" testing)

[re: string parsing]
= FootNoteFormatterState is perfect because it is impossible to test [the parsing or the formatting] in isolation because:
  = m_tag is only assignable in SimpleBlockFormatterState
  = by a method (Consume) that accepts an instance of Match (Match can't be directly created)
    = it might be easiest to stop here and create the Match from a Regex on input
  = which is called from a private method
  = which is called from TextileFormatter.Format(string)
  = which must be constructed with an instance of IOutputter
  => see revision 202 for what a "test" looks like vs. what it looks like with a small stateless method extraction
For example, consider the following <tt>OnContextAcquired()</tt> method in a class that reads from the <tt>Tag</tt> property defined in a parent class and writes to the <tt>m\_noteID</tt> field.  This method is very difficult to test because it requires considerable work to get the read-only <tt>Tag</tt> property to have a specific value and considerable work to be able to observe the result of the <tt>m\_noteID</tt> field, since it is private.  See Appendix <see ref="chapter:FootNoteFormatterState" /> for a more thorough treatment.
                <block param="itemize">
                  <command name="item"> Original method:
                    <br />
                    <command name="lstinputlisting"
                      opt="label=lst:StatefulOnContextAcquired,style=realCode,linerange=72-76"
                      param="Stateful/FootNoteFormatterState.cs" />
                  </command>
                  <command name="item"> After SME:
                    <br />
                    <command name="lstinputlisting"
                      opt="label=lst:StatefulOnContextAcquired,style=realCode,linerange=79-88"
                      param="Stateless/FootNoteFormatterState.cs" />
                    Notice that the <tt>ParseFootNoteId()</tt> method can be unit tested by calling it directly and asserting on its output directly.
                  </command>
                </block>

[re: trivial visibility change]
        private string FixEntities(string text)
        {
            // de-entify any remaining angle brackets or ampersands
            text = text.Replace("&", "&amp;");
            text = text.Replace(">", "&gt;");
            text = text.Replace("<", "&lt;");
            //Regex.Replace(text, @"\b&([#a-z0-9]+;)", "x%x%");
            return text;
        }

[re: non-SME extraction, but still testability-related]
Extracted the regular expression pattern string in revision 220 (and a Regex instance itself in revision 221), which allowed the parsing to be tested independently of the formatting.
            -->
        </command>
        <command name="section" param="Suitability">
          <command name="label" param="sec:Suitability" />
          Although designed to work around the difficulties introduced by HMS, SME is suitable for methods that are difficult to test, even in the absence of HMS, due to unwieldy arrange phases, computation coupling, the presence of side-effects and/or restrictions of visibility.  These additional suitabilities are addressed in the following sub-sections.

          <command name="subsection" param="Unwieldy arrange phase">
            <command name="label" param="subsec:UnwieldyArrangePhase" />
            If a unit test method has an <em>arrange</em> phase that is longer than 50% of the test method, it is probably an indication that there are too many parameters, the parameters are too difficult to create and/or the functionality under test is buried too deep.  SME would help isolate the functionality that is intended to be tested and thus reduce the number of parameters, since candidate blocks are selected to use between 1 and 6 parameters.  SME would also help reduce the complexity of the parameters - the input simplification step takes care of this - and expose the computation as a single, direct method call.  The arrange phase would then be shrunk considerably, if not entirely removed, leading to simpler unit tests.
            TODO: add an example?
          </command>

          <command name="subsection" param="Computation coupling">
            A method may be performing several computations in such a way to make it difficult to unit test any such computation on an individual basis, usually due to [simultaneous] operations that make it difficult to observe intermediate results.  We call this <em>computation coupling</em>.  For example, the <tt>ModifyLine()</tt> method in listing <see ref="lst:StatefulCodeFormatMatchEvaluator" /> combines parsing and formatting in a single operation <footnote>The <tt>Replace()</tt> method will call the <tt>CodeFormatMatchEvaluator()</tt> method to re-format every match.</footnote> while listing <see ref="lst:StatelessCodeFormatMatchEvaluator" /> shows how exposing the <tt>CodeBlockRegex</tt> object and the <tt>BuildCodeElementString()</tt> method makes the functionality more directly reachable.  Indeed, consult listing <see ref="lst:StatelessCodeFormatMatchEvaluatorTest" /> to see how this decoupling enables the unit testing of the parsing and the formatting, seen in the <tt>ParseZone()</tt> and <tt>BuildCodeElementString()</tt> test methods, respectively, without needing to always perform both at once.  Contrast this to the <tt>ModifyLine()</tt> test method in listing <see ref="lst:StatefulCodeFormatMatchEvaluatorTest" />, which must exercise the parsing and the formatting simultaneously.

            In this particular case, the SME technique was extended to include two other extractions:  the compile-time <tt>Pattern</tt> string constant representing the regular expression pattern and the <tt>CodeBlockRegex</tt> run-time constant representing the compiled regular expression.  This provided the unit tests with access to the same functionality used for performing the work, thereby enhancing the unit tests' realism and relevance.  Finally, SME's candidate block identification enabled the separation of parsing and formatting, which allowed both to be tested separately as units, as well as together since the public-facing functionality did not change as a result of the refactorings.

            <region name="table and two code listings for computation coupling">
              <raw>\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatefulMortonLayout,caption=The original Decode() method computes the values of x and y simultaneously,style=realCode,linerange=4-27"
                param="Stateful/MortonLayout.cs" />
              <raw>&amp;</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatelessMortonLayout,caption=The Decode() method with the DecodeAxis() method extracted out of it,style=realCode,linerange=4-31"
                param="Stateless/MortonLayout.cs" />
              <raw>\end{tabular}</raw>
            </region>

            Computation de-coupling might not always be addressable through SME as there could be computations that are tightly-coupled for readability or performance reasons and separating them would lead to a readability or performance loss.  An example of two computations that would be worse if separated can be seen in listing <see ref="lst:StatefulMortonLayout" />, where we can see that <tt>x</tt> and <tt>y</tt> are computed simultaneously.  Compare this to listing <see ref="lst:StatelessMortonLayout" />, where <tt>x</tt> and <tt>y</tt> are computed separately, meaning two runs through the loop on <tt>bits</tt> instead of one.  It is also less obvious, in the second case, that the values of <tt>x</tt> and <tt>y</tt> were obtained by interpreting interleaved bits of the Morton Layout's <tt>index</tt> <see cite="msdn08deepzoom" />.
          </command>

          <command name="subsection" param="The presence of side-effects">
            A method may not suffer from the state problem (it neither reads from nor writes to instance fields), but nevertheless has side-effects that increase the difficulty when writing unit tests, such as the modification of input parameters or interactions with the environment.  Stateless method extraction could potentially still take place, provided some candidate blocks can be identified around the code causing said side-effects.  This would allow some simple unit tests to be written against the simple stateless methods extracted, while still allowing more involved integration tests against the original method.

            <command name="lstinputlisting"
              opt="label=lst:StatefulMutableVector,caption=The CalculateAngle() method causes side-effects on its parameters,style=realCode,linerange=3-32"
              param="Stateful/MutableVector.cs" />

            An example of a method producing a result and causing side-effects can be seen in listing <see ref="lst:StatefulMutableVector" />.  The <tt>CalculateAngle()</tt> method calls the <tt>Normalize()</tt> method on <tt>MutableVector</tt>, which irreversibly scales the parameters to be unit vectors.  SME's candidate block identification would exclude both calls to <tt>Normalize()</tt> and would allow a version of the <tt>CalculateAngle()</tt> method to be created that had no side-effects but assumed both parameters were of unit length.
          </command>

          <command name="subsection" param="Visibility or access restrictions">
            An instance method may already be stateless, but, because of its nature, it may be difficult to reach with unit tests.  This situation can manifest itself when the class under test subclasses another class to override some of its methods, but said methods are only visible to the superclass and subclasses thereof.  This is usually achieved with a visibility or accessibility of <tt>protected</tt>.  This can also happen when the class under test explicitly implements an interface (when using C#): the explicitly-implemented interface members will not be visible from the class' default interface <see cite="msdn10explicitinterface" />.

            In both cases, SME can help extract one or more stateless methods that will not require an instance of the class to be created and can be directly unit tested, while keeping the original methods with the visibility and accessibility they require.
          </command>

          <!-- TODO:
          Talk about file stream processing if we're starting to run out of content
          <command name="subsection" param="Unsuitability">
            TODO: There exist cases that even SME has difficulty helping; is it worth expanding upon the "uninteresting categories" given in Step 1?  What about for stuff not mentioned there, such as calls to base class methods as in KeePassLib's BinaryReaderEx.ReadBytes(int) that calls BinaryReader.ReadBytes(int) through base?
          "Applying SME with parameterizable side-effects"
          TODO: talk about using call-backs/function pointers
          </command>
          -->
        </command>

        <command name="section" param="Applicability">
          In general, SME is most applicable to existing or legacy projects that were built with few or no unit tests.  As a result, their source code was not written with testability in mind, nor is it possible (for various reasons) to make large, sweeping testability-related changes.  The prospect of fixing defects or adding features to such a project without sufficient tests to catch regressions would seem risky.  SME could be used to introduce easily-testable methods - along with some unit tests - to the affected source code before making each fix or adding each new feature, thereby establishing a functionality baseline, if only a partial one.

          As noted in section <see ref="sec:Suitability" />, SME is suitable for more than HMS and, by the same token, can also be applied to more than legacy projects.  Sometimes there are technological reasons that impede the testability of a class or method.  For example, some frameworks force the introduction of a parameterless constructor to be able to create an instance of a class for the purposes of serialization.  Such frameworks may introduce mutable state where none would be present otherwise and SME can then be used to help keep the unit tests simple.

          It would seem that any software project with insufficient testing coverage is fair game, although as the following sub-sections discuss, there are conditions under which SME could deliver more value than others.

          <command name="subsection" param="Identifying stateless methods">
            <command name="label" param="subsec:IdentifyStateless" />
            SME will work best if the programming language or toolkit used has a concept of a <em>stateless</em> method.  This would ensure that each method marked as such only reads from its input parameters, only writes to its return values, does not read from or write to any instance or static fields (reading from constants is acceptable, as long as they represent immutable instances), does not interact with the environment (such as reading a file, sending data across a network or updating a database) and only calls methods similarly identified as stateless.

            <region name="table and two code listings for the proposed attributes">
              <raw>\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatelessStatelessAttribute,caption=A proposed Stateless attribute with a sample of its use,style=realCode,linerange=3-24"
                param="Stateless/StatelessAttribute.cs" />
              <raw>&amp;</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatelessImmutableAttribute,caption=A proposed Immutable attribute with a sample of its use,style=realCode,linerange=3-24"
                param="Stateless/ImmutableAttribute.cs" />
              <raw>\end{tabular}</raw>
            </region>

            Such a concept need not be implemented at the language level and could instead be implemented by a static code analysis (SCA) tool with the help of a designated decoration implemented, for example, as an attribute in .NET or as an annotation in Java.  Listing <see ref="lst:StatelessStatelessAttribute" /> shows a C# implementation of the proposed <tt>Stateless</tt> attribute and a sample of its use.
          </command>
          <command name="subsection" param="Identifying immutable instances">
            A type which contains no mutable state is said to be <em>immutable</em>.  Any state an immutable type has can only be set during construction through the parameters of constructors or factory methods and all its instance methods either return that state directly or perform computations with it (and possibly some input parameters), in a manner not unlike stateless methods.  Immutable types can make SME better because there exists, by definition, no sequence of method calls on their instances that can modify their state and therefore there can be no side-effects as a result of using immutable types as inputs to stateless methods.  As discussed in section <see ref="subsec:Step4" />, immutable types are considered "simple" and can therefore provide stateless methods with convenient groupings of related input parameters, instead of specifying them separately.  The use of immutable types can thus provide additional readability in unit tests at the expense of a constructor call.

            Similar to the <tt>Stateless</tt> decoration suggested in sub-section <see ref="subsec:IdentifyStateless" />, a decoration could be defined to identify types that are immutable and thus safe to use as constants or input parameters.  Listing <see ref="lst:StatelessImmutableAttribute" /> shows a C# implementation of the proposed <tt>Immutable</tt> attribute and a sample of its use.  This idea was further developed by Bazuzi and Pilch-Bisson <see cite="pilch07enforcingimmutability" />.

            These proposed <tt>stateless</tt> and <tt>immutable</tt> decorations have the additional benefit that they could also be exploited by an optimizing compiler to inline the stateless methods (and apply other such performance improvements) in release mode due to the new guarantees of immutability and invariance they provide by being enforced by the compiler and/or SCA.
          </command>
          <command name="subsection" param="Controlling visibility">
            The SME technique will work best if the programming language has features to control the visibility of methods to ensure that the newly-introduced stateless methods do not pollute the public interface of the affected classes.  C# has the <tt>internal</tt> access modifier <see cite="msdn10internal" />, which, when combined with the <tt>InternalsVisibleTo</tt> attribute <see cite="msdn10internalsvisible" />, can expose the stateless methods to a unit test project but not to consumers of the API, which, in effect, hides the results of SME from end-users.  Java has a similar concept with its packages <see cite="java96packages" />.  Indeed, unless the <tt>public</tt> or <tt>private</tt> access modifiers are used, a method will be visible from within the package it was defined <see cite="java96names" />, which means unit tests in the same package will have access to the newly-extracted stateless methods but consumers of the API will not.

            An alternative to visibility controls or access modifiers - especially for programming languages without such features - is to place the extracted methods in a separate class (possibly named after the original class, but suffixed with <tt>Stateless</tt>) or even not attached to any class, provided the language makes this possible.  It may even be the case that, upon further consideration, a newly-extracted method should really belong in the class of one of its parameters.  For example, the <tt>CrossProduct()</tt> and <tt>DotProduct()</tt> methods extracted from the <tt>Plane</tt> class in listing <see ref="lst:StatelessVector" /> would probably be best located in the <tt>Vector</tt> class.
          </command>
        <!-- Loop item processing is difficult when there are operations other than per-item processing, such as stats and loop invariants
        File processing could be abstracted to stream or sequence processing, which is more testable through MemoryStream and IEnumerable.
        -->
        </command>

        <command name="section" param="Decisions made">
          <region name="Candidate block identification">
          The candidate block identification step in section <see ref="subsec:Step1" /> requires that blocks contain only stateless statements, because statelessness is a transitive property and the presence of any operation that causes side-effects in a method will disqualify all methods that call such a method from claiming statelessness.  A stateless method must therefore only call stateless methods, otherwise the effort is defeated.

          The candidate block identification also calls for selecting computations that use 1 to 6 inputs because a method that accepts no parameters would have to return a constant (otherwise it could not be considered stateless) while 6 was selected as a suggested maximum number of inputs as a matter of experience, since too many inputs might make it difficult to write tests, defeating the goal of this thesis.  <!-- TODO: a stateless method with a single parameter could be implemented as an extension method or hanging off that class, as mentioned with Vector's [Dot|Cross]Product --> <!-- TODO: Binder p.172 "Suppose a small function has 6 or fewer variables.", p. 389 "It is effective for small methods: roughly [cyclomatic complexity] of 10 or less, six or fewer instance variables." -->

          The last criterion in block candidacy is selecting computations that produce 1 to 3 outputs because a method that does not return any results likely causes side-effects - thus can not be considered stateless - and side-effects are not trivial to observe during unit testing.  The suggested maximum number of outputs was also selected from experience and is again intended to keep unit tests simple, mostly because very few programming languages support returning more than one value at once.  Returning multiple values at once is often emulated by using a container for the values, either through a specialized type (such as <tt>Vector</tt> in listings <see ref="lst:StatefulVector" /> and <see ref="lst:StatelessVector" /> or <tt>EarthLocation</tt> in listing <see ref="lst:StatelessImmutableAttribute" />) or an anonymous one, such as a tuple <see cite="msdn10tupleclass, python08datastructures" />.  <!-- TODO: talk about experimental tuple unpacking in Mono: http://tirania.org/blog/archive/2009/Dec-23.html --> <!-- TODO: "returning" more than one value can be done with a call-back/functor -->
          </region>

          The intent of incidental operation re-ordering is to maximize the number of operations in a candidate block while minimizing the number of inputs and outputs.  This is done to avoid extracting stateless methods that perform too few operations, which would cause unit testing to become a high-work and low-return activity. <!-- TODO: if an example is warranted, the best one is probably cartesian to polar coordinates: it makes no sense to extract (_x * _x) or (_y * _y) or (xSquared + ySquared) individually, but collectively, yes.  Similar for the computation of theta, especially if Math.Atan(y, x) wasn't available. -->  Although this incidental operation re-ordering step is automatable through data dependency analysis and program slicing, a programmer will likely be the best judge of which operations are considered related and if these operations collectively have a recognized or standard meaning.  For example, the expression <tt>new Vector(a.Y * b.Z - a.Z * b.Y, a.Z * b.X - a.X * b.Z, a.X * b.Y - a.Y * b.X)</tt> is better identified as a <tt>CrossProduct()</tt> method that accepts two <tt>Vector</tt> instances <tt>a</tt> and <tt>b</tt>.

          Input simplification's intent is to minimize the amount of knowledge the stateless method will need to perform its processing or computation.  It does this by optimizing the inputs and outputs such that the upcoming unit tests (exercising the to-be-extracted stateless method) contain a minimal number of statements, while balancing the readability and maintainability of both the stateless method and said upcoming unit tests.  Another reason for favoring "simple" types - usually the language's built-in base types, such as strings, integers and floating-point numbers - is that they are immutable and/or passed by value, meaning their use from within a stateless method will not result in side-effects.  Although any type with instance fields that are set at construction time and are read-only thereafter is acceptable as an input parameter, readability and maintainability should be considered if less than the majority of its instance fields are used by the method under test.  For example, the use of a <tt>DateTime</tt> struct as a parameter when only its <tt>Year</tt> and <tt>Month</tt> properties are needed might suggest that two integer parameters for <tt>year</tt> and <tt>month</tt> would make for a better choice.

          In the absence of programming language features to definitely identify and enforce a method as stateless, the <tt>static</tt> keyword is used to at least make it more difficult to access or manipulate HMS.  It should be noted that it is not always possible to restrict the use of HMS from a static method.  Making a stateless method static also makes it callable without first having to create an instance of a class.  Unfortunately, the <tt>static</tt> keyword does not prevent manipulation of static fields nor does it enforce that all method calls therein are also stateless.

          The stateless methods' visibility of <tt>package</tt> or <tt>internal</tt> was selected to make the use of SME invisible to end-users.  Indeed, having the test fixture in the same package as the class under test is the convention for JUnit <see cite="vogel07junittutorial" />.  Using MSTest to test methods marked as internal in another project is not only documented but also assisted by Visual Studio <see cite="msdn10settinginternals" />.

          Sub-section <see ref="subsec:UnwieldyArrangePhase" /> argues for a threshold on the size of a unit test's <em>arrange</em> phase that should trigger an investigation into the content of said arrange phase, to see if simplification through SME or other means is possible.  The intent here is to minimize the size of unit tests to encourage their use.  Tests with long arrange phases are still valid but beyond a certain size might be considered <em>integration</em> tests more than <em>unit</em> tests.

          The set of transformations performed during SME were designed to be low-impact in order to encourage their use and reduce the risk of breaking the very code to which unit tests added.  Indeed, "altering internal structure without changing external behaviour" is the very definition of refactoring <see cite="fowler00refactoring" /> and, as such, care should be taken to <em>only</em> perform the SME steps during the process and to resist the temptation to fix defects or add features at the same time.  Once SME has been performed, unit tests are written against the new method to establish a functionality baseline and both sets of changes are committed to source control.  Only then will it be safe to add unit tests to expose any potential defects or missing features encountered during SME and then fix the defects or add the features in the presence of the safety net added in the previous step.  Binder calls this approach <em>Incremental Testing</em> <see cite="binder00classes, binder00testharness" />.
        </command>
        <command name="section" param="Summary">
          <!-- key points of what was presented and linkage to next chapter -->
          ...
        </command>
      </command>
      <command name="chapter" param="Results and Validation">
        <command name="section" param="Introduction">
          <!-- what the chapter is about -->
          ...
        </command>
        <command name="section" param="Evaluation design">
          <!-- TODO: should we move a few words from the overview section up here? -->
        <!--
        = TODO: regarding the motivation for CGT in our case
        == The better the statement coverage of the generated tests, the more testable the original source code under the transformation is considered.
        = {Project}.ManualTests created to avoid interference with Pex if had used {Project}.Tests
        = discuss experiments with Pex (if only to introduce for another section)
        == trade-offs of automatic test generation based on code coverage
        == differences between a constraint solver and evolutionary testing
          -->
          <command name="subsection" param="Overview">
            The goal of stateless method extraction is to improve the testability of source code, especially that of classes with hidden mutable state.  To measure SME's efficiency and validate its effectiveness, it is compared to the following strategies:
            <block param="enumerate">
              <command name="item"> Do nothing</command>
              <command name="item"> TODO: other strategies have been commented out, but can be added if we think there is insufficient data</command>
              <!-- TODO: we can add more strategies later
              <command name="item"> Write test helper methods</command>
              <command name="item"> Increase visibility of mutable state</command>
              <command name="item"> Replace mutable state with immutable state</command>
              <command name="item"> Use private accessors</command>
              -->
              <!-- a.k.a. "Private Access Driver" [Binder, chapter 19].  TOOD: mention in the detailed results that this won't help peek at local variables that would be turned into return values by SME -->
              <!-- There are other strategies, such as "Built-in Test Driver" (an inner class of the CUT has access to the CUT's private members), "Drone" (using multiple inheritance to with Eiffel to get at private members -->
            </block>

            The evaluation uses select interesting and/or difficult-to-test methods from the source code of the following C# open-source projects (TODO: provide links/citations, plus version numbers?):
            <block param="enumerate">
              <command name="item"> AtomicCms</command>
              <command name="item"> KeePassLib</command>
              <!-- TODO: is PivotStack good enough? <command name="item"> PivotStack</command> -->
              <command name="item"> Textile</command>
            </block>

            The following evaluations are performed for each of the competing strategies on each of the open-source projects:
            <block param="enumerate">
              <command name="item"> Complexity of the unit tests.</command>
              <command name="item"> Number of changes to the class under test's public interface.</command>
              <command name="item"> Percentage of branches covered using concolic testing.</command>
            </block>

            The evaluations are now explained in further detail, followed by the strategies, the selected methods from the open-source projects and finally how the evaluations were conducted.
          </command>
          <command name="subsection" param="Evaluations">
            <command name="subsubsection" param="Complexity of the unit tests">
              <block param="quote">
                "If the effort to produce and run tests is high, however, less testing will be done." <see cite="binder00testharness" /> <!-- page 1043 -->
              </block>
              There appears to be consensus regarding the minimization of unit tests' sizes <see cite="feathers05unittesting, osherove06writemaintainable, stewart10testsizes" />.  Keeping unit tests small is generally with the intention of reducing the friction related to writing said unit tests (as noted above) as well as increasing the readability and maintainability of the source code <see cite="graham93onlisp" />.

              TODO: talk about the unit tests I wrote both on top of the base and on top of the manual versions, but out of the way of Pex.  These are the ones being evaluated for complexity, although it might be interesting to also measure the complexity of the tests generated by Pex.

              The tool used for evaluating the complexity of unit tests is the <em>Visual Studio Code Metrics PowerTool 10.0</em> <see cite="ms11codemetrics" /> (CMPT).  It can compute, among others, a <em>Maintainability Index</em> (MI) that is derived and adapted <see cite="morrison07maintainabilityindex" /> from the Carnegie Mellon University's Software Engineering Institute metric of the same name <see cite="vandoren97maintainabilityindex" />.  In short, the tool combines a few metrics obtained by scanning the byte code and scales the result between 0 and 100.  Higher values are better.
              <!-- TODO: talk about which variant of the metric is used, what counts toward the score and what does not, which tool was used and how the results were extracted -->
            </command>
            <command name="subsubsection" param="Number of changes to the class under test's public interface">
              It could be undesirable to make changes to the CUT's public interface simply to increase its testability.  Reasons for not wanting any such changes include:
              <block param="enumerate">
                <command name="item"> The class is part of an API with pre-existing releases. Changes to the API could break third-party applications consuming it.</command>
                <command name="item"> The class must implement a specific interface; a technological variation of the previous reason.</command>
                <command name="item"> Exposing instance state as directly mutable might allow callers to violate some constraints or invariants.</command>
              </block>
              This second evaluation, therefore, counts how often each strategy causes a change to the public interface of the class under test, compared to the original version.  This metric will be referred to as the <em>Public Interface Changes</em> (PIC) metric.  Lower values are better, with zero being ideal.  The tool used is the <em>Public Interface Comparer</em> and it is further described in Appendix <see ref="chapter:PublicInterfaceComparer" />.
            </command>
            <command name="subsubsection" param="Percentage of branches covered using concolic testing">
              The Pex tool <see cite="tillman08pex" /> can be used to analyze a specified project and generate unit tests to exercise as much of that project's source code as it can.  Pex's ability to exercise the CUT's methods in an automated and unattended fashion provides a very good objective evaluation of testability.  This ability is measured by the code coverage reported when executing the generated unit tests with a code coverage tool.  Higher values are better.  Version 0.91.50418.0 of Pex is used, along with NUnit <see cite="poole00nunit" /> version 2.4.8 to run the unit tests and NCover <see cite="waldschmidt04ncover" /> version 1.5.8 to measure the code coverage.
            </command>
          </command>
          <command name="subsection" param="Strategies">
            <command name="subsubsection" param="Do nothing">
              No transformations are to be performed to the IUT, the source code will be used as-is to establish a baseline.
            </command>
            <command name="subsubsection" param="Extract stateless methods">
              The very approach proposed by this thesis; stateless methods are extracted where good candidate blocks are identified.
            </command>
          </command>
          <command name="subsection" param="Selected methods">
            Table <see ref="tbl:InterestingMethods" /> lists the methods that have been selected because they represent testability challenges (difficulties?). (TODO: add more methods)
            <block param="table" opt="htbp">
              <raw>\begin{tabular}{l l l l}</raw>
                Project <raw>&amp;</raw> Namespace <raw>&amp;</raw> Class <raw>&amp;</raw> Method <raw>\tabularnewline</raw>
                <command name="hline" />
                <raw>\multicolumn{4}{l}{Textile}</raw> <raw>\tabularnewline</raw>
                <raw>&amp;</raw> <raw>\multicolumn{3}{l}{Textile.States}</raw> <raw>\tabularnewline</raw>
                <raw>&amp;</raw> <raw>&amp;</raw> <raw>\multicolumn{2}{l}{FootNoteFormatterState}</raw> <raw>\tabularnewline</raw>
                <raw>&amp;</raw> <raw>&amp;</raw> <raw>&amp;</raw> void Enter() <raw>\tabularnewline</raw>
                <raw>&amp;</raw> <raw>&amp;</raw> <raw>&amp;</raw> void OnContextAcquired() <raw>\tabularnewline</raw>

                <raw>&amp;</raw> <raw>\multicolumn{3}{l}{Textile.Blocks}</raw> <raw>\tabularnewline</raw>
                <raw>&amp;</raw> <raw>&amp;</raw> <raw>\multicolumn{2}{l}{CodeBlockModifier}</raw> <raw>\tabularnewline</raw>
                <raw>&amp;</raw> <raw>&amp;</raw> <raw>&amp;</raw> string ModifyLine(string) <raw>\tabularnewline</raw>
                <raw>&amp;</raw> <raw>&amp;</raw> <raw>&amp;</raw> string CodeFormatMatchEvaluator(Match) <raw>\tabularnewline</raw>

                <raw>\multicolumn{4}{l}{KeePassLib}</raw> <raw>\tabularnewline</raw>
                <raw>&amp;</raw> <raw>\multicolumn{3}{l}{KeePassLib.Cryptography.PasswordGenerator}</raw> <raw>\tabularnewline</raw>
                <raw>&amp;</raw> <raw>&amp;</raw> <raw>\multicolumn{2}{l}{PatternBasedGenerator}</raw> <raw>\tabularnewline</raw>
              <raw>&amp;</raw> <raw>&amp;</raw> <raw>&amp;</raw> string ExpandPattern(string) <raw>\tabularnewline</raw>
              <raw>\end{tabular}</raw>
              <command name="caption" param="Selected interesting methods" />
              <command name="label" param="tbl:InterestingMethods" />
            </block>
          </command>
          <command name="subsection" param="How it works">
            <region comment="Intro">
            The source code to the projects was imported into a source control repository<footnote>The Subversion repository used for the evaluation of this thesis is available at <br /> <url>https://testoriented.googlecode.com/svn/suitability/trunk</url></footnote>.  Each project gets its own folder and the imported version (which serves as a baseline) is placed in a sub-folder called <tt>base</tt>.  Some slight modifications were made to the source code to simplify the evaluation, detailed as follows:
            </region>
            <command name="subsubsection" param="Consolidate projects">
              If a project consisted of many sub-projects, the source files for those sub-projects were combined into a single project, to simplify the configuration of Pex.
            </command>
            <command name="subsubsection" param="Remove provided tests">
              Any existing automated tests were removed, otherwise Pex would be able to trivially reach areas of the CUTs through their tests, defeating the purpose of that part of the evaluation.
            </command>
            <command name="subsubsection" param="Add two empty test projects">
              To help Pex generate unit tests, a corresponding empty test project was created for each project, as was another emtpy test project created for the complexity evaluations.  Each empty test project was configured to reference its associated project.  The test projects are ready to have test classes added to them.
            </command>
            <command name="subsubsection" param="Expose internal members to Pex">
              Each project was configured to make any methods marked as <tt>internal</tt> visible to both the empty test project and to Pex itself, using the <tt>InternalsVisibleTo</tt> attribute.
            </command>
            <command name="subsubsection" param="Disable functionality that interferes with the evaluation">
              The KeePassLib project contains code to show a modal message box dialog that must be dismissed by an end-user.  This is undesirable for an unattended evaluation and therefore the body of the <tt>SafeShowMessageBox()</tt> method in the <tt>MessageService</tt> class was removed, as was that of the <tt>SafeShowMessageBoxInternal()</tt> method in the <tt>MessageService</tt> class.  Also, to prevent assertions in the projects from interrupting the automated evaluation in the same way, the compilation options were modified to use the <em>Release</em> configuration with optimizations disabled and full debug symbols enabled <footnote>Assertions will only display a dialog if the <tt>DEBUG</tt> constant is defined and it is not defined when using the Release configuration.  Disabling optimizations and enabling debug symbols is done to help keep the static code analysis as representative to the original source code as possible.</footnote>.
            </command>

            Now that we have a baseline for each project, we can create a copy of the <tt>base</tt> folder for each strategy we wish to compare against.  As such, the following folders were created:  <tt>manual</tt> (manual application of SME), TODO.

            The evaluation is conducted automatically using a small program written with NAnt <see cite="shaw06nant" />.  The major steps are as follows:
            <command name="subsubsection" param="Create a working copy">
              Pex modifies the test project file as part of its test generation process.  To make the evaluations repeatable, a copy is made, at the start of the evaluation, of each strategy folder of each project, erasing the previous run's folders as necessary.  Pex can then operate in each working copy without chance of interference from the artifacts of any previous runs.
            </command>
            <command name="subsubsection" param="Compile">
              All the analysis tools (CMPT, Public Interface Comparer and Pex) work by analyzing the byte code of the projects (as opposed to their source code) and thus the next step is to compile the projects.
            </command>
            <command name="subsubsection" param="Run manual tests">
              As a sanity check, the tests written to be evaluated for their complexity are run to make sure they all pass.
            </command>
            <command name="subsubsection" param="Determine public interface differences">
              The PIC metric is computed on each project's IUT and the report is stored in the project's folder as the file <tt>PublicInterfaceDifferences.txt</tt>.
            </command>
            <command name="subsubsection" param="Evaluate maintainability of manual tests">
              The MI metric is computed on the unit tests.
              TODO: explain what tests are included and how the metric is aggregated
            </command>
            <command name="subsubsection" param="Invoke Pex Wizard">
              Pex first needs to first run in "Wizard" mode, which inspects the IUT and generates test helper methods called "parameterized unit tests".  Unfortunately, there are some defects in Pex that garble the test project files and must then be repaired.  This is done using the Extensible Stylesheet Language (XSL) transformation file <tt>FixPexWizard.xsl</tt> located in the <tt>Tools</tt> folder.  Lastly, the projects are recompiled so that Pex may perform the next step by inspecting the new byte code.
            </command>
            <command name="subsubsection" param="Invoke Pex Generator">
              Pex is now run in "Generate" mode, which produces the actual unit tests by using the helpers it generated in the previous step.  Again, some Pex defects call for the repair of the affected test project files, this time using the <tt>FixPexGenerator.xsl</tt> XSL transformation file.  The projects are recompiled one last time in preparation for running the generated tests.
            </command>
            <command name="subsubsection" param="Run generated tests with coverage">
              The console NUnit runner executes all the unit tests that Pex generated while NCover monitors the execution to collect code coverage data for the IUT.  It is not important whether the tests pass, fail or end in error - Pex by its very nature will generate tests that throw or expect to throw ArgumentException instances - it is only important to record code coverage.
            </command>
            <command name="subsubsection" param="Record results">
              An online spreadsheet <footnote>The spreadsheet can be seen at <url>https://docs.google.com/spreadsheet/ccc?key=0Ag6eugnyWA09dG9zQnFtTlQ0Z1dGUjI5TUlFMnpFWWc</url></footnote> is used to collect the results.  Its columns are explained in table <see ref="tbl:SpreadsheetColumns" />.
              <block param="table" opt="htbp">
                <tabular spec="p{0.2\textwidth} p{0.75\textwidth}">
                  <tr><td>Column name</td><td>Description</td></tr>
                  <hline />
                  <tr><td>Timestamp</td><td>The date and time the result row was inserted</td></tr>
                  <tr><td>Batch #</td><td>The revision of the Subversion repository or <tt>private</tt> if run for testing purposes instead of in a batch</td></tr>
                  <tr><td>Project</td><td>The name of the project</td></tr>
                  <tr><td>Strategy</td><td>The name of the strategy employed</td></tr>
                  <tr><td>TSP</td><td>Total Sequence Points, the denominator for code coverage percentage calculation</td></tr>
                  <tr><td>VSP</td><td>Visited Sequence Points, the numerator for code coverage percentage calculation</td></tr>
                  <tr><td>DPI</td><td>Differences in Public Interface</td></tr>
                  <tr><td>MI</td><td>Maintainability Index of the manual tests</td></tr>
                </tabular>
                <command name="caption" param="Names and descriptions of spreadsheet columns" />
                <command name="label" param="tbl:SpreadsheetColumns" />
              </block>
            </command>
          </command>
        </command>
        <command name="section" param="Results">
          ...
        </command>
        <command name="section" param="Detailed results">
          <!--
          = applying the stateless method extraction technique to the open-source projects
          = applying the technique to examples provided in original paper
          = applying the technique backwards to PivotStack
          = evaluating with code coverage percentage of tests generated by Pex
          = difficulties with Pex:
          == 2010/07/14: "tests generated between runs of Pex are not always the same due to timeouts"
          == not aware of test double opportunities (i.e. mocks)
          == 2010/09/11: "time - it will give up/timeout to not be stuck"
          == 2010/09/11: "intent - unit testing is (validation +) verification exercise using specification/requirements, neither of which are available"
          === "Parameter of abstract type Stream (System.IO) is somewhat vague; there are many implementations of it that could be used, but for unit tests, a MemoryStream should probably ue used. Pex has no such guidance and seems to [randomly?] pick System.Security.Cryptography.TailStream which I can not find in System.Security nor in MSDN documentation!"
          == 2010/09/11: "no focus - unless code is decorated with exclude/ignore attributes"
          == 2010/09/11: "scope"
          === "testability issue" with certain methods, such as:
          ==== Environment.get_NewLine()
          ==== Environment.get_OSVersion()
          ==== File.*
          ==== FileStream..ctor
          === "uninstrumentable" with memory allocation & garbage collection
          === "uninstrumented" source code not available for analysis
          === "extern" behaviour only available at runtime; special case of "uninstrumented"
          === HttpWebRequest (System.Net) does not have a public constructor; the Remarks of the class say to call WebRequest.Create() (which is not instrumented)
          === Neither does Match (System.Text.RegularExpressions) and it is not instrumented anyway.
          = evaluating with metrics (cyclomatic complexity)
          -->
          <!--
          TODO:
          = number of stateless methods extracted per project
          = number of tests generated by Pex
          = number of tests written by hand
          = observations about difficulties, suitabilities, etc.
          -->
          ...
        </command>
        <command name="section" param="Validation">
          <!-- Demonstrate that you met your goal
          Objectives can be checked off one by one
          If goal was "improve X", then show that X became better (i.e. less clicks, etc.)
          Verification is not very useful; this really has to be about validation -->
          <!-- Cross-reference with Scope and discuss observed trade-offs of other potential approaches -->
          ...
        </command>
        <command name="section" param="Summary">
          ...
        </command>
      </command>
      <command name="chapter" param="Summary of work, Conclusions and Future Work">
        <command name="section" param="Introduction">
          <!-- what the chapter is about -->
          ...
        </command>
        <command name="section" param="Summary of results">
          <!-- Review goal and contributions -->
          ...
        </command>
        <command name="section" param="Conclusions">
          <!-- list of inferences made -->
          ...
        </command>
        <command name="section" param="Future work">
          <!-- best ideas of next steps -->
          ...
        </command>
      </command>
    </command>
    <command name="appendix">
      <!-- material of length that would impede the flow of the -->
      <!-- main body: program listings, long data results, long mathematical -->
      <!-- proofs -->
      <command name="chapter" param="Acronyms">
        <!-- TODO: do we need to turn this into a glossary with explanations? -->
        <block param="description">
          <command name="item" opt="API"> Application Programming Interface</command>
          <command name="item" opt="CT"> Concolic Testing</command>
          <command name="item" opt="CGT"> Computer-Generated Tests</command>
          <command name="item" opt="CMPT"> Code Metrics PowerTool</command>
          <command name="item" opt="CUT"> Class Under Test</command>
          <command name="item" opt="ET"> Evolutionary Testing</command>
          <command name="item" opt="GA"> Genetic Algorithms</command>
          <command name="item" opt="HGT"> Human-Generated Tests</command>
          <command name="item" opt="HMT"> Hidden Mutable State</command>
          <command name="item" opt="IUT"> Implementation Under Test</command>
          <command name="item" opt="MI"> Maintainability Index</command>
          <command name="item" opt="MST"> Metaheuristic Search Technique</command>
          <command name="item" opt="MUT"> Method Under Test</command>
          <command name="item" opt="OO"> Object-Oriented</command>
          <command name="item" opt="OOP"> Object-Oriented Programming</command>
          <command name="item" opt="PIC"> Public Interface Changes</command>
          <command name="item" opt="RT"> Random Testing</command>
          <command name="item" opt="SBST"> Search-Based Software Testing</command>
          <command name="item" opt="SCA"> Static Code Analysis</command>
          <command name="item" opt="SE"> Symbolic Execution</command>
          <command name="item" opt="SME"> Stateless Method Extraction</command>
          <command name="item" opt="XSL"> Extensible Stylesheet Language</command>
        </block>
      </command>
      <command name="chapter" param="Simple parsing and templating made trivial to test">
        <command name="label" param="chapter:FootNoteFormatterState" />
        TODO: tell the sad tale of untestability in FootNoteFormatterState and show the unit tests before and after SME using content from revision 99, 202 and whatever revision will add a test for OnContextAcquired to prove the point.
<!--
From Textile/States/FootNoteFormatterState.cs;

Revision 99:
Before
protected override void OnContextAcquired()
{
  Match m = Regex.Match(Tag, @"^fn(?<id>[0-9]+)");
  m_noteID = Int32.Parse(m.Groups["id"].Value);
}

During
protected override void OnContextAcquired()
{
  string input = Tag;
  Match m = Regex.Match(input, @"^fn(?<id>[0-9]+)");
  string result = Int32.Parse(m.Groups["id"].Value);
  m_noteID = result;
}

After
protected override void OnContextAcquired()
{
  m_noteID = ParseFootNoteId(Tag);
}

internal static int ParseFootNoteId(string input)
{
  Match m = Regex.Match(input, @"^fn(?<id>[0-9]+)");
  return Int32.Parse(m.Groups["id"].Value);
}

Revision 202:
Before
public override void Enter()
{
  Formatter.Output.Write(
    string.Format("<p id=\"fn{0}\"{1}><sup>{2}</sup> ",
      m_noteID,
      FormattedStylesAndAlignment(),
      m_noteID));
}

During
public override void Enter()
{
  var noteID = m_noteID;
  var formattedStylesAndAlignment = FormattedStylesAndAlignment();
  var result = string.Format("<p id=\"fn{0}\"{1}><sup>{2}</sup> ",
    noteID,
    formattedStylesAndAlignment,
    noteID);
  Formatter.Output.Write(result);
}

After
public override void Enter()
{
  Formatter.Output.Write(
    FormatFootNote(m_noteID, FormattedStylesAndAlignment()));
}

internal static string FormatFootNote(int noteId, string formattedStylesAndAlignment)
{
  return string.Format("<p id=\"fn{0}\"{1}><sup>{2}</sup> ",
    noteID,
    formattedStylesAndAlignment,
    noteID));
}

-->
      </command>
      <command name="chapter" param="Public Interface Comparer tool">
        <command name="label" param="chapter:PublicInterfaceComparer" />
        TODO: explain the tool, point to its location in source control and maybe include some source code, if not of the implementation, then of its tests
      </command>
    </command>
    <command name="bibliographystyle" param="abbrv" />
    <command name="bibliography" param="thesis" />
  </document>
</iTeX>