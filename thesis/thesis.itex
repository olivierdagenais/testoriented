<?xml version="1.0" encoding="UTF-8"?>
<iTeX>
  <preamble><!-- !TEX TS-program = pdflatex -->
    <!-- !TEX encoding = UTF-8 Unicode -->

    <command name="documentclass" opt="12pt" param="dalthesis" />

    <command name="usepackage" opt="utf8" param="inputenc" /> <!-- set input encoding (not needed with XeLaTeX) -->

    <!-- disable turning "fi", "ff", etc. into one character: http://www.latex-community.org/forum/viewtopic.php?f=5&t=953  -->
    <command name="usepackage" param="microtype" />
    <command name="DisableLigatures" param="encoding = *, family = *" />

    <command name="usepackage" param="array" />

    <region comment="Make sure spaces before citations are non-breaking">
      <raw>\let\originalcite\cite</raw>
      <raw>\renewcommand{\cite}[1]{\unskip~\originalcite{#1}}</raw>
    </region>

    <region comment='the "listings" package is used for source code snippets'>
      <command name="usepackage" param="listings" />
      <command name="usepackage" param="courier" />
      <command name="lstset" param="tabsize=2" />
      <command name="lstdefinestyle" param="realCode}{basicstyle=\tiny\ttfamily, numbers=left, numberstyle=\tiny\ttfamily" />
      <command name="lstdefinestyle" param="pseudoCode}{basicstyle=\small, numbers=none" />
      <!-- Override the lstinputlisting command to surround it inside braces,
      otherwise the style parameter does not work:
        http://tex.stackexchange.com/q/21663/1892
        http://stackoverflow.com/questions/2908908/#2909530
      -->
      <raw>\let\originallstinputlisting\lstinputlisting</raw>
      <raw>\renewcommand{\lstinputlisting}[2][]{{\originallstinputlisting[{#1}]{#2}}}</raw>
    </region>

    <region comment="URLs and references are hyperlinked">
      <command name="usepackage" param="url" />
      <command name="usepackage" param="hyperref" opt="pdftitle={Stateless Programming And Testing: Extracting a functional layer from object-oriented code},pdfauthor={Olivier Dagenais},colorlinks=true,linkcolor=black,anchorcolor=black,citecolor=black,citecolor=black,urlcolor=black,pdftex=true" />
    </region>

    <region comment="Make sure spaces before references are non-breaking">
      <command name="usepackage" param="nameref" />
      <raw>\let\originalref\ref</raw>
      <raw>\renewcommand{\ref}[1]{\unskip~\originalref{#1}}</raw>

      <raw>\let\originalnameref\nameref</raw>
      <raw>\renewcommand{\nameref}[1]{\unskip~\originalnameref{#1}}</raw>
    </region>
  </preamble>
  <document>
    <region name="Title page">
      <command name="title" param="Stateless Programming And Testing: \\ Extracting a functional layer from object-oriented code" />
      <command name="author" param="Olivier Dagenais" />
      <command name="submitdate" param="July 29, 2011" />
      <command name="copyrightyear" param="2011" />
      <command name="degree" param="Master of Computer Science" />
    </region>

    <command name="frontmatter">
      <region name="[List of] Listings">
        <command name="addcontentsline" param="toc}{chapter}{Listings" />
        <command name="lstlistoflistings" />
        <command name="clearpage" />
      </region>
      <block param="abstract">
        <!-- An abstract is required in all theses. -->
        <!-- Make sure that it fits on one page! -->
      </block>
      <block param="acknowledgements">
        <!-- This is the acknowledgements. -->
        <!-- It is optional. -->
      </block>
    </command>
    <command name="mainmatter">
      <command name="chapter" param="Introduction">
        <command name="section" param="Introduction">
          This chapter introduces the problem and the motivation for solving it, as well as the overall goal and specific objectives.  It concludes with an overview of the rest of the document.
        </command>
        <command name="section" param="Problem">
          Software has advanced considerably in the last several years, but has software quality kept up?  We do not always know how good a program or component is or if it is free of defects, if only those defects that will affect us, directly or otherwise.  Software defects can range from the benign, such as incorrect colors and typographical errors in the interface or output, to very serious, such as causing the destruction of a rocket carrying four satellites <command name="cite" param="lions96ariane" /> <command name="cite" param="esa05clustermission" /> or causing the death of several patients <command name="cite" param="leveson95medicaldevices" />.

          Programming languages and compilers evolved to add features that make it easier to write code, although those features do not always make it easier to test the same code.  Object-oriented programming (OOP), for example, has introduced constructs and paradigms designed to make abstraction, inheritance and polymorphism easier, but at the same time introduced a feature that can make testing more difficult:  encapsulation (information hiding) in the form of instance state.  Encapsulation allows an object to hide its implementation details so as to present a simpler interface to callers.  Indeed, Alan Kay describes this simpler, higher-level interaction between objects as "goals", replacing low-level assignments: "Again, the whole point of OOP is <command name="underline" param="not" /> to have to worry about what is <em>inside</em> an object." <command name="cite" param="kay93earlyhistory" />

          Hidden and mutable instance state poses a problem for automated unit testing because that instance state may come into play when exercising a specific scenario <command name="cite" param="binder00testharness" />.  Since the instance state is mutable, the values may not be initialized at instance construction or can change as instance methods are called.  Since the instance state is hidden, there exists, by definition, no way to manipulate this instance state directly.  Separately, hidden (but immutable) instance state or mutable (but visible) instance state do not provide too many difficulties for test writing.  It is the combination of the hidden and mutable properties that make it difficult to write tests.

          <command name="subsection" param="Hidden mutable state, described">
            Hidden mutable state (HMS) manifests itself in a few different forms:
            <block param="itemize">
              <command name="item"> Instance state that cannot be set from the constructor or a factory method.</command>
              <command name="item"> Instance state that cannot be directly set from a setter method or property.</command>
              <command name="item"> A constructor or direct factory method is not available.  For example, an instance can only be created as a by-product of a method call on another class.</command>
              <command name="item"> Instance state points to objects with their own hidden mutable state.</command>
            </block>
            In summary, a class with hidden mutable state has variables or fields that must be set or modified indirectly as a result of calling a method that, although not necessarily directly related, nonetheless modifies one or more variables or fields.
          </command>

          The result of hidden mutable state is we end up with difficult-to-test code, which means it stays untested, even despite the many automated test frameworks and systems available <command name="cite" param="aberdour07dotnetunit" />.  This is likely due to a trade-off between ease of maintenance and testability where testability was ultimately not favoured.

          We still want to test the code, but we must first surmount the difficult-to-test obstacle that hidden mutable state introduces:
          <block param="quote">
            "It is often difficult to control the pretest state of the IUT.  The instance variables of the IUT are encapsulated and often composed of still more uncontrollable objects.  The interface of the IUT is typically insufficient for testing purposes. (...) Although existing IUT methods can be used to control state, they often do not provide all access needed and can produce spurious test results if they are buggy.  They maybe not even exist, if their development has been deferred to a later increment or they are part of an abstract class. (...) Observing the post-test state of the IUT is often difficult, for the same reasons that controlling the pretest state is difficult." <command name="cite" param="binder00testharness" />
          </block>

          In the process of testing a method that uses hidden instance state (as input, output or both), it usually becomes necessary to write the unit test such that it will indirectly orchestrate said instance state so that specific scenarios can be implemented.  This makes the test method difficult to maintain because the test will be more unwieldy and less obvious - especially in the "arrange" phase - which may have the effect of discouraging the creation of such tests.

          An example of the state problem can be seen in listings <command name="ref" param="lst:StatefulSmokeDetector" /> and <command name="ref" param="lst:StatefulSmokeDetectorTest" />.  Notice how having all the instance fields private makes it so any test wishing to bring the object to a certain state (such as "alarm sounds while detection decays") has to repeatedly call the <tt>Cycle()</tt> method with various values provided to the <tt>level</tt> parameter?  By the same token, the only observable state for verification is the return value of the method, although, in this particular instance, this should be sufficient for most test scenarios.
        </command>
        <command name="section" param="Motivation">
          <!-- TODO:
          = should I motivate [unit] testing more, like I did in my paper?
          = how about talking about the applicability to code that is currently without tests or with insufficient tests
          -->
          Lest we could somehow perform the practically impossible "complete testing" (in other words, exhaustively trying all possible inputs), testing can only show the presence of defects and not their absence <command name="cite" param="dijkstra69structuredprogramming" />.  A good set of automated tests, on the other hand, can catch software regressions that may be introduced through the addition of a feature or the removal of a defect.  Finding (and fixing) regressions as early as possible ensures their fixing cost is minimized <command name="cite" param="spolsky00joeltest" />.  A good set of automated tests is henceforth defined as one that can catch such software regressions.

          <!-- TODO: should the listings use a figure with subfloats, instead? -->
          <region name="table and two stateful code listings">
            <raw>\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}</raw>
            <command name="lstinputlisting"
              opt="label=lst:StatefulSmokeDetector,caption=SmokeDetector class with hidden mutable state,style=realCode"
              param="Stateful/SmokeDetector.cs" />
            <raw>&amp;</raw>
            <command name="lstinputlisting"
              opt="label=lst:StatefulSmokeDetectorTest,caption=Test class for the SmokeDetector,style=realCode"
              param="Stateful/SmokeDetectorTest.cs" />
            <raw>\end{tabular}</raw>
          </region>

          A metric commonly used to represent confidence in a set of automated tests is code coverage percentage, usually in the form of statement coverage <command name="cite" param="sink06advocatingcoverage" />.  Code that is covered might be - but is not necessarily - tested, but uncovered code is definitely untested code <command name="cite" param="binder00classes" />.  Shipping software with untested code is like serving a dish that has not yet been tasted.

          HMS does not just present trouble to tests written by programmers - henceforth referred to as human-generated tests (HGT) - but also to computer-generated tests (CGT), such as those generated through Evolutionary Testing (ET), a form of Search Based Software Testing.  <!-- TODO: does Concolic Testing also suffer from the state problem? -->  Indeed, McMinn reported on the difficulty HMS brought to ET:
          <block param="quote">
            "States can cause a variety of problems for ET, since test goals involving states can be dependent on the entire history of input to the test object, as well as just the current input." <command name="cite" param="mcminn03thestate" />
          </block>

          Although it is possible to work around some HMS with a noteworthy "arrange" phase, this is not always desirable as it can increase the maintenance overhead and costs to write the unit tests, both for human- and computer-generated tests.  There are other obvious options available, such as increasing the visibility of the mutable state or converting the state from mutable to read-only, but both these options would likely change the public interface of the class under test to an unacceptable level (such as breaking encapsulation), not to mention the associated risk in performing non-trivial modifications (in the latter case) without the safety net of sufficient tests.

          One perhaps less obvious option is the extraction of a subset of the state<em>ful</em> functionality in the form of a state<em>less</em> method which has all its inputs and outputs available to the test driver, while sourcing those inputs and outputs from and to the very instance fields they represent within the implementation itself.  An example of this can be seen in listings <command name="ref" param="lst:StatelessSmokeDetector" /> and <command name="ref" param="lst:StatelessSmokeDetectorTest" />.  Notice how the original implementation of the <tt>Cycle()</tt> method has been trivially extracted into a static overload that accepts all its input and emits all its output through parameters and the method return value?  The <tt>AccumulateDetection()</tt> test method can then be written to supply values for all parameters, while keeping the fields that the parameters would be initialized from safe from modification.  Indeed, the previous test is still there, unchanged, since the <tt>SmokeDetector</tt>'s public interface did not change as a result of performing this transformation.

          <!-- TODO: should the listings use a figure with subfloats, instead? -->
          <region name="table and two stateless code listings">
            <raw>\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}</raw>
            <command name="lstinputlisting"
              opt="label=lst:StatelessSmokeDetector,caption=SmokeDetector class with a stateless method extracted,style=realCode"
              param="Stateless/SmokeDetector.cs" />
            <raw>&amp;</raw>
            <command name="lstinputlisting"
              opt="label=lst:StatelessSmokeDetectorTest,caption=Test class for SmokeDetector exploiting the new Cycle() method overload,style=realCode"
              param="Stateless/SmokeDetectorTest.cs" />
            <raw>\end{tabular}</raw>
          </region>
        </command>
        <command name="section" param="Goal">
          <!-- Can address only part of the problem
          Something abstract/general, such as "world hunger", or a subset of it "hunger in Ottawa"
          Can be written retroactively, after the results have been written -->
          If we are to defeat the difficulties of HMS, can we do so with minimal changes to the public interface and with minimal risk of introducing regressions?  Can the unit tests be kept parsimonious, yet cover all the important edge cases?  Is there something we can do to make code containing hidden mutable state more easily testable?

          The goal of this thesis is to improve the testability of classes that suffer from the "state problem" -- because they contain HMS -- while minimally affecting functionality, maintainability and the public interface of the code under test.  The goal is to be validated according to the following metrics:

          <block param="enumerate">
            <command name="item"> Cyclomatic complexity <command name="cite" param="mccabe76complexitymeasure" /> of the unit tests.</command>
            <command name="item"> Number of changes to class under test's public interface.</command>
            <command name="item"> Percentage of branches covered using concolic testing <command name="cite" param="lakhotia10empiricalinvestigation" />.
            <!-- TODO: can maintainability be measured? -->
            <!-- TODO:
            = can I measure the risk of introducing defects or regressions?
            = in other words, what is the safety of the testability transformation/refactoring?
            -->
            </command>
          </block>
          <!--
          = even though I mention ET in the motivation section, I have no goal to evaluate anything for ET???
          = is there a mention of instance state (i.e. HMS) being a problem for Pex or concolic testing in general?
          == my experiments with Pex were designed to have it be the objective evaluator, such that if Pex is unable to create an instance of a class, it is unlikely a human will have an easy time.  This is mostly for the case where a class has no constructor and no easy factory method.
          == Pex is documented as handling ALL state with the help of a shadow interpreter
          == "But then Pex may not know how to create an object through the publicly available constructors such that the object's private fields are in the desired state." (Pex)
          == "If the class is visible and has a visible default constructor, Pex can create an instance of the class. If all the fields are visible, it can generate values for them as well. However, if the fields are encapsulated with properties or not exposed to the outside world, Pex requires help to create the object so as to achieve a better code coverage." http://msdn.microsoft.com/en-us/magazine/ee819140.aspx
          ==
          """
          Warning: field xxx is not public; Pex needs help to construct object (or similar)

Pex generates test inputs, and part of the inputs may be objects with fields. Here, Pex wants to generate an instance of an object which has a private field, and Pex believes that an interesting program behavior will occur when this private field has a particular value. However, while possible with Reflection, Pex does not dare to manufacture objects with arbitrary field values. Instead, in those cases it relies on the user to provide hints how to use the public methods of a class to create an object and bring it into a state where its private field has the desired value.
          """
http://research.microsoft.com/en-us/um/redmond/projects/pex/wiki/pex%20needs%20help%20to%20construct%20object.html
          === I should be able to find instances where Pex can not
          -->
        </command>
        <command name="section" param="Objectives">
          <!-- (what you will produce to meet your goal)
          action items to address goal -->
          To meet the goal, a testability refactoring <command name="cite" param="harman11refactoringtestability" /> algorithm called "stateless method extraction" (SME) is proposed and explained/detailed.  The SME algorithm transforms the source code of the implementation under test (IUT) to introduce a functional or "externally state-free" software layer to specifically work around many of the testability problems of HMS and to generally increase the testability of the code under test.  The SME algorithm's efficiency and effectiveness will be evaluated by comparing the results of the algorithm's application to other testing approaches.
        </command>
        <command name="section" param="Outline">
          ...
          The <!-- ref: Approach --> chapter covers the details, the how-tos and applicability of the proposed testability refactoring.
        </command>
        <command name="section" param="Summary">
          <!-- key points of what was presented and linkage to next chapter -->
          ...
        </command>
      </command>
      <command name="chapter" param="Background">
        <command name="section" param="Introduction">
          This chapter presents an overview of the related concepts from object-oriented programming to automated testing to computer-generated tests, introduces related work, establishes context within that work and lastly defines the scope of the thesis.
        </command>
        <command name="section" param="Object oriented programming">
          This thesis focuses on testing programs written with object-oriented (OO) languages, as opposed to procedural or functional languages because the intent is to solve a problem specific to OO languages:  hidden mutable state.  Although procedural languages (such as C) allow programs to have mutable state, the state is not hidden.  Functional languages (such as Lisp) on the other hand, allow programs to be written using immutable state through the use of set-once variables.

          <command name="subsection" param="Terminology">
            OO languages will generally have a basic set of features, the most important of which are described here for clarity.
            <block param="description">
              <command name="item" opt="class"> The definition for an object.</command>
              <command name="item" opt="instance"> A run-time manifestation of a class, each of which have their own scope.</command>
              <command name="item" opt="static"> A scope for the definition of a class.</command>
              <command name="item" opt="field"> A variable associated with a class (static field) or with an instance (instance field).</command>
              <command name="item" opt="method"> A set of operations attached to a class (static method) or to an instance (instance method).</command>
              <command name="item" opt="constructor"> A special method that is called when an instance of a class is created.</command>
              <command name="item" opt="factory method"> A method whose purpose is to create instances of a class, but not necessarily of the class on which it is found.</command>
              <command name="item" opt="overload"> Two (or more) methods that have the same name but different parameter numbers and/or types are said to be <em>overloads</em> of the same method.</command>
              <command name="item" opt="interface"> A contract (usually in the form of a list of methods) for classes to implement to enable their instances to be interchangeable with other implementations of the interface.</command>
              <command name="item" opt="property"> A method whose purpose is to allow the reading or reading and writing of a field's value.  Some languages support this directly while others offer a convention of "getter" and "setter" methods, instead.</command>
              <!-- TODO: encapsulation? -->
            </block>
          </command>
        </command>
        <command name="section" param="Automated testing">
          A proper introduction to automated testing, especially as it pertains to object-oriented programs would fill a book and indeed it has.  The reader is encouraged to consult <em>Testing Object-Oriented Systems</em> by Robert V. Binder <command name="cite" param="binder00testharness" /> for details beyond this chapter's overview.

          Generally, a test is said to be automated if there exists a program that can start the implementation under test (IUT) or a subset thereof, initialize some suitable inputs for the scenario to be verified, provide these inputs to the IUT and then verify the resulting output, without any intervening assistance.
          <command name="subsection" param="Testing frameworks">
            Automated testing frameworks provide developers the ability to write and organize test scenarios, execute them sequentially and independently from one another and finally report on their successes.

            This thesis focuses on testing frameworks <command name="cite" param="beck99simplesmalltalk" /> that allow the test development environment to be identical to the implementation development environment, collectively called XUnit <command name="cite" param="fowler06xunit" />.  A single test scenario can be implemented as a <em>test method</em> in a <em>test class</em>, exercising functionality in the method under test (MUT) in another class; the class under test (CUT).  A collection of test classes is known as a <em>test suite</em>.

            Test methods will generally have three phases - arrange, act and assert - although the functionality is not always separated as such and might be intermixed or even be located elsewhere in the test class.  The <em>arrange</em> phase concerns itself with preparing the CUT and/or the environment, effectively setting the indirect inputs for the MUT and optionally initializing complex direct inputs.  The <em>act</em> phase contains code that calls the MUT with its direct inputs and collects the direct outputs, if any.  The <em>assert</em> phase derives any indirect outputs, if any, and verifies the <em>actual</em> outputs against the <em>expected</em> outputs, cleaning up the environment afterward, as necessary.

            The terms <em>test inputs</em> and <em>test outputs</em> will henceforth be used to refer to both their direct and indirect sets.  It is worth noting that because exhaustive testing is infeasible, test suites will usually contain scenarios that sample only a fraction of the possible input space.  In those cases, the test inputs will have been selected to represent typical use, boundary conditions and other potential areas for defects.  Such classes of values for the test inputs earns them the "interesting and relevant" designation.
          </command>
          <command name="subsection" param="Test scope">
            As alluded to in the previous sub-section, this thesis concerns itself with automated testing at the lowest level by focusing the test scenarios on methods, which is also known as <em>unit testing</em>.  This is in contrast to <em>integration testing</em> which concerns itself with the interaction between a class and another class and/or some external environment such as a file system or a network, and <em>subsystem testing</em> which involves observing the interaction between a class and several other classes and/or external components such as a database or a web service.
          </command>
          <command name="subsection" param="Code coverage">
            An IUT can be automatically <em>instrumented</em> to record which statements and expressions are executed during an automated test run.  The resulting report is known as <em>statement coverage</em> and will usually correlate its results with the original source code by highlighting the statements and expressions that were executed  <command name="cite" param="binder00classes" />.  This report will also include enough data to determine the coverage percentage - which is computed as the number of statements executed divided by the total number of statements - at the method, class, namespace and program levels <command name="cite" param="sink06advocatingcoverage" />.

            Code coverage can be used to determine the completeness of the test suite or, more precisely, to identify areas of the IUT that are untouched by the tests.  The presence of uncovered code can also reveal surprises in the implementation although its best use remains the identification of missing test scenarios.
          </command>
        </command>
        <command name="section" param="Motivation for Computer-Generated Tests">
          It may not always be possible or feasible to have a programmer write automated tests for a component or an implementation.  Reasons provided by Bühler and Wegener <command name="cite" param="buehler08evolutionaryfunctional" /> include the simultaneous satisfaction of functional, real-time and safety requirements as well as the very large test space resulting from the interaction of 50-70 independently-developed embedded systems.  The nature of the assembled system - in this case a premium vehicle - also makes manual testing, such as driving the vehicle in an environment suitable for each scenario, prohibitively expensive.  Bühler and Wegener go on to suggest generating tests automatically to work around these obstacles and thus reduce costs.  Evolutionary testing (ET), "the application of evolutionary computation to test automation" <command name="cite" param="buehler08evolutionaryfunctional" />, is therefore suggested to automatically and efficiently sample the test input space.  ET will usually be implemented using genetic algorithms (GA), which are well-suited to a mix of exploration and exploitation in the search space <command name="cite" param="mcminn04searchbased" />.

          Binder writes:
          <block param="quote">
            "Automatic test generation can be used without having to pregenerate expected results.  Although generating input values automatically is easy, generating the corresponding expected results automatically is usually difficult." <command name="cite" param="binder00assertions" />
          </block>
          Even if tests are automatically generated without the use of an oracle (human or otherwise), the generated test suite can still serve as a baseline and could be used to detect changes in the outputs as a result of adding features or fixing defects.  These changes in the outputs could indicate a regression, just as changes in the outputs of human-generated tests would.

          In the present case, there's an additional reason computer-generated tests are interesting:  we can use an automatic structural test generator to objectively compare the testability of source code under various transformations.

          More details about the various flavours and uses of computer-generated tests are provided in the following sections.
        </command>
        <command name="section" param="Approaches to Computer-Generated Tests">
          There are three major approaches in generating tests <command name="cite" param="lakhotia10empiricalinvestigation" />.
          <command name="subsection" param="Random Testing">
            Random testing (RT), as the name implies, consists of generating inputs based on random numbers and is thus undirected.  RT does not perform as well as ET <command name="cite" param="wegener01evolutionarytest" />, although it has been used as a baseline for comparing other test generators <command name="cite" param="lakhotia10empiricalinvestigation" />.
          </command>
          <command name="subsection" param="Search Based Software Testing">
            Search-based software testing (SBST) is the application of a metaheuristic search technique (MST) to the problem of generating test inputs <command name="cite" param="mcminn04searchbased" />.  The technique is based around optimization of an <em>objective function</em>, trying to improve an initial solution based on feedback by said objective function - either by maximizing or minimizing its value, depending on the desired outcome - effectively making it a guided quest for global optima in the search space.

            For test input generation, the search space is the domain of the test inputs and the objective function is carefully constructed to reward interesting and relevant test inputs.  The nature of "interesting and relevant" depends on the <em>intent</em> of the testing exercise.  Consult the following section for the major intents, but suffice it to say that the biggest difficulty of SBST lies in the definition of the objective function <command name="cite" param="baresel02fitnessfunction" />.

            The general flow of MST implementations is to start with one or more "initial solutions", created either with domain knowledge or at random, and apply the objective function on the solution(s) to establish a solution score.  If no solution score exceeded a pre-defined threshold, tweak the solution(s) according to some heuristic and repeat the process with the new solution(s) until either no improvement in score is detected or some pre-defined time or iteration threshold is reached.

            The simplest heuristic is called "hill climbing" and is a strategy that focuses on the best objective function value in the neighborhood of the current solution's search space.  This greedy exploit-only strategy will often cause a hill climber to get stuck in local optima.

            An improvement to hill climbing was proposed in the "simulated annealing" heuristic whereby solutions with worse objective function values will be considered with a probability decreasing with the number of iterations, allowing more of the search space to be explored in the beginning and ending with a hill climber-like exploitation.

            One of the better MST heuristics is "genetic algorithms (GA)", a class of "evolutionary algorithms".  It is designed to simulate the process of natural selection (sometimes known as "survival of the fittest") through modeling a <em>population</em> of solutions as chromosomes and providing ways for pairs of solutions to "breed" through recombination (splicing part of one parent with part of the other and also combining the remaining two parts), providing the next generation of solutions.  The simulation is made more authentic through the use of mutations (random, low-probability alterations to the chromosome) and various reproduction selection mechanisms, such as fitness-proportional selection and tournament selection.  Through this simulation, solutions will appear to evolve across the generations and, given appropriately-tuned parameters, the population of solutions will be diverse and "fit", thus providing a good balance of exploration and exploitation of the search space.
          </command>
          <command name="subsection" param="Concolic Testing">
            Concolic testing (CT) is the combination of <em>conc</em>rete and symb<em>olic</em> execution applied to the problem of test data generation and is also known as dynamic symbolic execution <command name="cite" param="mcminn04searchbased" />.

            Symbolic execution (SE) is a simulated execution of a given path through the program using symbols in place of input values and keeping track of expressions instead of concrete values as assignments and operations take place <command name="cite" param="king76symbolicexecution" />.  For a program operating exclusively with integers, one could say SE is the algebraic equivalent of the arithmetic operations that would be evaluated with concrete execution.  The resulting output of SE is generally a system of constraints on the inputs for executing the given path.

            Concrete execution - running an instrumented version of the program - can be combined with SE such that the two executions are correlated to verify the generated constraints against concrete values.  Often times, this correlation allows the simplification of these constraints, for example by removing non-linear sub-expressions <command name="cite" param="mcminn04searchbased" />.  A constraint solver can then be used to find test input values that cause the execution of specific paths through the IUT <command name="cite" param="tillman08pex" />.
          </command>
        </command>
        <command name="section" param="Intents of Computer-Generated Tests">
          There are four major uses for Computer-Generated Tests (CGT).  They differ mostly in the choice of executable statement(s) to target and are not usually specific to any approach in particular.  The exception is non-functional testing, which does not target any executable statement in particular and is more suited to an optimization approach (such as SBST).
          <command name="subsection" param="Structural Testing">
            Coupling an automated test generator with a code coverage tool makes it possible to not only discover which inputs can be used to reach otherwise hard-to-cover areas but also to discover areas of the code where no inputs can be found to reach them (within a pre-defined search time).  This could indicate the code is unreachable because it contains, for example, conflicting pre-conditions.  Structural testing will generally attempt to execute all statements of an IUT at least once.
          </command>
          <command name="subsection" param="Functional Testing">
            Functional testing is a form of verification that uses a machine-readable form of the specification <command name="cite" param="mcminn04searchbased" />.  One way of doing so is with a formal specification expressed as disjunctions that represent <em>routes</em> (or paths) through the program.  These routes can then be tested individually using structural testing.

            An easier approach is to automatically turn the specification into pre-conditions and post-conditions.  The objective is then to find test inputs that conform to all pre-conditions but that cause post-conditions to fail, in effect targeting the fault branch of the post-conditions.

            A third approach is to encode the specification's requirements as a component of a simulator.  For example, Bühler and Wegener evaluated the functionality of a brake assist system using a simulator to find instances where the system either did not enhance the driver's brake torque in a critical situation or provided too much braking in a non-critical situation <command name="cite" param="buehler08evolutionaryfunctional" />.
          </command>
          <command name="subsection" param="Grey-Box Testing">
            The objectives of grey-box testing are to attempt to get assertions already embedded in a program to be violated and to trigger exception conditions.  Some of the work even temporarily turned specially-formatted comments into executable assertions for the purposes of targeting their fault branches for execution <command name="cite" param="mcminn04searchbased" />.
          </command>
          <command name="subsection" param="Non-Functional Testing">
            Non-functional testing concerns itself with verifying non-functional requirements, such as constraints on execution time, working memory, long-term storage and processor load, usually for embedded and real-time systems.  Test inputs are sought which cause the program to, for example, take longer than usual or consume more memory than expected, according to instrumentation external to the IUT such as the operating system's timers and counters, or the use of a simulator <command name="cite" param="sthamer02usingevolutionary" />.
          </command>
        </command>
        <command name="section" param="Related work">
          <command name="subsection" param="The state problem">
            <block param="quote">
              "Side-effects, by which I mean changes to the values stored in fields of objects or elements of arrays, are clearly intended to be used frequently in Java. However, the presence of side-effects can make it harder to reason about a program, because there is invisble [sic] state to the side of computations which changes. That means a reader needs to keep track of both the visible aspects of a program and the hidden values off to the side that may change." <command name="cite" param="haahr99programmingstyle" />
            </block>
            McMinn identified the "State Problem" in the context of evolutionary testing and described a few possible solutions that enhanced the ET system to compensate for problems brought on by state <command name="cite" param="mcminn03thestate" />.  Difficulties with internal state are also mentioned by Bühler and Wegener <command name="cite" param="buehler08evolutionaryfunctional" />, Harman et al. <command name="cite" param="harman09aop" />, Tillman and de Halleux <command name="cite" param="tillman08pex" /> and Baresel et al. <command name="cite" param="baresel02fitnessfunction" />.

            Difficulties associated with internal state can be reduced or worked around with better analysis, such as data dependency analysis <command name="cite" param="korel05datadependence" />.  Since said analysis can often be time-consuming, techniques, such as program slicing <command name="cite" param="tip95surveyslicing" /> were developed to help reduce the search space.  McMinn went on to develop a technique that enhances the search to look for method call sequences along with combining the chaining approach with evolutionary search <command name="cite" param="mcminn05evolutionarysearch" />.

            Another approach to generate tests for programs with state - specifically those written in object-oriented programming languages - was proposed by Wappler and Wegener <command name="cite" param="wappler06evolutionaryunit" />.  Their two-phase technique is called "strongly-typed genetic programming" and consists of first using genetic programming to generate a sequence of methods to call (creating instances of classes as necessary), then using a genetic algorithm to find suitable values for the parameters of the generated method calls.
            <!-- TODO: discuss Microsoft's PrivateObject -->
          </command>
          <command name="subsection" param="The case for functional programming">
            <block param="quote">
             "However, the functional style is also perfectly adapted to incremental testing:  programs written in this style can also be <em>tested</em> one function at a time.  When a function neither examines nor alters external state, any bugs will appear immediately. Such a function can affect the outside world only through its return values. Insofar as these are what you expected, you can trust the code which produced them." <command name="cite" param="graham93onlisp" />
            </block>
            "Imperative functional programming" is argued by Reddy <command name="cite" param="reddy96imperativefunctional" /> and appears to push the idea of a <em>public</em> functional programming interface built on top of imperative features, whereas the present thesis would see an <em>internal</em> functional programming interface (built on top of imperative features) as a building block for a possibly pre-existing object-oriented interface.

            Hevery, on the other hand, appears to disagree with the proposed approach <command name="cite" param="hevery08staticmethods" /> and argues for a pure object-oriented approach <command name="cite" param="hevery09thinkoo" />.  Haahr nevertheless argues for "referential transparency" <command name="cite" param="haahr99programmingstyle" /> to not only make computations easier to understand but also easier to parallelize.
          </command>
          <command name="subsection" param="The case for testability transformations">
            <block param="quote">
              "It could be said that the algorithm for side-effect removal creates an `almost functional' language, in which all state changes are expressed using the assignment statement. This would return the programming paradigm to that considered by the initial work on the Axiomatic Method, where axiomatic semantics is comparatively elegant and easy to define and use. This, perhaps, provides further additional anecdotal evidence that side-effects are hard to reason about and that their removal is worthwhile for comprehension." <command name="cite" param="harman01sideeffect" />
            </block>
            Because programs are not always easily testable as written, it has been suggested by Harman et al. to automatically create an alternate (and temporary) version of the program that is easier to analyze or test by applying some transformations <command name="cite" param="harman04testabilitytransformation" />, which can be as simple as "flag removal"; the inline expansion of a boolean variable with its underlying expression <command name="cite" param="harman02improvingevolutionary" />.  Another example would be the removal of expressions with side-effects <command name="cite" param="harman01sideeffect" />.

            The general idea of testability transformation was further developed by Korel et al. <command name="cite" param="korel05datadependence" /> as well as McMinn et al. <command name="cite" param="mcminn08empiricalevaluation" />, among others.  Program slicing could also be considered a testability transformation <command name="cite" param="harman09aop" />.  Harman eventually goes one step further and suggests "testability refactoring": a permanent program transformation that has the simultaneous goals of making the program easier to test and better (or at least no worse) for the programmer <command name="cite" param="harman11refactoringtestability" />.
          </command>
          <command name="subsection" param="The case for simplicity">
            <block param="quote">
              "A low cyclomatic complexity generally indicates a method that is easy to understand, test, and maintain." <command name="cite" param="msdn10avoidcomplexity" />
            </block>
            McCabe introduced the concept of "cyclomatic complexity" with the intention of evaluating the difficulty involved when testing programs based on their structure <command name="cite" param="mccabe76complexitymeasure" />.  Indeed, McCabe even discussed the possibility of reducing a program's structure to reduce the testing effort, in an effort to make software that is both testable and maintainable.

            Hevery created the Testability Explorer tool to compute the "Non-Mockable Total Recursive Cyclomatic Complexity" metric, compute the "Demeter" metric as well as count the number of global mutable fields in Java programs <command name="cite" param="hevery08testabilityexplorer" />.  The first metric is an evolution of McCabe's metric for object-oriented programs while the other two also help reduce testing effort through smaller call chains (Demeter) and less "spooky action at a distance" (surprise side-effects) by reducing the use of mutable global fields <command name="cite" param="hevery08flawbrittle" />.
          </command>
        </command>
        <command name="section" param="Scope">
          The present thesis focuses on addressing the glass-box unit testing difficulties introduced by hidden mutable state, in the context of object-oriented software, through the use of stateless method extraction.  In other words, the implementation under test is available for inspection as tests are written on a per-method basis for classes that contain private instance fields whose values are altered by calls to instance methods.

          Considerations outside the scope of this thesis therefore include:
          <block param="itemize">
            <command name="item"> Opaque-box testing</command>
            <command name="item"> Integration (or other high-level) testing</command>
            <command name="item"> Non-object-oriented software</command>
          </block>

          Additional considerations outside the scope of this thesis include:
          <block param="itemize">
            <command name="item"> Testing of hidden state mutations.  These must still be tested, but those tests are not covered by this thesis.</command>
            <command name="item"> Run-time performance of IUT or unit tests</command>
            <command name="item"> Performance of SBST (such as ET) on IUT</command>
            <!-- Is the last one really reasonable since the basis of this thesis was the ET-related "state problem"?  Shouldn't I be able to show some progress on that front? -->
          </block>

          Stateless method extraction is to be compared against other approaches for unit testing object-oriented software containing hidden mutable state;  see table <command name="ref" param="tbl:ScopeTable" />.

          <block param="table" opt="htbp">
            <raw>\begin{tabular}{l >{\centering}m{2cm} >{\centering}m{2cm} >{\centering}m{2cm} >{\centering}m{2cm} }</raw>
              <raw>&amp; \multicolumn{4}{c}{Features}\tabularnewline</raw>
              <raw>\multicolumn{1}{c}{Approach}</raw> <raw>&amp;</raw> Transforms IUT <raw>&amp;</raw> Transforms tests <raw>&amp;</raw> Affects public interface <raw>&amp;</raw> Requires tool <raw>\tabularnewline</raw>
              <command name="hline" />
              Stateless method extraction <raw>&amp;</raw> Y <raw>&amp;</raw> N <raw>&amp;</raw> N <raw>&amp;</raw> N <raw>\tabularnewline</raw>
              Isolated test methods <raw>&amp;</raw> N <raw>&amp;</raw> N <raw>&amp;</raw> N <raw>&amp;</raw> N <raw>\tabularnewline</raw>
              Test helper methods <raw>&amp;</raw> N <raw>&amp;</raw> Y <raw>&amp;</raw> N <raw>&amp;</raw> N <raw>\tabularnewline</raw>
              Reflection-based helpers <raw>&amp;</raw> N <raw>&amp;</raw> Y <raw>&amp;</raw> N <raw>&amp;</raw> Y <raw>\tabularnewline</raw>
              Making mutable state visible <raw>&amp;</raw> Y <raw>&amp;</raw> N <raw>&amp;</raw> Y <raw>&amp;</raw> N <raw>\tabularnewline</raw>
              Making hidden state mutable <raw>&amp;</raw> Y <raw>&amp;</raw> N <raw>&amp;</raw> Y <raw>&amp;</raw> N <raw>\tabularnewline</raw>
            <raw>\end{tabular}</raw>
            <command name="caption" param="Approach vs. Features" />
            <command name="label" param="tbl:ScopeTable" />
          </block>
          <!--
          = contrast with isolated, stand-alone tests
          = contrast with test helper methods
          == For example, DeepZoomImageTest.TestComputeLevelSize() that creates two instances per call:
          Assert.AreEqual (new Size (1200, 1500), TestComputeLevelSize (PortraitImageSize, 12));
          vs. the original stateless method that could be called directly:
          Assert.AreEqual (new Size (1200, 1500), DeepZoomImage.ComputeLevelSize (PortraitImageSize, 12));
          === For that particular one, because my settings class performs work in the constructor, there are some properties which MUST be provided.
          == how about test helper properties?
          == they shift complexity instead of removing it altogether.  I need to find some way to prove that this leads to more brittle tests.  Perhaps the fact that the stateless method is reusable vs. the test helper method is not?
          = constrast with factory methods:
          """
          As an alternative to employing only existing constructors to configure objects,
the user may also provide factory methods, which could invoke a sequence of
method calls to construct and configure a new object, possibly creating cyclic
references as well.
          """ Pex, last paragraph of section 3.4
          = contrast with visible, mutable state
          == changes current public interface
          = contrast with hidden, immutable state
          == changes current public interface
          -->
        </command>
        <command name="section" param="Summary">
          <!-- key points of what was presented and linkage to next chapter -->
          ...
        </command>
      </command>
      <command name="chapter" param="Approach">
        <command name="section" param="Introduction">
          <!-- what the chapter is about -->
          ...
        </command>
        <command name="section" param="Design">
          Stateless method extraction's intent is to separate the interaction between the hidden mutable state in a class and the inputs and outputs of said class' instance methods.  This decoupling allows programmers to first focus their unit tests on the pure computation aspects, then on the object-oriented layer above the stateless methods.

          <command name="subsection" param="Overview">
            Stateless method extraction is performed in six high-level steps:
            <block param="enumerate">
              <command name="item"> Identification of a candidate block.
                <br />
                A "candidate block" is a functionality subset of an instance method that looks promising to turn into a stateless method.
              </command>
              <command name="item"> Re-ordering of incidental operations.
                <br />
                On some occasions, it may be necessary to move some statements whose ordering isn't critical (such as logging) out of the candidate block.
              </command>
              <command name="item"> Assignment of inputs and outputs to local variables.
                <br />
                Identify the new method's input and output parameters then create local variables for them.  This will facilitate the method extraction and provides useful names for the parameters of the to-be-extracted method.
              </command>
              <command name="item"> Simplification of inputs.
                <br />
                Optimize the input parameters to be native or built-in types.
              </command>
              <command name="item"> Extraction of the candidate block into a method.
                <br />
                The candidate block should now be easily converted into a stateless method.
              </command>
              <command name="item"> Re-inline any variables created to facilitate a refactor.
                <br />
                This reverses the actions of step #3 so the refactor has as little impact on the original code as possible and only contains the necessary changes.
              </command>
            </block>
            Refer to listing <command name="ref" param="lst:Procedure" /> for a pseudo-code version of the stateless method extraction procedure.  The following sub-sections will cover the individual steps in greater detail.
            <!-- TODO: should this be an "algorithmic" block, instead? -->
            <command name="lstinputlisting"
              opt="label=lst:Procedure,caption=General procedure for extracting stateless methods,style=pseudoCode"
              param="Procedure.pc" />
          </command>

          <command name="subsection" param="Step 1: Identification of a candidate block">
            The first step of SME consists of identifying, in an instance method, one or more functionality subsets that would be good candidates for extraction and subsequent unit testing.  That is to say it is not necessary to extract the entire body of an instance method if there are parts of the original method that would be more suitable to extract and unit test individually and separately.

            The criteria for establishing candidacy of a block consist of:
            <block param="enumerate">
              <command name="item"> A continuous set of statements.</command>
              <command name="item"> Inputs (local variables, fields and/or method parameters): at least 1 but no more than 6.</command>
              <command name="item"> Outputs (local variables, fields and/or return values): at least 1 but no more than 3.
                <br />
                At least one non-trivial result must be produced by processing the input(s).
              </command>
              <command name="item"> Contains no calls to instance methods on self.
                <br />
                If the instance method calls are not sensitive to ordering, it may be possible to move them out of the candidate block, otherwise it may be useful to create two candidate blocks, one on either side of the instance method call.
              </command>
            </block>
            Categories of interesting candidate blocks include:
            <block param="itemize">
              <command name="item"> Implementations of mathematical formulas.
                For example, converting from degrees to radians or computing the great circle distance (the shortest path between two points on a sphere), both of which are shown being performed inline in listing <command name="ref" param="lst:StatefulComputeTourLength" />.
              </command>
              <command name="item"> Processing of a single element where such processing currently takes place while looping through a sequence of elements.
                For a before-after example, refer to listings <command name="ref" param="lst:StatefulGenerateXml" /> and <command name="ref" param="lst:StatelessGenerateXml" />.
              </command>
              <command name="item"> String parsing, especially when using a regular expression.
              </command>
              <command name="item"> Filling in of templates.
                This can be considered the reverse of string parsing and usually involves combining a few inputs to yield a meaninful string representation.
              </command>
            </block>
            It follows that there are uninteresting categories of blocks, such as:
            <block param="itemize">
              <command name="item"> Trivial state changes, such as a Reset() method that sets a number of instance fields to a specific set of values.</command>
              <command name="item"> Too many inputs and/or outputs.
                This could be considered a more general case than the previous category but there are instances where it may not make sense to break up some processing for either readability or performance reasons.
              </command>
              <command name="item"> Not enough outputs.
                For example, an instance method may be calling instance methods on its fields in such a way that there are no observable changes to the fields' own hidden mutable state.
              </command>
            </block>
            <command name="lstinputlisting"
              opt="caption=ComputeTourLength() method with some inlined mathematical formulas,label=lst:StatefulComputeTourLength,style=realCode,linerange=38-60"
              param="Stateful/FlyingSalespersonProblem.cs" />
            <region name="table and two code listings for partial loop block extraction">
              <raw>\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatefulGenerateXml,caption=GenerateXml() method with a candidate block between lines 18-30,style=realCode,linerange=40-81"
                param="Stateful/ImageCollection.cs" />
              <raw>&amp;</raw>
              <command name="lstinputlisting"
                opt="label=lst:StatelessGenerateXml,caption=GenerateXml() method with the candidate block extracted as the GenerateItemNode() method,style=realCode,linerange=40-91"
                param="Stateless/ImageCollection.cs" />
              <raw>\end{tabular}</raw>
            </region>
            <!-- examples
[re: formulas]
Notice how the SME refactoring not only makes testing trivial but also makes the processing in the original method a lot more obvious and transparent:  once ToRadians() and CalculateGreatCircleDistance() are tested the implementation of ComputeTourLength() is easier to read and it becomes easier to re-use these two methods elsewhere.

[re: string parsing]
= FootNoteFormatterState is perfect because it is impossible to test [the parsing or the formatting] in isolation because:
  = m_tag is only assignable in SimpleBlockFormatterState
  = by a method (Consume) that accepts an instance of Match (Match can't be directly created)
    = it might be easiest to stop here and create the Match from a Regex on input
  = which is called from a private method
  = which is called from TextileFormatter.Format(string)
  = which must be constructed with an instance of IOutputter
  => see revision 202 for what a "test" looks like vs. what it looks like with a small stateless method extraction
For example, consider the following <tt>OnContextAcquired()</tt> method in a class that reads from the <tt>Tag</tt> property defined in a parent class and writes to the <tt>m\_noteID</tt> field.  This method is very difficult to test because it requires considerable work to get the read-only <tt>Tag</tt> property to have a specific value and considerable work to be able to observe the result of the <tt>m\_noteID</tt> field, since it is private.  See Appendix <command name="ref" param="chapter:FootNoteFormatterState" /> for a more thorough treatment.
                <block param="itemize">
                  <command name="item"> Original method:
                    <br />
                    <command name="lstinputlisting"
                      opt="label=lst:StatefulOnContextAcquired,style=realCode,linerange=72-76"
                      param="Stateful/FootNoteFormatterState.cs" />
                  </command>
                  <command name="item"> After SME:
                    <br />
                    <command name="lstinputlisting"
                      opt="label=lst:StatefulOnContextAcquired,style=realCode,linerange=79-88"
                      param="Stateless/FootNoteFormatterState.cs" />
                    Notice that the <tt>ParseFootNoteId()</tt> method can be unit tested by calling it directly and asserting on its output directly.
                  </command>
                </block>
            -->
          </command>
        </command>

        <command name="section" param="Suitability">
        TODO: What code does it just trivially work on?  What should we look for?  Is it a metric that can be automatically measured through something like code analysis? (for example, how many instance fields are being read from and written to)
        <!-- It is trivial to extract a stateless method when all the inputs come from the method's parameters and the only output is the method's return value.  If the method wasn't an override or an interface implementation, it could simply be turned into a static method, but we don't do public interface changes -->
        </command>

        <command name="section" param="Applicability">
        TODO: What code can it almost work on and what needs to be done first (in other words, how to make it suitable).  This can augment the algorithm presented earlier with lots of special cases.  For example, the use of a call-back for incidental operations that can not be re-ordered, multiple return values, etc.
        <!-- Loop item processing is difficult when there are operations other than per-item processing, such as stats and loop invariants -->
        </command>

        <!-- TODO: regarding the motivation for CGT in our case
        The better the statement coverage of the generated tests, the more testable the original source code under the transformation is considered.
        -->
        <!--
        = discuss applicability/suitability (in 1 or 2 sections?)
        == existing/legacy systems with few tests (through acquisition, maintenance)
        == technology constraints (i.e. class must have default public constructor, such as IHttpModule implementations in ASP.NET)
        == programming language with visibility controls for methods such that the extracted methods are visible to tests but not necessarily all users
        = discuss theoretical trade-offs and suitability towards goal
        == forces number of arguments of stateless method to remain small, to avoid Misko's splippery slope
        == MUST be a pure refactor, i.e. callers are/will be none the wiser
        === no bugs added
        === no bugs fixed during this step, always expose and fix bug separately from extraction
        === no performance differences (extracted method could always be inlined by the compiler for release)
        == MUST preserve seams, in case code is already partially tested
        => work around reachability barriers
        = discuss scope of technique (i.e. on which code should it be applied)
        == what to extract, what not to extract
        == what can be re-ordered because its exact "timing" is not terribly important
        == how many [static/instance] fields read
        == how many [static/instance] fields modified
        == how many parameters needed
        == what happens when environment-modifying operations are used
        = discuss experiments with Pex (if only to introduce for another section)
        == trade-offs of automatic test generation based on code coverage
        == differences between a constraint solver and evolutionary testing
        = manual application
        == manual test writing
        == manual stateless method extraction
        == compare unit tests before and after
        -->
        <!--
        = reduce the number of inputs participating in the test
        == reduce the number of methods called to bring object under test into appropriate state (methods executed before - arrange)
        == reduce the number of instances created to support test scenario
        = reduce the number of outputs produced by the test
        == reduce the number of methods called to extract interesting output (methods executed after - assert)
        = reduce the amount of clean-up done to compensate for "arrange" phase
        -->
        <command name="section" param="Decisions made">
          <!--
          = number of inputs to include in a candidate block: 1 to 6 (although 1 should probably be an instance or extension method on the class/struct and 7 is getting complicated)
          = number of outputs to include in a candidate block: 1 to 3 (must return something, otherwise not function; if more than 1, maybe use a call-back?)
          = {Project}.ManualTests created to avoid interference with Pex if had used {Project}.Tests
          -->
          ...
        </command>
        <command name="section" param="Reproducibility">
          <!-- Enough for somebody to reproduce experiment -->
          ...
        </command>
        <command name="section" param="Summary">
          <!-- key points of what was presented and linkage to next chapter -->
          ...
        </command>
      </command>
      <command name="chapter" param="Results and Validation">
        <command name="section" param="Introduction">
          <!-- what the chapter is about -->
          ...
        </command>
        <command name="section" param="Evaluation/experiment design">
          To verify the proposed stateless method extraction (SME) algorithm's efficiency and validate its effectiveness, it is to be compared to (against?) the following strategies (should we bother with "visibility increase" and "mutation removal"?  they both alter the implementation under test (IUT)'s public interface):
          <block param="enumerate">
            <command name="item"> No modifications to the code under test</command>
            <command name="item"> Visibility increases</command>
            <command name="item"> Mutation removal</command>
            <command name="item"> Private accessors</command>
            <command name="item"> Test helper methods</command>
          </block>

          Verification and validation will take place on interesting and/or difficult-to-test methods from the source code of the following 4 select open-source projects:
          <block param="enumerate">
            <command name="item"> AtomicCms</command>
            <command name="item"> KeePassLib</command>
            <command name="item"> PivotStack</command>
            <command name="item"> Textile</command>
          </block>

          The following evaluations will be made against the results of writing tests using each of the 6 strategies on each of the 4 projects:
          <block param="enumerate">
            <command name="item"> Cyclomatic complexity of the unit tests.</command>
            <command name="item"> Number of changes to the class under test's public interface.</command>
            <command name="item"> Percentage of branches covered using concolic testing.</command>
          </block>

          The 3 metrics are now explained in further detail.
          <command name="subsection" param="Cyclomatic complexity of the unit tests">
            Cyclomatic complexity was selected as a metric since it essentially measures the simplicity of a method, in this case unit test methods.  The more simple the unit test methods are, the easier they are to maintain <!-- TODO: cite -->.  Should a regression be introduced in the future, it would be more desirable to have many small test methods instead of a few large test methods, to make it easier to discover exactly what is broken and what is not <!-- TODO: cite -->.

            <!-- TODO: talk about which variant of the metric is used, what counts toward the score and what does not, which tool was used and how the results were extracted -->
          </command>
          <command name="subsection" param="Number of changes to the class under test's public interface">
            It could be undesirable to make changes to the class under test (CUT)'s public interface simply to increase its testability.  Reasons for not wanting any such changes include:
            <block param="enumerate">
              <command name="item"> Textile</command>
              <command name="item"> The class is part of an API with pre-existing releases. Changes to the API would break third-party applications consuming it.</command>
              <command name="item"> The class must implement a specific interface.  This is a technological variation of the previous reason.</command>
              <command name="item"> Exposing instance state as directly mutable might allow callers to violate some constraints or invariants previously handled by the instance state-altering methods.</command>
            </block>

          </command>
          <command name="subsection" param="Percentage of branches covered using concolic testing">
          </command>
        </command>
        <command name="section" param="Results">
          ...
        </command>
        <command name="section" param="Detailed results">
          <!--
          = applying the stateless method extraction technique to the open-source projects
          = applying the technique to examples provided in original paper
          = applying the technique backwards to PivotStack
          = evaluating with code coverage percentage of tests generated by Pex
          = difficulties with Pex:
          == 2010/07/14: "tests generated between runs of Pex are not always the same due to timeouts"
          == not aware of test double opportunities (i.e. mocks)
          == 2010/09/11: "time - it will give up/timeout to not be stuck"
          == 2010/09/11: "intent - unit testing is (validation +) verification exercise using specification/requirements, neither of which are available"
          === "Parameter of abstract type Stream (System.IO) is somewhat vague; there are many implementations of it that could be used, but for unit tests, a MemoryStream should probably ue used. Pex has no such guidance and seems to [randomly?] pick System.Security.Cryptography.TailStream which I can not find in System.Security nor in MSDN documentation!"
          == 2010/09/11: "no focus - unless code is decorated with exclude/ignore attributes"
          == 2010/09/11: "scope"
          === "testability issue" with certain methods, such as:
          ==== Environment.get_NewLine()
          ==== Environment.get_OSVersion()
          ==== File.*
          ==== FileStream..ctor
          === "uninstrumentable" with memory allocation & garbage collection
          === "uninstrumented" source code not available for analysis
          === "extern" behaviour only available at runtime; special case of "uninstrumented"
          === HttpWebRequest (System.Net) does not have a public constructor; the Remarks of the class say to call WebRequest.Create() (which is not instrumented)
          === Neither does Match (System.Text.RegularExpressions) and it is not instrumented anyway.
          = evaluating with metrics (cyclomatic complexity)
          -->
          ...
        </command>
        <command name="section" param="Validation">
          <!-- Demonstrate that you met your goal
          Objectives can be checked off one by one
          If goal was "improve X", then show that X became better (i.e. less clicks, etc.)
          Verification is not very useful; this really has to be about validation -->
          <!-- Cross-reference with Scope and discuss observed trade-offs of other potential approaches -->
          ...
        </command>
        <command name="section" param="Summary">
          ...
        </command>
      </command>
      <command name="chapter" param="Summary of work, Conclusions and Future Work">
        <command name="section" param="Introduction">
          <!-- what the chapter is about -->
          ...
        </command>
        <command name="section" param="Summary of results">
          <!-- Review goal and contributions -->
          ...
        </command>
        <command name="section" param="Conclusions">
          <!-- list of inferences made -->
          ...
        </command>
        <command name="section" param="Future work">
          <!-- best ideas of next steps -->
          ...
        </command>
      </command>
    </command>
    <command name="appendix">
      <!-- material of length that would impede the flow of the -->
      <!-- main body: program listings, long data results, long mathematical -->
      <!-- proofs -->
      <command name="chapter" param="Acronyms">
        <!-- TODO: do we need to turn this into a glossary with explanations? -->
        <block param="description">
          <command name="item" opt="API"> Application Programming Interface</command>
          <command name="item" opt="CT"> Concolic Testing</command>
          <command name="item" opt="CGT"> Computer-Generated Tests</command>
          <command name="item" opt="CUT"> Class Under Test</command>
          <command name="item" opt="ET"> Evolutionary Testing</command>
          <command name="item" opt="GA"> Genetic Algorithms</command>
          <command name="item" opt="HGT"> Human-Generated Tests</command>
          <command name="item" opt="HMT"> Hidden Mutable State</command>
          <command name="item" opt="IUT"> Implementation Under Test</command>
          <command name="item" opt="MST"> Metaheuristic Search Technique</command>
          <command name="item" opt="MUT"> Method Under Test</command>
          <command name="item" opt="OO"> Object-Oriented</command>
          <command name="item" opt="OOP"> Object-Oriented Programming</command>
          <command name="item" opt="RT"> Random Testing</command>
          <command name="item" opt="SBST"> Search-Based Software Testing</command>
          <command name="item" opt="SE"> Symbolic Execution</command>
          <command name="item" opt="SME"> Stateless Method Extraction</command>
        </block>
      </command>
      <command name="chapter" param="Simple parsing and templating made trivial to test">
        <command name="label" param="chapter:FootNoteFormatterState" />
        TODO: tell the sad tale of untestability in FootNoteFormatterState and show the unit tests before and after SME using content from revision 99, 202 and whatever revision will add a test for OnContextAcquired to prove the point.
<!--
From Textile/States/FootNoteFormatterState.cs;

Revision 99:
Before
protected override void OnContextAcquired()
{
  Match m = Regex.Match(Tag, @"^fn(?<id>[0-9]+)");
  m_noteID = Int32.Parse(m.Groups["id"].Value);
}

During
protected override void OnContextAcquired()
{
  string input = Tag;
  Match m = Regex.Match(input, @"^fn(?<id>[0-9]+)");
  string result = Int32.Parse(m.Groups["id"].Value);
  m_noteID = result;
}

After
protected override void OnContextAcquired()
{
  m_noteID = ParseFootNoteId(Tag);
}

internal static int ParseFootNoteId(string input)
{
  Match m = Regex.Match(input, @"^fn(?<id>[0-9]+)");
  return Int32.Parse(m.Groups["id"].Value);
}

Revision 202:
Before
public override void Enter()
{
  Formatter.Output.Write(
    string.Format("<p id=\"fn{0}\"{1}><sup>{2}</sup> ",
      m_noteID,
      FormattedStylesAndAlignment(),
      m_noteID));
}

During
public override void Enter()
{
  var noteID = m_noteID;
  var formattedStylesAndAlignment = FormattedStylesAndAlignment();
  var result = string.Format("<p id=\"fn{0}\"{1}><sup>{2}</sup> ",
    noteID,
    formattedStylesAndAlignment,
    noteID);
  Formatter.Output.Write(result);
}

After
public override void Enter()
{
  Formatter.Output.Write(
    FormatFootNote(m_noteID, FormattedStylesAndAlignment()));
}

internal static string FormatFootNote(int noteId, string formattedStylesAndAlignment)
{
  return string.Format("<p id=\"fn{0}\"{1}><sup>{2}</sup> ",
    noteID,
    formattedStylesAndAlignment,
    noteID));
}

-->
      </command>
    </command>
    <command name="bibliographystyle" param="abbrv" />
    <command name="bibliography" param="thesis" />
  </document>
</iTeX>