<?xml version="1.0" encoding="UTF-8"?>
<iTeX>
  <preamble><!-- !TEX TS-program = pdflatex -->
    <!-- !TEX encoding = UTF-8 Unicode -->

    <command name="documentclass" opt="12pt" param="dalthesis" />

    <command name="usepackage" opt="utf8" param="inputenc" /> <!-- set input encoding (not needed with XeLaTeX) -->
    
    <!-- disable turning "fi", "ff", etc. into one character: http://www.latex-community.org/forum/viewtopic.php?f=5&t=953  -->
    <command name="usepackage" param="microtype" />
    <command name="DisableLigatures" param="encoding = *, family = *" />

    <region comment='the "listings" package is used for source code snippets'>
      <command name="usepackage" param="listings" />
      <command name="usepackage" param="courier" />
      <command name="lstset"
        param="basicstyle=\tiny\ttfamily,tabsize=2,numbers=left,numberstyle=\tiny\ttfamily" />
    </region>
  </preamble>
  <document>
    <region name="Title page">
      <command name="title" param="Stateless Programming And Testing: \\ Extracting a functional layer from object-oriented code" />
      <command name="author" param="Olivier Dagenais" />
      <command name="submitdate" param="July 29, 2011" />
      <command name="copyrightyear" param="2011" />
      <command name="degree" param="Master of Computer Science" />
    </region>

    <command name="frontmatter">
      <region name="[List of] Listings">
        <command name="addcontentsline" param="toc}{chapter}{Listings" />
        <command name="lstlistoflistings" />
        <command name="clearpage" />
      </region>
      <block param="abstract">
        <!-- An abstract is required in all theses. -->
        <!-- Make sure that it fits on one page! -->
      </block>
      <block param="acknowledgements">
        <!-- This is the acknowledgements. -->
        <!-- It is optional. -->
      </block>
    </command>
    <command name="mainmatter">
      <command name="chapter" param="Introduction">
        <command name="section" param="Introduction">
          This chapter introduces the problem and the motivation for solving it, as well as the overall goals and specific objectives covered by the present thesis.  It concludes with an overview of the rest of the document.
        </command>
        <command name="section" param="Problem">
          Software has advanced considerably in the last several years, but has software quality kept up?  We do not always know how good a program or component is or if it is free of defects, if only those defects that will affect us, directly or otherwise.  Software defects can range from the bening, such as incorrect colors and typographical errors in the interface or output, to very serious, such as causing the destruction of a rocket carrying four spacecraft <!-- TODO: cite "Ariane 5 Flight 501 Failure, Report by the Inquiry Board" --> or causing the death of several patients <!-- TODO: cite "Medical Devices: The Therac-25 Nancy Leveson, University of Washington" -->.

          Programming languages and compilers evolved to add features that make it easier to write code, although those features do not always make it easier to test the same code.  Object-oriented programming, for example, has introduced constructs and paradigms designed to make abstraction, inheritance and polymorphism easier, but at the same time introduced a feature that can make testing more difficult:  encapsulation (i.e. information hiding) in the form of instance state.  Encapsulation allows an object to hide its implementation details so as to present a simpler interface to callers.  Alan Kay wrote that object state was meant to be immutable <!-- TODO: reference --> but that intent is seldom enforced by programming languages, frameworks or toolkits.

          Hidden and mutable instance state poses a problem for automated unit testing <!-- TODO: cite --> because that instance state may come into play when exercising a specific scenario <!-- TODO: cite Binder at page 961 -->.  Since the instance state is mutable, the values may not be initialized at instance construction or can change as instance methods are called.  Since the instance state is hidden, there exists, by definition, no way to manipulate this instance state directly.  Separately, hidden (but immutable) instance state or mutable (but visible) instance state do not provide too many difficulties for test writing.  It is the combination of the hidden and mutable properties that make it difficult to write tests.

          <!-- TODO: we could use a small example snippet or two -->
          <command name="subsection" param="Hidden mutable state, described">
            Hidden mutable state (HMS) manifests itself in a few different forms:
            <block param="itemize">
              <command name="item"> Instance state that cannot be set from the constructor or a factory method.</command>
              <command name="item"> Instance state that cannot be directly set from a setter method or property.</command>
              <command name="item"> A constructor or direct factory method is not available.  For example, an instance can only be created as a by-product of a method call on another class.</command>
              <command name="item"> Instance state points to objects with their own hidden mutable state.</command>
            </block>
            In summary, a class with hidden mutable state has variables or fields that must be set or modified indirectly as a result of calling a method that, although not necessarily directly related, nonetheless modifies one or more variables or fields.
          </command>

          The result of hidden mutable state is we end up with difficult-to-test code, which means it stays untested, even despite the many automated test frameworks and systems available <!-- TODO: reference http://opensourcetesting.org/ -->.  This is likely due to a tradeoff between ease of maintenance <!-- TODO: modification? --> and testability <!-- TODO: find source --> where testability was ultimately not favoured.

          We still want to test the code, but we must first surmount the difficult-to-test obstacle that hidden mutable state introduces.  In the process of testing a method that uses hidden instance state (as input, output or both), it usually becomes necessary to write the unit test such that it will indirectly orchestrate said instance state so that specific scenarios can be implemented <!-- TODO: instrumented/probed/explored? --> <!-- TODO: cite Binder page 962 -->.  This makes the test method difficult to maintain because the test will be more unwieldy and less obvious - especially in the "arrange" phase - which may have the effect of discouraging the creation of such tests.

          An example of the state problem can be seen in listings <command name="ref" param="lst:StatefulSmokeDetector" /> and <command name="ref" param="lst:StatefulSmokeDetectorTest" />.  Notice how having all the instance fields private makes it so any test wishing to bring the object to a certain state (such as "alarm sounds while detection decays") has to repeatedly call the <tt>Cycle()</tt> method with various values provided to the <tt>level</tt> parameter?  By the same token, the only observable state for verification is the return value of the method, although, in this particular instance, this should be sufficient for most test scenarios.
          <!-- TODO: should the listings use a figure with subfloats, instead? -->
          <region name="table and two stateful code listings">
            <raw>\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}</raw>
            <command name="lstinputlisting"
              opt="label=lst:StatefulSmokeDetector,caption=SmokeDetector class with hidden mutable state"
              param="Stateful/SmokeDetector.cs" />
            <raw>&amp;</raw>
            <command name="lstinputlisting"
              opt="label=lst:StatefulSmokeDetectorTest,caption=Test class for SmokeDetector"
              param="Stateful/SmokeDetectorTest.cs" />
            <raw>\end{tabular}</raw>
          </region>
        </command>
        <command name="section" param="Motivation">
          <!-- Explain why some people would care -->
          <!-- TODO: 
          = should I motivate [unit] testing more, like I did in my paper?
          = how about talking about the applicability to code that is currently without tests or with insufficient tests
          -->
          Lest we could somehow perform the practically impossible "complete testing" (i.e. exhaustively trying all possible inputs), <!-- TODO: cite a source? --> testing can only prove the presence of defects and not their absence <!-- TODO: cite Dijkstra -->.  A good set of automated tests, on the other hand, can catch software regressions that may be introduced through the addition of a feature or the removal of a defect.  Finding regressions as early as possible ensures their fixing cost is minimized <!-- TOOD: source, probably Joel Spolsky -->.  A good set of automated tests is henceforth defined as one that can catch such software regressions.

          A metric commonly used to represent confidence in a set of automated tests is code coverage percentage <!-- TODO: source -->, usually in the form of branch coverage <!-- TODO: source -->.  Code that is covered might be - but is not necessarily - tested, but uncovered code is definitely untested code.  Shipping software with untested code is like serving a dish that has not yet been tasted.

          Hidden mutable state (HMS) does not just present trouble to tests written by programmers (henceforth referred to as human-generated tests (HGT)), but also to computer-generated tests (CGT), such as those generated through Evolutionary Testing (ET), a form of Search Based Software Testing.  <!-- TODO: does Concolic Testing also suffer from the state problem? -->  Indeed, McMinn reported on the difficulty HMS brought to ET <command name="cite" param="Mcminn03thestate" />:
          <block param="quote">States can cause a variety of problems for ET, since test 
goals involving states can be dependent on the entire history of input to the test object, as well as just the current input.
          </block>

          Although it is possible to work around some HMS with a noteworthy "arrange" phase, this is not always desirable as it can increase the maintenance overhead and costs to write the unit tests, both for human- and computer-generated tests.  There are other obvious options available, such as increasing the visiblity of the mutable state or converting the state from mutable to read-only, but both these options would likely change the public interface of the class under test to an unacceptable level (such as breaking encapsulation), not to mention the associated risk in performing non-trivial modifications (in the latter case) without the safety net of sufficient tests.

          One perhaps less obvious option is the extraction of a subset of the state<em>ful</em> functionality in the form of a state<em>less</em> method which has all its inputs and outputs available to the test driver, while sourcing those inputs and outputs from and to the very instance fields they represent within the implementation itself.  An example of this can be seen in listings <command name="ref" param="lst:StatelessSmokeDetector" /> and <command name="ref" param="lst:StatelessSmokeDetectorTest" />.  Notice how the original implementation of the <tt>Cycle()</tt> method has been trivially extracted into a static overload that accepts all its input and emits all its output through parameters and the method return value?  The <tt>AccumulateDetection()</tt> test method can then be written to supply values for all parameters, while keeping the fields that the parameters would be initialized from safe from modification.  Indeed, the previous test is still there, unchanged, since the <tt>SmokeDetector</tt>'s public interface did not change as a result of performing this transformation.

          <!-- TODO: should the listings use a figure with subfloats, instead? -->
          <region name="table and two stateless code listings">
            <raw>\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}</raw>
            <command name="lstinputlisting"
              opt="label=lst:StatelessSmokeDetector,caption=SmokeDetector class with a stateless method extracted"
              param="Stateless/SmokeDetector.cs" />
            <raw>&amp;</raw>
            <command name="lstinputlisting"
              opt="label=lst:StatelessSmokeDetectorTest,caption=Test class for SmokeDetector exploiting the new Cycle() method overload"
              param="Stateless/SmokeDetectorTest.cs" />
            <raw>\end{tabular}</raw>
          </region>
        </command>
        <command name="section" param="Goal">
          <!-- Can address only part of the problem
          Something abstract/general, such as "world hunger", or a subset of it "hunger in Ottawa"
          Can be written retroactively, after the results have been written -->
          If we are to defeat the difficulties of hidden mutable state (HMS), can we do so with minimal changes to the public interface and with minimal risk of introducing regressions?  Can the unit tests be kept parsimonious, yet cover all the important edge cases?  Is there something we can do to make code containing hidden mutable state more easily testable?

          The goal of this thesis is to improve the testability of classes that suffer from the "state problem" -- because they contain HMS -- while minimally affecting functionality, maintainability and the public interface of the code under test.  The goal is to be validated according to the following metrics:

          <block param="enumerate">
            <command name="item"> Cyclomatic complexity <!-- TODO: cite --> of the unit tests.</command>
            <command name="item"> Number of changes to class under test's public interface.</command>
            <command name="item"> Percentage of branches covered using concolic testing <!-- TODO: source -->.
            <!-- TODO: can maintainability be measured? -->
            <!-- TODO:
            = can I measure the risk of introducing defects or regressions?
            = in other words, what is the safety of the testability transformation/refactoring?
            -->
            </command>
          </block>
          <!--
          = even though I mention ET in the motivation section, I have no goal to evaluate anything for ET???
          = is there a mention of instance state (i.e. HMS) being a problem for Pex or concolic testing in general?
          == my experiments with Pex were designed to have it be the objective evaluator, such that if Pex is unable to create an instance of a class, it is unlikely a human will have an easy time.  This is mostly for the case where a class has no constructor and no easy factory method.
          == Pex is documented as handling ALL state with the help of a shadow interpreter
          == "But then Pex may not know how to create an object through the publicly available constructors such that the object's private fields are in the desired state." (Pex)
          == "If the class is visible and has a visible default constructor, Pex can create an instance of the class. If all the fields are visible, it can generate values for them as well. However, if the fields are encapsulated with properties or not exposed to the outside world, Pex requires help to create the object so as to achieve a better code coverage." http://msdn.microsoft.com/en-us/magazine/ee819140.aspx
          ==
          """
          Warning: field xxx is not public; Pex needs help to construct object (or similar)

Pex generates test inputs, and part of the inputs may be objects with fields. Here, Pex wants to generate an instance of an object which has a private field, and Pex believes that an interesting program behavior will occur when this private field has a particular value. However, while possible with Reflection, Pex does not dare to manufacture objects with arbitrary field values. Instead, in those cases it relies on the user to provide hints how to use the public methods of a class to create an object and bring it into a state where its private field has the desired value.
          """
http://research.microsoft.com/en-us/um/redmond/projects/pex/wiki/pex%20needs%20help%20to%20construct%20object.html
          === I should be able to find instances where Pex can not
          -->
        </command>
        <command name="section" param="Objectives">
          <!-- (what you will produce to meet your goal)
          action items to address goal -->
          To meet the goal, a testability refactoring <!-- TODO: cite "Refactoring as testability transformation" --> algorithm called "stateless method extraction" (SME) is proposed and explained/detailed.  The SME algorithm transforms the source code of the implementation under test (IUT) to introduce a functional (i.e. "externally state-free") software layer to specifically work around many of the testability problems of hidden mutable state (HMS) and to generally increase the testability of the code under test.  The SME algorithm's efficiency and effectiveness will be evaluted by comparing the results of the algorithm's application to other testing approaches.
        </command>
        <command name="section" param="Outline">
          ...
          The <!-- ref: Approach --> chapter covers the details, the how-tos and applicability of the proposed testability refactoring.
        </command>
        <command name="section" param="Summary">
          <!-- key points of what was presented and linkage to next chapter -->
          ...
        </command>
      </command>
      <command name="chapter" param="Background">
        <command name="section" param="Introduction">
          This chapter presents an overview of the related concepts from object-oriented programming to automated testing to computer-generated tests, introduces related work, establishes context within that work and lastly defines the scope of the thesis.
        </command>
        <command name="section" param="Object oriented programming">
          This thesis focuses on testing programs written with object-oriented (OO) languages, as opposed to procedural or functional languages because the intent is to solve a problem specific to OO languages:  hidden mutable state (HMS).  Although procedural languages (such as C) allow programs to have mutable state, the state is generally not hidden as there is (by definition) no encapsulation mechanism.  Functional languages (such as Lisp) on the other hand, allow programs to be written using immutable state through the use of set-once variables.

          <command name="subsection" param="Terminology">
            OO languages will generally have a basic set of features, the most important of which are described here for clarity.
            <block param="description">
              <command name="item" opt="class"> The definition for an object.</command>
              <command name="item" opt="instance"> A run-time manifestation of a class, which carries its own scope.</command>
              <command name="item" opt="static"> A scope for the definition of a class.</command>
              <command name="item" opt="field"> A variable associated with a class (static field) or with an object (instance field).</command>
              <command name="item" opt="method"> A set of operations attached to a class (static method) or to an object (instance method).</command>
              <command name="item" opt="constructor"> A special method that is called when an instance of a class is created.</command>
              <command name="item" opt="factory method"> A method whose purpose is to create instances of a class, but not necessarily of the class on which it is found.</command>
              <command name="item" opt="overload"> Two (or more) methods that have the same name but different parameter types are said to be <em>overloads</em> of the same method.</command>
              <command name="item" opt="interface"> A contract (usually in the form of a list of methods) for classes to implement to enable their instances to be interchangeable with other implementations of the interface.</command>
              <command name="item" opt="property"> A method whose purpose is to allow the reading or reading and writing of a field's value.  Some languages support this directly while others offer a convention of "getters and setters", instead.</command>
            </block>
          </command>
        </command>
        <command name="section" param="Automated testing">
          <!-- TODO:
          = intro
          = I think it was Binder who painfully explained these test frameworks from the point of view of someone who has only ever done manual testing
          -->
          <command name="subsection" param="Testing frameworks">
            <!-- TODO:
            = xUnit
            = arrange, act, assert
            = integration with a build process to further establish confidence
            -->
          </command>
          <command name="subsection" param="Test scope">
            <!-- TODO:
            = unit tests vs. integration tests vs. ???
            -->
          </command>
          <command name="subsection" param="Code coverage">
          </command>
        </command>
        <command name="section" param="Motivations for Computer-Generated Tests">
          <!-- TODO:
          = see notes about the reasons given by the car guys (computer-generated code, integration/co-operation testing of components written by many parties, expensive manual testing like driving the car, etc.)
          -->
        </command>
        <command name="section" param="Intents of Computer-Generated Tests">
          There are four major reasons <!-- TODO: is it a reason? how about objective? --> to use Computer-Generated Tests (CGT).
          <command name="subsection" param="Structural Testing">
          </command>
          <command name="subsection" param="Functional Testing">
          </command>
          <command name="subsection" param="Non-functional Testing">
          </command>
          <!-- <command name="subsection" param="TODO: 4th Intent of CGT">
          </command> -->
        </command>
        <command name="section" param="Approaches to Computer-Generated Tests">
          There are three major approaches in generating tests. <!-- TODO: cite "An empirical investigation into branch coverage for C programs using CUTE and AUSTIN" -->
          <command name="subsection" param="Random Testing">
          </command>
          <command name="subsection" param="Search Based Software Testing">
            <!-- 
            = Also called metaheuristic
            = Hill climbing, simulated annealing
            = Evolutionary Testing
            -->
          </command>
          <command name="subsection" param="Concolic Testing">
            <!--
            = Concrete + Symbolic = Concolic (a.k.a. dynamic symbolic execution)
            = Constraint solvers
            = Pex
            = difficulties with concolic, esp. Pex
            == fields of abstract type (i.e. System.IO.Stream)
            == environment-related values (input domain is very constrained and specialized)
            -->
          </command>
        </command>
        <command name="section" param="Related work">
          <!--
          = Miško Hevery
          == testability explorer
          === Non-Mockable Total Recursive Cyclomatic Complexity
          === Global Mutable State
          === Law of Demeter
          == "How to think about OO"
          == "Static Methods are Death to Testability"
          = FxCop/Code Analysis tools
          == "CA1502: Avoid excessive complexity" http://msdn.microsoft.com/en-us/library/ms182212.aspx
          === "A low cyclomatic complexity generally indicates a method that is easy to understand, test, and maintain."
          = The same data dependency analysis used in Mcminn03thestate can also be used to determine the arguments to a stateless method
          = any SBST research that aims to work around state problems
          == GP then GA
          == Data Dependency Analysis
          == temporary program transformations
          -->
          ...
        </command>
        <command name="section" param="Context">
          <!-- Show that I understand what everybody else has done ("master an area") -->
          ...
          Binder, page 52 introduces a few relevant concepts
        </command>
        <command name="section" param="Scope">
          <!-- End with feature matrix, comparing my solution to others -->
          <!--
          = contrast with isolated, stand-alone tests
          = contrast with test helper methods
          == For example, DeepZoomImageTest.TestComputeLevelSize() that creates two instances per call:
          Assert.AreEqual (new Size (1200, 1500), TestComputeLevelSize (PortraitImageSize, 12));
          vs. the original stateless method that could be called directly:
          Assert.AreEqual (new Size (1200, 1500), DeepZoomImage.ComputeLevelSize (PortraitImageSize, 12));
          === For that particular one, because my settings class performs work in the constructor, there are some properties which MUST be provided.
          == how about test helper properties?
          == they shift complexity instead of removing it altogether.  I need to find some way to prove that this leads to more brittle tests.  Perhaps the fact that the stateless method is reusable vs. the test helper method is not?
          = constrast with factory methods:
          """
          As an alternative to employing only existing constructors to configure objects,
the user may also provide factory methods, which could invoke a sequence of
method calls to construct and configure a new object, possibly creating cyclic
references as well.
          """ Pex, last paragraph of section 3.4
          = contrast with better abstractions/use of interfaces
          == virtual/in-memory file system
          == operating on sequences instead of streams
          == introducing a class for private methods that coordinate related pieces of data
          == introducing a functor for methods that coordinate related pieces of data
          == introducing a generic class to remove copy/pasted typed implementations (i.e. FooCollection, BarCollection replaced by Collection{Foo} and Collection{Bar})
          == a regular expression toolkit or compiler that generates a model specific to the specified expression
          = contrast with visible, mutable state
          == changes current public interface
          = contrast with hidden, immutable state
          == changes current public interface
          = contrast with no state whatsoever
          == changes current public interface
          = contrast with static code analysis
          == contrast with code contracts
          = contrast with code reviews
          = contrast with dependency injection
          = contrast with improving the tools (i.e. research in SBST and DSE)
          = contrast with temporary program transformations (i.e. non-refactoring)
          
          Not in scope:
          = parallelization of tests (although probably easier with technique)
          = difficult-to-test object state changes?
          = should we assume no changes to IUT's public interface are allowed?
          == the IUT's design suitability is out of scope, we could assume it's "perfect" for the needs of the user (or impossible to change due to implementing an interface)
          -->
          ...
        </command>
        <command name="section" param="Summary">
          <!-- key points of what was presented and linkage to next chapter -->
          ...
        </command>
      </command>
      <command name="chapter" param="Approach">
        <command name="section" param="Introduction">
          <!-- what the chapter is about -->
          ...
        </command>
        <command name="section" param="Design">
          <!-- 
          = discuss applicability/suitability (in 1 or 2 sections?)
          == existing/legacy systems with few tests (through acquisition, maintenance)
          == technology constraints (i.e. class must have default public constructor, such as IHttpModule implementations in ASP.NET)
          == programming language with visibility controls for methods such that the extracted methods are visible to tests but not necessarily all users
          = discuss theoretical trade-offs and suitability towards goal
          == forces number of arguments of stateless method to remain small, to avoid Misko's splippery slope
          == MUST be a pure refactor, i.e. callers are/will be none the wiser
          === no bugs added
          === no bugs fixed during this step, always expose and fix bug separately from extraction
          === no performance differences (extracted method could always be inlined by the compiler for release)
          == MUST preserve seams, in case code is already partially tested
          => work around reachability barriers
          = discuss scope of technique (i.e. on which code should it be applied)
          == what to extract, what not to extract
          == what can be re-ordered because its exact "timing" is not terribly important
          == how many [static/instance] fields read
          == how many [static/instance] fields modified
          == how many parameters needed
          == what happens when environment-modifying operations are used
          = discuss experiments with Pex (if only to introduce for another section)
          == trade-offs of automatic test generation based on code coverage
          == differences between a constraint solver and evolutionary testing
          = manual application
          == manual test writing
          == manual statelesss method extraction
          == compare unit tests before and after
          -->
          <!-- 
          = reduce the number of inputs participating in the test
          == reduce the number of methods called to bring object under test into appropriate state (methods executed before - arrange)
          == reduce the number of instances created to support test scenario
          = reduce the number of outputs produced by the test
          == reduce the number of methods called to extract interesting output (methods executed after - assert)
          = reduce the amount of clean-up done to compensate for "arrange" phase
          -->
          ...
        </command>
        <command name="section" param="Decisions made">
          <!--
          = {Project}.ManualTests created to avoid interference with Pex if had used {Project}.Tests
          -->
          ...
        </command>
        <command name="section" param="Reproducability">
          <!-- Enough for somebody to reproduce experiment -->
          ...
        </command>
        <command name="section" param="Summary">
          <!-- key points of what was presented and linkage to next chapter -->
          ...
        </command>
      </command>
      <command name="chapter" param="Results and Validation">
        <command name="section" param="Introduction">
          <!-- what the chapter is about -->
          ...
        </command>
        <command name="section" param="Evaluation/experiment design">
          To verify the proposed stateless method extraction (SME) algorithm's efficiency and validate its effectiveness, it is to be compared to (against?) the following strategies (should we bother with "visibility increase" and "mutation removal"?  they both alter the implementation under test (IUT)'s public interface):
          <block param="enumerate">
            <command name="item"> No modifications to the code under test</command>
            <command name="item"> Visibility increases</command>
            <command name="item"> Mutation removal</command>
            <command name="item"> Private accessors</command>
            <command name="item"> Test helper methods</command>
          </block>
  
          Verification and validation will take place on interesting and/or difficult-to-test methods from the source code of the following 4 select open-source projects:
          <block param="enumerate">
            <command name="item"> AtomicCms</command>
            <command name="item"> KeePassLib</command>
            <command name="item"> PivotStack</command>
            <command name="item"> Textile</command>
          </block>

          The following evaluations will be made against the results of writing tests using each of the 6 strategies on each of the 4 projects:
          <block param="enumerate">
            <command name="item"> Cyclomatic complexity of the unit tests.</command>
            <command name="item"> Number of changes to the class under test's public interface.</command>
            <command name="item"> Percentage of branches covered using concolic testing.</command>
          </block>

          The 3 metrics are now explained in further detail.
          <command name="subsection" param="Cyclomatic complexity of the unit tests">
            Cyclomatic complexity was selected as a metric since it essentially measures the simplicity of a method, in this case unit test methods.  The more simple the unit test methods are, the easier they are to maintain <!-- TODO: cite -->.  Should a regression be introduced in the future, it would be more desirable to have many small test methods instead of a few large test methods, to make it easier to discover exactly what is broken and what is not <!-- TODO: cite -->.
            
            <!-- TODO: talk about which variant of the metric is used, what counts toward the score and what does not, which tool was used and how the results were extracted -->
          </command>
          <command name="subsection" param="Number of changes to the class under test's public interface">
            It could be undesirable to make changes to the class under test (CUT)'s public interface simply to increase its testability.  Reasons for not wanting any such changes include:
            <block param="enumerate">
              <command name="item"> Textile</command>
              <command name="item"> The class is part of an API with pre-existing releases. Changes to the API would break third-party applications consuming it.</command>
              <command name="item"> The class must implement a specific interface.  This is a technological variation of the previous reason.</command>
              <command name="item"> Exposing instance state as directly mutable might allow callers to violate some constraints or invariants previously handled by the instance state-altering methods.</command>
            </block>
            
          </command>
          <command name="subsection" param="Percentage of branches covered using concolic testing">
          </command>
        </command>
        <command name="section" param="Results">
          ...
        </command>
        <command name="section" param="Detailed results">
          <!--
          = applying the stateless method extraction technique to the open-source projects
          = applying the technique to examples provided in original paper
          = applying the technique backwards to PivotStack
          = evaluating with code coverage percentage of tests generated by Pex
          = difficulties with Pex:
          == 2010/07/14: "tests generated between runs of Pex are not always the same due to timeouts"
          == not aware of test double opportunities (i.e. mocks)
          == 2010/09/11: "time - it will give up/timeout to not be stuck"
          == 2010/09/11: "intent - unit testing is (validation +) verification exercise using specification/requirements, neither of which are available"
          === "Parameter of abstract type Stream (System.IO) is somewhat vague; there are many implementations of it that could be used, but for unit tests, a MemoryStream should probably ue used. Pex has no such guidance and seems to [randomly?] pick System.Security.Cryptography.TailStream which I can not find in System.Security nor in MSDN documentation!"
          == 2010/09/11: "no focus - unless code is decorated with exclude/ignore attributes"
          == 2010/09/11: "scope"
          === "testability issue" with certain methods, such as:
          ==== Environment.get_NewLine()
          ==== Environment.get_OSVersion()
          ==== File.*
          ==== FileStream..ctor
          === "uninstrumentable" with memory allocation & garbage collection
          === "uninstrumented" source code not available for analysis
          === "extern" behaviour only available at runtime; special case of "uninstrumented"
          === HttpWebRequest (System.Net) does not have a public constructor; the Remarks of the class say to call WebRequest.Create() (which is not instrumented)
          === Neither does Match (System.Text.RegularExpressions) and it is not instrumented anyway.
          = evaluating with metrics (cyclomatic complexity)
          -->
          ...
        </command>
        <command name="section" param="Validation">
          <!-- Demonstrate that you met your goal
          Objectives can be checked off one by one
          If goal was "improve X", then show that X became better (i.e. less clicks, etc.)
          Verification is not very useful; this really has to be about validation -->
          <!-- Cross-reference with Scope and discuss observed trade-offs of other potential approaches -->
          ...
        </command>
        <command name="section" param="Summary">
          ...
        </command>
      </command>
      <command name="chapter" param="Summary of work, Conclusions and Future Work">
        <command name="section" param="Introduction">
          <!-- what the chapter is about -->
          ...
        </command>
        <command name="section" param="Summary of results">
          <!-- Review goal and contributions -->
          ...
        </command>
        <command name="section" param="Conclusions">
          <!-- list of inferences made -->
          ...
        </command>
        <command name="section" param="Future work">
          <!-- best ideas of next steps -->
          ...
        </command>
      </command>
    </command>
    <command name="appendix">
      <!-- material of length that would impede the flow of the -->
      <!-- main body: program listings, long data results, long mathematical -->
      <!-- proofs -->
      <command name="chapter" param="Acronyms">
        <!-- TODO: do we need to turn this into a glossary with explanations? -->
        <block param="description">
          <command name="item" opt="API"> Application Programming Interface</command>
          <command name="item" opt="CGT"> Computer-Generated Tests</command>
          <command name="item" opt="ET"> Evolutionary Testing</command>
          <command name="item" opt="HGT"> Human-Generated Tests</command>
          <command name="item" opt="HMT"> Hidden Mutable State</command>
          <command name="item" opt="IUT"> Implementation Under Test</command>
          <command name="item" opt="SBST"> Search-Based Software Testing</command>
          <command name="item" opt="SME"> Stateless Method Extraction</command>
        </block>
      </command>
    </command>
    <command name="bibliographystyle" param="abbrv" />
    <command name="bibliography" param="thesis" />
  </document>
</iTeX>